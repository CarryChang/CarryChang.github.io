<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python语言之随机数和正则]]></title>
    <url>%2F2018%2F07%2F05%2FPython%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[random模块&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;真正意义上的随机数（或者随机事件）在某次产生过程中是按照实验过程中表现的分布概率随机产生的，其结果是不可预测的，是不可见的。而计算机中的随机函数是按照一定算法模拟产生的，其结果是确定的，是可见的。我们可以这样认为这个可预见的结果其出现的概率是100%。所以用计算机随机函数所产生的“随机数”并不随机，是伪随机数。 计算机的伪随机数是由随机种子根据一定的计算方法计算出来的数值。所以，只要计算方法一定，随机种子一定，那么产生的随机数就是固定的。 只要用户或第三方不设置随机种子，那么在默认情况下随机种子来自系统时钟。 Python的这个库在底层使用通用的算法，经过长久的考验，可靠性没得说，但绝对不能用于密码相关的功能。 基本方法 random.seed(a=None, version=2)初始化伪随机数生成器。如果未提供a或者a=None，则使用系统时间为种子。如果a是一个整数，则作为种子。 random.getstate()返回一个当前生成器的内部状态的对象 random.setstate(state)传入一个先前利用getstate方法获得的状态对象，使得生成器恢复到这个状态。 random.getrandbits(k)返回一个不大于K位的Python整数（十进制），比如k=10，则结果在0~2^10之间的整数。 整数方法 random.randrange(stop) random.randrange(start, stop[, step])等同于choice(range(start, stop, step))，但并不实际创建range对象。 random.randint(a, b)返回一个a &lt;= N &lt;= b的随机整数N。等同于 randrange(a, b+1) 代码示例1234import randomprint(random.randrange(4)) # 3print(random.randrange(2, 10,2)) # 8print(random.randint(1, 5)) # 1 序列结构方法 random.choice(seq)从非空序列seq中随机选取一个元素。如果seq为空则弹出 IndexError异常。 random.choices(population, weights=None, *, cum_weights=None, k=1)3.6版本新增。从population集群中随机抽取K个元素。weights是相对权重列表，cum_weights是累计权重，两个参数不能同时存在。 random.shuffle(x[, random])随机打乱序列x内元素的排列顺序。只能针对可变的序列，对于不可变序列，请使用下面的sample()方法。 random.sample(population, k)从population样本或集合中随机抽取K个不重复的元素形成新的序列。常用于不重复的随机抽样。返回的是一个新的序列，不会破坏原有序列。要从一个整数区间随机抽取一定数量的整数，请使用sample(range(10000000), k=60)类似的方法，这非常有效和节省空间。如果k大于population的长度，则弹出ValueError异常。 代码示例12345678import randomlist_str = ["1", "2", "3", "4", "5"]print("原来排序:", list_str) # 原来排序: ['1', '2', '3', '4', '5']print("从指定序列中随机1个:", random.choice(list_str)) # 从指定序列中随机1个: 5print("从指定序列中随机2个:", random.choices(list_str, k=2)) # 从指定序列中随机2个: ['2', '3']random.shuffle(list_str) # 随机打乱顺序print("洗牌的显示:",list_str) # 洗牌的显示: ['5', '2', '3', '4', '1']print("抽取样本:", random.sample(list_str, k=3)) # 抽取样本: ['1', '2', '4'] 真值分布 random.random()返回一个介于左闭右开[0.0, 1.0)区间的浮点数 random.uniform(a, b)返回一个介于a和b之间的浮点数。如果a&gt;b，则是b到a之间的浮点数。这里的a和b都有可能出现在结果中。 random.triangular(low, high, mode)返回一个low &lt;= N &lt;=high的三角形分布的随机数。参数mode指明众数出现位置。 random.betavariate(alpha, beta)β分布。返回的结果在0~1之间 random.expovariate(lambd)指数分布 random.gammavariate(alpha, beta)伽马分布 random.gauss(mu, sigma)高斯分布 random.lognormvariate(mu, sigma)对数正态分布 random.normalvariate(mu, sigma)正态分布 random.vonmisesvariate(mu, kappa)卡帕分布 random.paretovariate(alpha)帕累托分布 random.weibullvariate(alpha, beta)威布尔分布 典型的问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt;&gt;&gt; random() # 随机浮点数: 0.0 &lt;= x &lt; 1.00.37444887175646646&gt;&gt;&gt; uniform(2.5, 10.0) # 随机浮点数: 2.5 &lt;= x &lt; 10.03.1800146073117523&gt;&gt;&gt; randrange(10) # 0-9的整数：7&gt;&gt;&gt; randrange(0, 101, 2) # 0-100的偶数26&gt;&gt;&gt; choice(['win', 'lose', 'draw']) # 从序列随机选择一个元素'draw'&gt;&gt;&gt; deck = 'ace two three four'.split()&gt;&gt;&gt; shuffle(deck) # 对序列进行洗牌，改变原序列&gt;&gt;&gt; deck['four', 'two', 'ace', 'three']&gt;&gt;&gt; sample([10, 20, 30, 40, 50], k=4) # 不改变原序列的抽取指定数目样本，并生成新序列[40, 10, 50, 30]&gt;&gt;&gt; # 6次旋转红黑绿轮盘(带权重可重复的取样)，不破坏原序列&gt;&gt;&gt; choices(['red', 'black', 'green'], [18, 18, 2], k=6)['red', 'green', 'black', 'black', 'red', 'black']&gt;&gt;&gt; # 德州扑克计算概率Deal 20 cards without replacement from a deck of 52 playing cards&gt;&gt;&gt; # and determine the proportion of cards with a ten-value&gt;&gt;&gt; # (a ten, jack, queen, or king).&gt;&gt;&gt; deck = collections.Counter(tens=16, low_cards=36)&gt;&gt;&gt; seen = sample(list(deck.elements()), k=20)&gt;&gt;&gt; seen.count('tens') / 200.15&gt;&gt;&gt; # 模拟概率Estimate the probability of getting 5 or more heads from 7 spins&gt;&gt;&gt; # of a biased coin that settles on heads 60% of the time.&gt;&gt;&gt; trial = lambda: choices('HT', cum_weights=(0.60, 1.00), k=7).count('H') &gt;= 5&gt;&gt;&gt; sum(trial() for i in range(10000)) / 100000.4169&gt;&gt;&gt; # Probability of the median of 5 samples being in middle two quartiles&gt;&gt;&gt; trial = lambda : 2500 &lt;= sorted(choices(range(10000), k=5))[2] &lt; 7500&gt;&gt;&gt; sum(trial() for i in range(10000)) / 100000.7958 下面是生成一个包含大写字母A-Z和数字0-9的随机4位验证码的程序1234567891011import randomcheckcode = []for i in range(4): type = ["num", "alp"] random_type = random.choice(type) if random_type == "num": checkcode.append(chr(random.randint(65, 90))) else: checkcode.append(random.randint(0, 9))print(checkcode) 下面是生成指定长度字母数字随机序列的代码：12345678910111213141516171819202122#!/usr/bin/env python# -*- coding:utf-8 -*-import random, stringdef gen_random_string(length): # 数字的个数随机产生 num_of_numeric = random.randint(1,length-1) # 剩下的都是字母 num_of_letter = length - num_of_numeric # 随机生成数字 numerics = [random.choice(string.digits) for i in range(num_of_numeric)] # 随机生成字母 letters = [random.choice(string.ascii_letters) for i in range(num_of_letter)] # 结合两者 all_chars = numerics + letters # 洗牌 random.shuffle(all_chars) # 生成最终字符串 result = ''.join([i for i in all_chars]) return resultif __name__ == '__main__': print(gen_random_string(64)) Python正则表达式正则表达式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正则表达式（regular expression）是可以匹配文本片段的模式。最简单的正则表达式就是普通字符串，可以匹配其自身。比如，正则表达式 ‘hello’ 可以匹配字符串 ‘hello’。 要注意的是，正则表达式并不是一个程序，而是用于处理字符串的一种模式，如果你想用它来处理字符串，就必须使用支持正则表达式的工具，比如 Linux 中的 awk, sed, grep，或者编程语言 Perl, Python, Java 等等。 正则表达式有多种不同的风格，下表列出了适用于 Python等编程语言的部分元字符以及说明： 数量词的贪婪模式与非贪婪模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab“如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词”ab?”，将找到”a”。 反斜杠的困扰&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\“表示。同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。 匹配模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;正则表达式提供了一些可用的匹配模式，比如忽略大小写、多行匹配等，这部分内容将在Pattern类的工厂方法re.compile(pattern[, flags])中一起介绍。 re模块开始使用re&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Python通过re模块提供对正则表达式的支持。使用re的一般步骤是先将正则表达式的字符串形式编译为Pattern实例，然后使用Pattern实例处理文本并获得匹配结果（一个Match实例），最后使用Match实例获得信息，进行其他的操作。 函数总览 正则使用使用步骤如下： 使用 compile 函数将正则表达式的字符串形式编译为一个 Pattern 对象； 通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果（一个 Match 对象）； 最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作。1234567891011import re# 将正则表达式编译成Pattern对象pattern = re.compile(r'hello')# 使用Pattern匹配文本，获得匹配结果，无法匹配时将返回Nonematch = pattern.match('hello world!')if match: # 使用Match获得分组信息 print(match.group()) re.compile(strPattern[, flag]):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方法是Pattern类的工厂方法，用于将字符串形式的正则表达式编译为Pattern对象。 第二个参数flag是匹配模式，取值可以使用按位或运算符’|’表示同时生效，比如re.I | re.M。另外，你也可以在regex字符串中指定模式，比如re.compile(‘pattern’, re.I | re.M)与re.compile(‘(?im)pattern’)是等价的。可选值有： re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同） M(MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图） S(DOTALL): 点任意匹配模式，改变’.’的行为 L(LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定 U(UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性 X(VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。以下两个正则表达式是等价的 PatternPattern对象是一个编译好的正则表达式，通过Pattern提供的一系列方法可以对文本进行匹配查找。Pattern不能直接实例化，必须使用re.compile()进行构造。Pattern提供了几个可读属性用于获取表达式的相关信息： pattern: 编译时用的表达式字符串。 flags: 编译时用的匹配模式。数字形式。 groups: 表达式中分组的数量。 groupindex: 以表达式中有别名的组的别名为键、以该组对应的编号为值的字典，没有别名的组不包含在内。123456import rep = re.compile(r'(\w+) (\w+)(?P&lt;sign&gt;.*)', re.DOTALL)print("p.pattern:", p.pattern) # p.pattern: (\w+) (\w+)(?P&lt;sign&gt;.*)print("p.flags:", p.flags) # p.flags: 48print("p.groups:", p.groups) # p.groups: 3print("p.groupindex:", p.groupindex) # p.groupindex: &#123;'sign': 3&#125; Pattern的实例方法和re模块方法match参数：(string[, pos[, endpos]]) | re.match(pattern, string[, flags]):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方法将从string的pos下标处起尝试匹配pattern；如果pattern结束时仍可匹配，则返回一个Match对象；如果匹配过程中pattern无法匹配，或者匹配未结束就已到达endpos，则返回None。 pos和endpos的默认值分别为0和len(string)；re.match()无法指定这两个参数，参数flags用于编译pattern时指定匹配模式。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Match对象是一次匹配的结果，包含了很多关于此次匹配的信息，可以使用Match提供的可读属性或方法来获取这些信息。 属性： string: 匹配时使用的文本。 re: 匹配时使用的Pattern对象。 pos: 文本中正则表达式开始搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。 endpos: 文本中正则表达式结束搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。 lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None。 lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None。 123456789101112131415161718import re# pattern = re.compile(r'(\w+) (\w+)(?P&lt;sign&gt;.*)')# m = pattern.match('hello world!')m = re.match(r'(\w+) (\w+)(?P&lt;sign&gt;.*)', 'hello world!')print("m.string:", m.string) # m.string: hello world!print("m.re:", m.re) # m.re: re.compile('(\\w+) (\\w+)(?P&lt;sign&gt;.*)')print("m.pos:", m.pos) # m.pos: 0print("m.endpos:", m.endpos) # m.endpos: 12print("m.lastindex:", m.lastindex) # m.lastindex: 3print("m.lastgroup:", m.lastgroup) # m.lastgroup: signprint("m.group(1,2):", m.group(1, 2)) # m.group(1,2): ('hello', 'world')print("m.groups():", m.groups()) # m.groups(): ('hello', 'world', '!')print("m.groupdict():", m.groupdict()) # m.groupdict(): &#123;'sign': '!'&#125;print("m.start(2):", m.start(2)) # m.start(2): 6print("m.end(2):", m.end(2)) # m.end(2): 11print("m.span(2):", m.span(2)) # m.span(2): (6, 11)print(r"m.expand(r'\2 \1\3'):", m.expand(r'\2 \1\3')) # m.expand(r'\2 \1\3'): world hello! 方法： group([group1, …]):获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0)；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串。 groups([default]):以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None。 groupdict([default]):返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上。 start([group]):返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0。 end([group]):返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0。 span([group]):返回(start(group), end(group))。 expand(template):将匹配到的分组代入template中然后返回。template中可以使用\id或\g、\g引用分组，但不能使用编号0。\id与\g是等价的；但\10将被认为是第10个分组，如果你想表达\1之后是字符’0’，只能使用\g0。 1234567891011121314151617181920212223&gt;&gt;&gt; import re&gt;&gt;&gt; pattern = re.compile(r'([a-z]+) ([a-z]+)', re.I) # re.I 表示忽略大小写&gt;&gt;&gt; m = pattern.match('Hello World Wide Web')&gt;&gt;&gt; print m # 匹配成功，返回一个 Match 对象&lt;_sre.SRE_Match object at 0x10bea83e8&gt;&gt;&gt;&gt; m.group(0) # 返回匹配成功的整个子串'Hello World'&gt;&gt;&gt; m.span(0) # 返回匹配成功的整个子串的索引(0, 11)&gt;&gt;&gt; m.group(1) # 返回第一个分组匹配成功的子串'Hello'&gt;&gt;&gt; m.span(1) # 返回第一个分组匹配成功的子串的索引(0, 5)&gt;&gt;&gt; m.group(2) # 返回第二个分组匹配成功的子串'World'&gt;&gt;&gt; m.span(2) # 返回第二个分组匹配成功的子串(6, 11)&gt;&gt;&gt; m.groups() # 等价于 (m.group(1), m.group(2), ...)('Hello', 'World')&gt;&gt;&gt; m.group(3) # 不存在第三个分组Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;IndexError: no such group 注意：这个方法并不是完全匹配。当pattern结束时若string还有剩余字符，仍然视为成功。想要完全匹配，可以在表达式末尾加上边界匹配符’$’。 search参数：(string[, pos[, endpos]]) | re.search(pattern, string[, flags])&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个方法用于查找字符串中可以匹配成功的子串。从string的pos下标处起尝试匹配pattern，如果pattern结束时仍可匹配，则返回一个Match对象；若无法匹配，则将pos加1后重新尝试匹配；直到pos=endpos时仍无法匹配则返回None。 pos和endpos的默认值分别为0和len(string))；re.search()无法指定这两个参数，参数flags用于编译pattern时指定匹配模式。123456789101112import re# 将正则表达式编译成Pattern对象pattern = re.compile(r'world')# 使用search()查找匹配的子串，不存在能匹配的子串时将返回None# 这个例子中使用match()无法成功匹配match = pattern.search('hello world!')if match: # 使用Match获得分组信息 print(match.group()) # world split参数:(string[, maxsplit]) | re.split(pattern, string[, maxsplit])按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。1234import rep = re.compile(r'\d+')print(p.split('one1two2three3four4')) # ['one', 'two', 'three', 'four', ''] findall参数：(string[, pos[, endpos]]) | re.findall(pattern, string[, flags])搜索string，以列表形式返回全部能匹配的子串。1234import rep = re.compile(r'\d+')print(p.findall('one1two2three3four4')) # ['1', '2', '3', '4'] finditer参数：(string[, pos[, endpos]]) | re.finditer(pattern, string[, flags]):搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。12345import rep = re.compile(r'\d+')for m in p.finditer('one1two2three3four4'): print (m.group()) # 1 2 3 4 sub参数：(repl, string[, count]) | re.sub(pattern, repl, string[, count])使用repl替换string中每一个匹配的子串后返回替换后的字符串。 当repl是一个字符串时，可以使用\id或\g、\g引用分组，但不能使用编号0。 当repl是一个方法时，这个方法应当只接受一个参数（Match对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。 count用于指定最多替换次数，不指定时全部替换。 12345678910import rep = re.compile(r'(\w+) (\w+)')s = 'i say, hello world!'print(p.sub(r'\2 \1', s)) # say i, world hello!def func(m): return m.group(1).title() + ' ' + m.group(2).title()print(p.sub(func, s)) # I Say, Hello World! subn参数：(repl, string[, count]) |re.sub(pattern, repl, string[, count])返回 (sub(repl, string[, count]), 替换次数)。1234567891011import rep = re.compile(r'(\w+) (\w+)')s = 'i say, hello world!'print(p.subn(r'\2 \1', s)) # ('say i, world hello!', 2)def func(m): return m.group(1).title() + ' ' + m.group(2).title()print(p.subn(func, s)) # ('I Say, Hello World!', 2) 使用哪种方法？从上文可以看到，使用 re 模块有两种方式： 使用 re.compile 函数生成一个 Pattern 对象，然后使用 Pattern 对象的一系列方法对文本进行匹配查找； 直接使用 re.match, re.search 和 re.findall 等函数直接对文本匹配查找。 方法一1234567891011import re# 将正则表达式编译成Pattern对象pattern = re.compile(r'hello')# 使用Pattern匹配文本，获得匹配结果，无法匹配时将返回Nonematch = pattern.match('hello world!')if match: # 使用Match获得分组信息 print(match.group()) # hello 方法二12345678import re# 直接使用re模块的方法match = re.match(r'hello','hello world!')if match: # 使用Match获得分组信息 print(match.group()) # hello 如果一个正则表达式需要用到多次（比如上面的 \d+），在多种场合经常需要被用到，出于效率的考虑，我们应该预先编译该正则表达式，生成一个 Pattern 对象，再使用该对象的一系列方法对需要匹配的文件进行匹配；而如果直接使用 re.match, re.search 等函数，每次传入一个正则表达式，它都会被编译一次，效率就会大打折扣。因此，推荐使用第 1 种用法。 如果只是简单的对文本进行提取，可以使用方法2，可以使代码更加的简洁。 常见的正则提取匹配中文12345import retitle = '你好，hello，世界'pattern = re.compile(r'[\u4e00-\u9fa5]+')result = pattern.findall(title)print(result) # ['你好', '世界'] 贪婪匹配123456789import recontent = '&lt;div&gt;test1&lt;/div&gt;&lt;div&gt;test2&lt;/div&gt;'pattern1 = re.compile(r'&lt;div&gt;(.*)&lt;/div&gt;')result1 = pattern1.findall(content)pattern2 = re.compile(r'&lt;div&gt;(.*?)&lt;/div&gt;')result2 = pattern2.findall(content)print("贪婪匹配结果:", result1) # 贪婪匹配结果: ['test1&lt;/div&gt;&lt;div&gt;test2'] #print("非贪婪匹配结果:", result2) # 非贪婪匹配结果: ['test1', 'test2']]]></content>
      <categories>
        <category>Python语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
        <tag>随机数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python语言之时间模块]]></title>
    <url>%2F2018%2F07%2F04%2FPython%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[简介&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在平常的代码中，我们常常需要与时间打交道。在Python中，与时间处理有关的模块就包括：time，datetime以及calendar。 在Python中，通常有这几种方式来表示时间： 时间戳 格式化的时间字符串 时间元组（struct_time）共九个元素。由于Python的time模块实现主要调用C库，所以各个平台可能有所不同。 UTC（Coordinated Universal Time，世界协调时）亦即格林威治天文时间，世界标准时间。在中国为UTC+8。DST（Daylight Saving Time）即夏令时。 时间戳（timestamp）的方式：通常来说，时间戳表示的是从1970年1月1日00:00:00开始按秒计算的偏移量。返回时间戳方式的函数主要有time()，clock()等。 元组（struct_time）方式：struct_time元组共有9个元素，返回struct_time的函数主要有gmtime()，localtime()，strptime()。 Python处理时间的库 时间和日期时间戳(Timestamp)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;时间戳（timestamp），一个能表示一份数据在某个特定时间之前已经存在的、 完整的、 可验证的数据,通常是一个字符序列，唯一地标识某一刻的时间。使用数字签名技术产生的数据， 签名的对象包括了原始文件信息、 签名参数、 签名时间等信息。广泛的运用在知识产权保护、 合同签字、 金融帐务、 电子报价投标、 股票交易等方面。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;时间戳是指格林威治时间1970年01月01日00时00分00秒(北京时间1970年01月01日08时00分00秒)起至现在的总秒数。 时间格式化(Format_time)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;datetime、date、time都提供了strftime()方法，该方法接受一个格式字符串，输出日期时间的字符串表示,格式化符号如下： 格式符 含义 %a 星期的英文单词的缩写：如星期一， 则返回 Mon %A 星期的英文单词的全拼：如星期一，返回 Monday %b 月份的英文单词的缩写：如一月， 则返回 Jan %B 月份的引文单词的缩写：如一月， 则返回 January %c 返回datetime的字符串表示，如03/08/15 23:01:26 %d 返回的是当前时间是当前月的第几天 %f 微秒的表示： 范围: [0,999999] %H 以24小时制表示当前小时 %I 以12小时制表示当前小时 %j 返回 当天是当年的第几天 范围[001,366] %m 返回月份 范围[0,12] %M 返回分钟数 范围 [0,59] %P 返回是上午还是下午–AM or PM %S 返回秒数范围 [0,61]参看python手册 %U 返回当周是当年的第几周 以周日为第一天 %W 返回当周是当年的第几周 以周一为第一天 %w 当天在当周的天数，范围为[0, 6]，6表示星期天 %x 日期的字符串表示 ：03/08/15 %X 时间的字符串表示 ：23:22:08 %y 两个数字表示的年份 15 %Y 四个数字表示的年份 2015 %z 与utc时间的间隔 （如果是本地时间，返回空字符串） %Z 时区名称（如果是本地时间，返回空字符串） 时间元祖(Struct_time)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;返回struct_time的函数主要有gmtime()，localtime()，strptime()。 索引（Index） 属性（Attribute） 值（Values） 0 tm_year（年） 比如2011 1 tm_mon（月） 1 - 12 2 tm_mday（日） 1 - 31 3 tm_hour（时） 0 - 23 4 tm_min（分） 0 - 59 5 tm_sec（秒） 0 - 61 6 tm_wday（weekday） 0 - 6（0表示周日） 7 tm_yday（一年中的第几天） 1 - 366 8 tm_isdst（是否是夏令时） 默认为-1 内置标准库Time模块在time模块中，时间有三种表现形式： 时间戳，一般指Unix时间戳，是从1970年开始到现在的秒数。 本地时间的struct_time形式：一个长度为11的命名元组。 UTC时间的struct_time形式：一个长度为11的命名元组，类似于本地时间，只不过为UTC时间。 其中后两者的类型一致，区别在于一个是本地时间（localtime），一个是utc时间。各表现形式如下：12345678910import timeprint("time stamp:", time.time()) # 时间戳# time stamp: 1530605181.4410665print("local time:", time.localtime()) # 北京时间（东八区）# local time: time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=16, tm_min=6, tm_sec=21, tm_wday=1, tm_yday=184, tm_isdst=0)print("utc time:", time.gmtime()) # 世界时间 # utc time: time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=8, tm_min=6, tm_sec=21, tm_wday=1, tm_yday=184, tm_isdst=0) 各种时间形式和字符串之间的转换： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import timeimport calendartime_stamp = time.time() # 时间戳local_time = time.localtime(time_stamp) # 时间戳转struct_time类型的本地时间utc_time = time.gmtime(time_stamp) # 时间戳转struct_time类型的utc时间print("时间戳：", time_stamp, "，转换为本地时间：", local_time)# 时间戳： 1530606422.775597 ，转换为本地时间： time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=16, tm_min=27, tm_sec=2, tm_wday=1, tm_yday=184, tm_isdst=0)print("时间戳：", time_stamp, "，转换为utc时间：", utc_time)# 时间戳： 1530606422.775597 ，转换为utc时间： time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=8, tm_min=27, tm_sec=2, tm_wday=1, tm_yday=184, tm_isdst=0)time_stamp_1 = time.mktime(local_time) # struct_time类型的本地时间转时间戳time_stamp_2 = calendar.timegm(utc_time) # struct_time类型的utc时间转时间戳print("本地时间：", local_time, "，转换为时间戳：", time_stamp_1)# 本地时间： time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=16, tm_min=27, tm_sec=2, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为时间戳： 1530606422.0print("utc时间：", utc_time, "，转换为时间戳：", time_stamp_2)# utc时间： time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=8, tm_min=27, tm_sec=2, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为时间戳： 1530606422# 各种时间形式和字符串之间的转换(常用):str_time = time.ctime(time_stamp) # 时间戳转字符串(本地时间字符串)print("时间戳", time_stamp, "，转换为本地时间字符串：", str_time)# 时间戳 1530607825.8346324 ，转换为本地时间字符串： Tue Jul 3 16:50:25 2018str_time = time.asctime(local_time) # struct_time类型的本地时间转字符串print("struct_time类型的本地时间", local_time, "，转换为字符串：", str_time)# struct_time类型的本地时间 time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=16, tm_min=50, tm_sec=25, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为字符串： Tue Jul 3 16:50:25 2018str_time = time.asctime(utc_time) # struct_time类型的utc时间转字符串print("struct_time类型的utc时间", utc_time, "，转换为字符串：", str_time)# struct_time类型的utc时间 time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=8, tm_min=50, tm_sec=25, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为字符串： Tue Jul 3 08:50:25 2018# struct_time类型的本地时间转字符串：自定义格式set_time = time.strftime("%Y-%m-%d, %H:%M:%S, %w", local_time)print("struct_time类型的本地时间", local_time, "，转换为字符串：", set_time)# struct_time类型的本地时间 time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=16, tm_min=50, tm_sec=25, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为字符串： 2018-07-03, 16:50:25, 2# struct_time类型的utc时间转字符串：自定义格式set_time = time.strftime("%Y-%m-%d, %H:%M:%S, %w", utc_time)print("struct_time类型的本地时间", utc_time, "，转换为字符串：", set_time)# struct_time类型的本地时间 time.struct_time(tm_year=2018, tm_mon=7, tm_mday=3, tm_hour=8, tm_min=50, tm_sec=25, tm_wday=1, tm_yday=184, tm_isdst=0) ，转换为字符串： 2018-07-03, 08:50:25, 2# 字符串转struct_time类型struct_time1 = time.strptime("2016-11-15, 15:32:12, 2", "%Y-%m-%d, %H:%M:%S, %w")struct_time2 = time.strptime("20161115", "%Y%m%d")print("2016-11-15, 15:32:12, 2 匹配 %Y-%m-%d, %H:%M:%S, %w：", struct_time1)# 2016-11-15, 15:32:12, 2 匹配 %Y-%m-%d, %H:%M:%S, %w： time.struct_time(tm_year=2016, tm_mon=11, tm_mday=15, tm_hour=15, tm_min=32, tm_sec=12, tm_wday=1, tm_yday=320, tm_isdst=-1)print("20161115 匹配 %Y%m%:", struct_time2)# 20161115 匹配 %Y%m%: time.struct_time(tm_year=2016, tm_mon=11, tm_mday=15, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=1, tm_yday=320, tm_isdst=-1) 内置函数&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Time 模块包含了以下内置函数，既有时间处理的，也有转换时间格式的： Time模块包含了以下2个非常重要的属性： 序号 属性 描述 1 time.timezone 属性time.timezone是当地时区（未启动夏令时）距离格林威治的偏移秒数（&gt;0，美洲;&lt;=0大部分欧洲，亚洲，非洲）。 2 time.tzname 属性time.tzname包含一对根据情况的不同而不同的字符串，分别是带夏令时的本地时区名称，和不带的。 延伸拓展 CPU time和wall time的区别&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有时候需要统计程序的运行时间，这是我们一般会做一个艰难的选择：是使用time.clock()还是time.time(),首先需要明确几个概念：CPU time和wall time。 CPU time是当CPU完全被某个进程所使用时所花费的时间，因为CPU并不是被某个进程单独占用的，在你的进程执行的这段时间中，你的进程可能只占用了其中若干的时间片（由操作系统决定），CPU时间只是处理你的进程占用的那些时间片的相加，对于这段时间中由其他进程占用的时间片是不纳入你的进程的CPU时间的。 wall time从名字上来看就是墙上时钟的意思，可以理解为进程从开始到结束的时间，包括其他进程占用的时间。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Python中有哥模块专门用于统计程序运行时间的模块：timeit。在timeit的源代码中针对不同的系统做了不同的定义：123456if sys.platform == "win32": # On Windows, the best timer is time.clock() default_timer = time.clockelse: # On most other platforms the best timer is time.time() default_timer = time.time &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从中我们可以看出在Windows中最好使用clock()函数，而在其他平台上最好使用time.time()。程序的执行时间总是和运行环境相关的，因为程序不可能运行在一个拥有无限的资源的环境中，而且在测量运行时间时，多次测量取平均值要比只运行一次得到的结果要更好。 Datetime模块datatime模块重新封装了time模块，提供更多接口，该模块中包含4个主要的类： datetime.time：时间类，只包含时、分、秒、微秒等时间信息。 datetime.date：日期类，只包含年、月、日、星期等日期信息。 datetime.datetime：日期时间类，包含以上两者的全部信息。 datetime.timedelta：时间日期差值类，用来表示两个datetime之间的差值。 datetime.time类 datetime.time(hour[ , minute[ , second[ , microsecond[ , tzinfo,[fold ]] ] ] ] ) 所有参数都是可选的。 tzinfo可以是None，或者是tzinfo子类的实例。其余参数可以是整数，范围如下： 0 &lt;= hour &lt; 24， 0 &lt;= minute &lt; 60， 0 &lt;= second &lt; 60， 0 &lt;= microsecond &lt; 1000000， fold in [0, 1]。 1234print(datetime.time())print(datetime.time(23, 23, 30, 123123))# 00:00:00# 23:23:30.123123 静态字段 time.min：time类所能表示的最小时间，time.min = time(0, 0, 0, 0)。 time.max：time类所能表示的最大时间，time.max = time(23, 59, 59, 999999)。 time.resolution：时间的最小单位，这里是1微秒 属性和方法 t1.hour：时 t1.minute：分 t1.second：秒 t1.microsecond：微秒 t1.tzinfo：时区信息 t1.replace([ hour[ , minute[ , second[ , microsecond[ , tzinfo] ] ] ] ] )：创建一个新的时间对象，用参数指定的时、分、秒、微秒代替原有对象中的属性（原有对象仍保持不变） t1.isoformat()：返回型如”HH:MM:SS”格式的字符串表示 t1.strftime(fmt)：同time模块中的format 代码实例:1234567891011tm = datetime.time(9, 23, 45, 23123) # 初始化time对象print("time:",tm) # time: 09:23:45.023123print("时:", tm.hour) # 时: 9print("分:", tm.minute) # 分: 23print("秒:", tm.second) # 秒: 45print("微秒:", tm.microsecond) # 微秒: 23123print("时区信息:", tm.tzinfo) # 时区信息: Noneprint("替换对应的时间:", tm.replace(10)) # 替换对应的时间: 10:23:45.023123print("返回格式化时间字符串:", tm.isoformat())# 返回格式化时间字符串: 09:23:45.023123s = tm.strftime("%H:%M:%S %Z")print("格式化字符串:", s)# 格式化字符串: 09:23:45 datetime.date类 datetime.date(year, month, day) 所有参数都是必需的。参数可以是整数，范围如下： MINYEAR &lt;= year &lt;= MAXYEAR 1 &lt;= month &lt;= 12 1 &lt;= day &lt;= number of days in the given month and year 静态方法和字段1234- date.max、date.min：date对象所能表示的最大、最小日期；- date.resolution：date对象表示日期的最小单位。这里是天。- date.today()：返回一个表示当前本地日期的date对象；- date.fromtimestamp(timestamp)：根据给定的时间戮，返回一个date对象； 代码示例12345678910import timeimport datetimetime_stamp = time.time()print(time_stamp) # 1530672191.8658917dt = datetime.date.fromtimestamp(time_stamp)print(dt) # 2018-07-04print(dt.min) # 0001-01-01print(dt.max) # 9999-12-31print(dt.resolution) # 1 day, 0:00:00print(dt.today()) # 2018-07-04 方法和属性 d1.year、date.month、date.day：年、月、日； d1.replace(year, month, day)：生成一个新的日期对象，用参数指定的年，月，日代替原有对象中的属性。（原有对象仍保持不变） d1.timetuple()：返回日期对应的time.struct_time对象； d1.weekday()：返回weekday，如果是星期一，返回0；如果是星期2，返回1，以此类推； d1.isoweekday()：返回weekday，如果是星期一，返回1；如果是星期2，返回2，以此类推； d1.isocalendar()：返回格式如(year，month，day)的元组； d1.isoformat()：返回格式如’YYYY-MM-DD’的字符串； d1.strftime(fmt)：和time模块format相同。 代码示例12345678910td = datetime.date.today()print(td) # 2018-07-04print(td.year, td.month, td.day) # 2018 7 4print(td.replace(month=8)) # 2018-08-04print(td.timetuple()) # time.struct_time(tm_year=2018, tm_mon=7, tm_mday=4, tm_hour=0, tm_min=0, tm_sec=0, tm_wday=2, tm_yday=185, tm_isdst=-1)print(td.weekday()) # 2print(td.isoweekday()) # 3print(td.isocalendar()) # (2018, 27, 3)print(td.isoformat()) # 2018-07-04print(td.strftime("%Y-%m-%d")) # 2018-07-04 datetime.datetime类 datetime.datetime (year, month, day[ , hour[ , minute[ , second[ , microsecond[ , tzinfo] ] ] ] ] ) datetime相当于date和time结合起来，年，月和日的参数是必需的。 tzinfo可以是None，或者是tzinfo子类的实例。其余参数可以是整数，范围如下： MINYEAR &lt;= year &lt;= MAXYEAR， 1 &lt;= month &lt;= 12， 1 &lt;= day &lt;= number of days in the given month and year， 0 &lt;= hour &lt; 24， 0 &lt;= minute &lt; 60， 0 &lt;= second &lt; 60， 0 &lt;= microsecond &lt; 1000000， fold in [0, 1]。 静态方法和字段 datetime.today()：返回一个表示当前本地时间的datetime对象； datetime.now([tz])：返回一个表示当前本地时间的datetime对象，如果提供了参数tz，则获取tz参数所指时区的本地时间； datetime.utcnow()：返回一个当前utc时间的datetime对象；#格林威治时间 datetime.fromtimestamp(timestamp[, tz])：根据时间戮创建一个datetime对象，参数tz指定时区信息； datetime.utcfromtimestamp(timestamp)：根据时间戮创建一个datetime对象； datetime.combine(date, time)：根据date和time，创建一个datetime对象； datetime.strptime(date_string, format)：将格式字符串转换为datetime对象； 代码示例12345678910import timeimport datetimetime_stamp = time.time()print(datetime.datetime.today()) # 2018-07-04 13:46:57.688327print(datetime.datetime.now()) # 2018-07-04 13:46:57.688327print(datetime.datetime.utcnow()) # 2018-07-04 05:46:57.688327print(datetime.datetime.fromtimestamp(time_stamp)) # 2018-07-04 13:46:57.688327print(datetime.datetime.utcfromtimestamp(time_stamp))# 2018-07-04 05:46:57.688327print(datetime.datetime.combine(datetime.date.today(), datetime.time(13, 23, 23, 23213))) # 2018-07-04 13:23:23.023213print(datetime.datetime.strptime("20180111", "%Y%m%d")) # 2018-01-11 00:00:00 方法和属性 dt.year、month、day、hour、minute、second、microsecond、tzinfo： dt.date()：获取date对象； dt.time()：获取time对象； dt. replace([ year[ , month[ , day[ , hour[ , minute[ , second[ , microsecond[ , tzinfo] ] ] ] ] ] ] ]):替换时间； dt. timetuple()：本地时间元祖； dt. utctimetuple()：国际时间元祖； dt. toordinal()：返回日期的格雷戈里序数； dt. weekday()：返回weekday，如果是星期一，返回0；如果是星期2，返回1，以此类推； dt. isocalendar ()：返回weekday，如果是星期一，返回1；如果是星期2，返回2，以此类推； dt. isoformat([ sep] )：返回格式如’YYYY-MM-DD’的字符串； dt. ctime()：返回一个日期时间的C格式字符串，等效于time.ctime(time.mktime(dt.timetuple()))； dt. strftime (format)：和time模块format相同。 代码示例 1234567891011121314 datetime_str = datetime.datetime.today()print(datetime_str) # 2018-07-04 14:07:49.378147print(datetime_str.year, datetime_str.month, datetime_str.day, datetime_str.hour, datetime_str.minute, datetime_str.second, datetime_str.microsecond) # 2018 7 4 14 7 49 378147print(datetime_str.date(), datetime_str.time()) # 2018-07-04 14:07:49.378147print(datetime_str.replace(year=2019)) # 2019-07-04 14:07:49.378147print(datetime_str.timetuple()) # time.struct_time(tm_year=2018, tm_mon=7, tm_mday=4, tm_hour=14, tm_min=7, tm_sec=49, tm_wday=2, tm_yday=185, tm_isdst=-1)print(datetime_str.utctimetuple()) # time.struct_time(tm_year=2018, tm_mon=7, tm_mday=4, tm_hour=14, tm_min=7, tm_sec=49, tm_wday=2, tm_yday=185, tm_isdst=0)print(datetime_str.toordinal()) # 736879print(datetime_str.weekday()) # 2print(datetime_str.isoweekday()) # 3print(datetime_str.isoformat()) # 2018-07-04T14:07:49.378147print(datetime_str.ctime()) # Wed Jul 4 14:07:49 2018print(datetime_str.strptime("20191222", "%Y%m%d")) # 2019-12-22 00:00:00 datetime.timedelta类 datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) 使用timedelta可以很方便的在日期上做天days，小时hour，分钟，秒，毫秒，微妙的时间计算，如果要计算月份则需要另外的办法。所有参数都是可选的，默认为0。参数可能是整数或浮点数，可能是正数或负数。支持的操作 Operation Result t1 = t2 + t3 Sum of t2 and t3. Afterwards t1-t2 == t3 and t1-t3 == t2 are true. (1) t1 = t2 - t3 Difference of t2 and t3. Afterwards t1 == t2 - t3 and t2 == t1 + t3 are true. (1) t1 = t2 i or t1 = i t2 Delta multiplied by an integer. Afterwards t1 // i == t2 is true, provided i != 0. In general, t1 i == t1 (i-1) + t1 is true. (1) t1 = t2 f or t1 = f t2 Delta multiplied by a float. The result is rounded to the nearest multiple of timedelta.resolution using round-half-to-even. f = t2 / t3 Division (3) of t2 by t3. Returns a float object. t1 = t2 / f or t1 = t2 / i Delta divided by a float or an int. The result is rounded to the nearest multiple of timedelta.resolution using round-half-to-even. t1 = t2 // i or t1 = t2 // t3 The floor is computed and the remainder (if any) is thrown away. In the second case, an integer is returned. (3) t1 = t2 % t3 The remainder is computed as a timedelta object. (3) q, r = divmod(t1, t2) Computes the quotient and the remainder: q = t1 // t2 (3) and r = t1 % t2. q is an integer and r is a timedelta object. +t1 Returns a timedelta object with the same value. (2) -t1 equivalent to timedelta(-t1.days, -t1.seconds, -t1.microseconds), and to t1* -1. (1)(4) str(t) Returns a string in the form [D day[s], ][H]H:MM:SS[.UUUUUU], where D is negative for negative t. (5) repr(t) Returns a string representation of the timedelta object as a constructor call with canonical attribute values. abs(t)| equivalent to +t when t.days &gt;= 0, and to -t when t.days &lt; 0. (2)| calendar模块此模块的函数都是日历相关的，例如打印某月的字符月历。星期一是默认的每周第一天，星期天是默认的最后一天。更改设置需调用calendar.setfirstweekday()函数。代码示例12345678910import calendarprint(calendar.month(2018, 7))# July 2018# Mo Tu We Th Fr Sa Su# 1# 2 3 4 5 6 7 8# 9 10 11 12 13 14 15# 16 17 18 19 20 21 22# 23 24 25 26 27 28 29# 30 31 序号 函数 描述 1 calendar.calendar(year,w=2,l=1,c=6) 返回一个多行字符串格式的year年年历，3个月一行，间隔距离为c。 每日宽度间隔为w字符。每行长度为21 W+18+2 C。l是每星期行数。 2 calendar.firstweekday( ) 返回当前每周起始日期的设置。默认情况下，首次载入caendar模块时返回0，即星期一。 3 calendar.isleap(year) 是闰年返回True，否则为false。 4 calendar.leapdays(y1,y2) 返回在Y1，Y2两年之间的闰年总数。 5 calendar.month(year,month,w=2,l=1) 返回一个多行字符串格式的year年month月日历，两行标题，一周一行。每日宽度间隔为w字符。每行的长度为7* w+6。l是每星期的行数。 6 calendar.monthcalendar(year,month) 返回一个整数的单层嵌套列表。每个子列表装载代表一个星期的整数。Year年month月外的日期都设为0;范围内的日子都由该月第几日表示，从1开始。 7 calendar.monthrange(year,month) 返回两个整数。第一个是该月的星期几的日期码，第二个是该月的日期码。日从0（星期一）到6（星期日）;月从1到12。 8 calendar.prcal(year,w=2,l=1,c=6) 相当于 print calendar.calendar(year,w,l,c). 9 calendar.prmonth(year,month,w=2,l=1) 相当于 print calendar.calendar（year，w，l，c）。 10 calendar.setfirstweekday(weekday) 设置每周的起始日期码。0（星期一）到6（星期日）。 11 calendar.timegm(tupletime) 和time.gmtime相反：接受一个时间元组形式，返回该时刻的时间戳（1970纪元后经过的浮点秒数）。 12 calendar.weekday(year,month,day) 返回给定日期的日期码。0（星期一）到6（星期日）。月份为 1（一月） 到 12（12月）。 常用时间问题获取当前的日期、时间1234567dt = datetime.datetime.today()print("当前的日期和时间:", dt)print("当前的日期:", dt.date())print("当前的时间:", dt.time())# 当前的日期和时间: 2018-07-04 15:29:44.038381# 当前的日期: 2018-07-04# 当前的时间: 15:29:44.038381 将字符串转化为日期123456789101112131415161718def strtotime(str_time, format): return datetime.datetime.strptime(str_time, format)str_time1 = "2018723"format1 = "%Y%m%d"str_time2 = "2018-7-23"format2 = "%Y-%m-%d"str_time3 = "2018:7:23"format3 = "%Y:%m:%d"str_time4 = "2018年7月23日"format4 = "%Y年%m月%d日"print(strtotime(str_time1, format1).date())print(strtotime(str_time2, format2).date())print(strtotime(str_time3, format3).date())print(strtotime(str_time4, format4).date())# 2018-07-23# 2018-07-23# 2018-07-23# 2018-07-23 给定日期向前后N天的日期123456789import datetimed1 = datetime.datetime.today().date() # 只取日期print("今天：", d1) # 今天d2 = datetime.timedelta(-1) # 昨天d3 = datetime.timedelta(+1) # 明天print("昨天：", d1 + d2, "，明天：", d1 + d3)# 今天： 2018-07-04# 昨天： 2018-07-03 ，明天： 2018-07-05 获取给定参数的前几天的日期，返回一个list123456789101112import datetimedef getDayList(num): today = datetime.datetime.today().date() day = datetime.timedelta(-1) date_list = [] for i in range(num): date_list.append(today) today = today + day return date_listprint("前十天:", getDayList(10))# 前十天: [datetime.date(2018, 7, 4), datetime.date(2018, 7, 3), datetime.date(2018, 7, 2), datetime.date(2018, 7, 1), datetime.date(2018, 6, 30), datetime.date(2018, 6, 29), datetime.date(2018, 6, 28), datetime.date(2018, 6, 27), datetime.date(2018, 6, 26), datetime.date(2018, 6, 25)] 两个日期相隔的天数，如2018-3-4和2018-7-412345678910import datetimedef datediff(beginDate, endDate): format = "%Y-%m-%d" bd = datetime.datetime.strptime(beginDate, format) ed = datetime.datetime.strptime(endDate, format) return abs((bd - ed).days) + 1beginDate = "2018-3-4"endDate = "2018-7-4"print(beginDate,"到",endDate,"相隔:",datediff(beginDate, endDate),"天")# 2018-3-4 到 2018-7-4 相隔: 123 天 第三方扩展库（力推arrow）Arrowarrow是一个提供了更易懂和友好的方法来创建、操作、格式化和转化日期、时间和时间戳的python库。可以完全替代datetime，支持python2和3。 安装1pip install arrow 使用获取当前时间1234567891011import arrowt1 = arrow.now()t2 = arrow.utcnow()print("本地时间:", t1)print("国际时间:", t2)print(t1.date())print(t1.time())# 本地时间: 2018-07-04T16:11:31.994133+08:00# 国际时间: 2018-07-04T08:11:31.994133+00:00# 2018-07-04# 16:23:58.881471 通过utcnow()和now()分别获取了utc时间和local时间，最终获取的是一个Arrow时间对象，通过这个对象我们可以做各种时间转换。 时间形式转换1234567891011121314151617181920import arrowt1 = arrow.now()print("时间戳:", t1.timestamp)# 时间戳: 1530692291print("时间字符串:", t1.format())# 时间字符串: 2018-07-04 16:18:11+08:00print("格式化时间字符串:", t1.format("YYYY-MM-DD HH:mm"))# 格式化时间字符串: 2018-07-04 16:18print("从字符串转换成Arrow对象:",arrow.get("2017-07-04 11:30", "YYYY-MM-DD HH:mm"))# 从字符串转换成Arrow对象: 2017-07-04T11:30:00+00:00print("从时间戳转化为Arrow对象:",arrow.get(t1.timestamp)) #从时间戳转化为Arrow对象: 2018-07-04T08:18:11+00:00print("直接生成Arrow对象:",arrow.Arrow(2018, 7, 4))# 直接生成Arrow对象: 2018-07-04T00:00:00+00:00 时间推移时间推移就是要获取某个时间之前的时间或者之后的时间，比如要获取相对于当前时间前一天的时间。123456t1 = arrow.now()print("今天:",t1.date()) # 今天: 2018-07-04print("前一天:",t1.shift(days=-1).date()) # 前一天: 2018-07-03print("前一周",t1.shift(weeks=-1).date()) # 前一周2018-06-27print("前两个月:",t1.shift(months=-2).date()) # 前两个月2018-05-04print("明年:",t1.shift(years=1).date()) # 明年2019-07-04 Arrow的时间格式化]]></content>
      <categories>
        <category>Python语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>时间模块</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python语言之IO文件操作]]></title>
    <url>%2F2018%2F06%2F29%2FPython%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I/O在计算机中是指Input/Output，也就是Stream(流)的输入和输出。这里的输入和输出是相对于内存来说的，Input Stream（输入流）是指数据从外（磁盘、网络）流进内存，Output Stream是数据从内存流出到外面（磁盘、网络）。程序运行时，数据都是在内存中驻留，由CPU这个超快的计算核心来执行，涉及到数据交换的地方（通常是磁盘、网络操作）就需要IO接口。 文件的读写操作 文件读写实现原理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;文件读写就是一种常见的IO操作。那么根据上面的描述，可以推断python也应该封装操作系统的底层接口，直接提供了文件读写相关的操作方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于操作I/O的能力是由操作系统提供的，且现代操作系统不允许普通程序直接操作磁盘，所以读写文件时需要请求操作系统打开一个对象（通常被称为文件描述符–file descriptor, 简称fd），这就是我们在程序中要操作的文件对象。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通常高级编程语言中会提供一个内置的函数，通过接收“文件路径”以及“文件打开模式”等参数来打开一个文件对象，并返回该文件对象的文件描述符。因此通过这个函数我们就可以获取要操作的文件对象了。这个内置函数在Python中叫open(), 在PHP中叫fopen()。 文件读写操作步骤不同的编程语言读写文件的操作步骤大体都是一样的，都分为以下几个步骤： 打开文件，获取文件描述符 操作文件描述符,读/写 关闭文件,close方法 需要注意的是：文件读写操作完成后，应该及时关闭。 一方面，文件对象会占用操作系统的资源； 另外一方面，操作系统对同一时间能打开的文件描述符的数量是有限制的。常用数据格式储存 TXT是微软在操作系统上附带的一种文本格式，是最常见的一种文件格式 。 JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。 易于人阅读和编写。格式如下所示,非常类似Python的字典形式： CSV(Comma-Separated Values,逗号分隔值)其文件以纯文本形式存储表格数据（数字和文本）。CSV文件由任意数目的记录组成，记录间以某种换行符分隔；每条记录由字段组成，字段间的分隔符是其它字符或字符串，最常见的是逗号或制表符。 Microsoft Excel是Microsoft为使用Windows和Apple Macintosh操作系统的计算机编写的一款电子表格软件。直观的界面、出色的计算功能和图表工具，再加上成功的市场营销，使Excel成为最流行的个人计算机数据处理软件。文件操作控制台I/O 读取键盘输入：内置函数input([prompt])，用于从标准输入读取一个行，并返回一个字符串（去掉结尾的换行符）。 1i = input("Enter your input:") 印到屏幕：最简单的输出方法是用print语句，你可以给它传递零个或多个用逗号隔开的表达式。 1print([object, ...][, sep=' '][, end='endline_character_here'][, file=redirect_to_here]) sep表示分割符 end表示结束符 file表示重定向文件 如果要给sep、end、file指定值必须使用关键字参数。12print('hello', 'world', sep='%') # 输出 hello%world print('hello', 'world', end='*') # 输出 hello world*，并且不换行 打开和关闭文件使用内置函数open()，创建file文件对象。1file=open(file,mode ='r',buffering = -1,encoding=None,errors=None,newline=None,closefd =True,opener=None) file：一个类似于路径的对象，它提供要打开的文件的路径名（绝对或相对于当前工作目录）或要打包的文件的整数文件描述符。 mode：是一个可选字符串，用于指定文件打开的模式 。它默认为’r’，这意味着开放以文本方式阅读。 buffering：是用于设置缓冲策略的可选整数。通过0切换缓冲关闭（仅在二进制模式下允许），1选择行缓冲（仅在文本模式下可用）以及&gt; 1的整数，以指示固定大小的块缓冲区的大小（以字节为单位）。 encoding：是用于解码或编码文件的编码的名称。这只能用于文本模式。默认编码是平台相关的（无论locale.getpreferredencoding()返回），但可以使用Python支持的任何文本编码。 以上是比较常用的参数，下面的参数只做了解即可： errors：是一个可选字符串，指定如何处理编码和解码错误 - 这不能用于二进制模式。有多种标准错误处理程序可用（列在“ 错误处理程序”下），但已注册的任何错误处理名称 codecs.register_error()也是有效的。标准名称包括： strict如果存在编码错误，则引发异常。默认值None具有相同的效果。 ignore忽略错误。请注意，忽略编码错误可能会导致数据丢失。 replace导致替换标记（例如’?’）被插入有错误数据的地方。 surrogateescape会将任何不正确的字节表示为Unicode专用区域中的代码。 xmlcharrefreplace仅在写入文件时才受支持。编码不支持的字符将替换为适当的XML字符引用&#nnn;。 backslashreplace 用Python的反斜杠转义序列替换畸形数据。 namereplace（也仅在写入时才支持）用换\N{…}码序列替换不支持的字符。 newline：控制通用换行符模式的工作方式（仅适用于文本模式）。它可以是None，’’，’\n’，’\r’，和 ‘\r\n’。 closefd：是False文件描述符而不是文件名，那么文件关闭时底层文件描述符将保持打开状态。如果给定文件名，closefd必须是True（默认），否则会引发错误。 opener：可以通过传递可调用的opener来使用自定义opener。然后通过调用opener（file，flags）来获得文件对象的底层文件描述符。 File对象的属性一个文件被打开后，你有一个file对象，你可以得到有关该文件的各种信息。以下是和file对象相关的所有属性的列表： 属性 描述 file.closefd 返回true如果文件已被关闭，否则返回false file name 返回文件的名称 file.mode 返回open中的mode参数配置 file.buffer 返回open中的buffer参数配置 file.encoding 返回open中的encoding参数配置 file.errors 返回open中的errors参数配置 file.line_buffering 返回open中的buffering参数配置 file.newlines 返回open中的newlines参数配置 代码测试如下：123456789file = open('demo.txt','r',encoding='utf8',)print("是否关闭：",file.closed)# 是否关闭： Falseprint("文件名称：",file.name)# 文件名称： demo.txtprint("访问模式：",file.mode)# 访问模式： rprint("文件缓冲：",file.buffer)# 文件缓冲： &lt;_io.BufferedReader name='demo.txt'&gt;print("文件编码：",file.encoding)# 文件编码： utf8print("错误处理：",file.errors)# 错误处理： strictprint("行缓冲：",file.line_buffering)# 行缓冲： Falseprint("行换符：",file.newlines)# 行换符： None File读写操作file对象使用open函数来创建，下面列出了file对象常用的函数。建立一个demo.txt文件对上述方法进行实际操作，demo.txt的内容如下，是python之道。12345678910111213141516171819202122import thisprint(this)---------------------------Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren&apos;t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one-- and preferably only one --obvious way to do it.Although that way may not be obvious at first unless you&apos;re Dutch.Now is better than never.Although never is often better than *right* now.If the implementation is hard to explain, it&apos;s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea -- let&apos;s do more of those! 测试的脚本为demo.txt1234567891011with open('demo.txt','r+') as file: print("光标起始位置：",file.tell())# 光标起始位置： 0 print("光标移动字符：",file.seek(10))# 光标移动字符： 10 print('现在光标的位置：',file.tell())# 现在光标的位置： 10 print('恢复光标起始位置：',file.seek(0))# 恢复光标起始位置： 0 print('光标所在的一行：',file.__next__())# 光标所在的一行： import this print('读取十个字符：',file.read(20))# 读取十个字符： print(this)-------- print('读取整行：',file.readline())# 读取整行： --------------------------- print('读取所有行并储存为列表：',file.readlines())# 读取所有行并储存为列表： ['Beautiful is better than ugly.\n', 'Explicit is better than implicit.\n', 'Simple is better than complex.\n', 'Complex is better than complicated.\n', 'Flat is better than nested.\n', 'Sparse is better than dense.\n', 'Readability counts.\n', "Special cases aren't special enough to break the rules.\n", 'Although practicality beats purity.\n', 'Errors should never pass silently.\n', 'Unless explicitly silenced.\n', 'In the face of ambiguity, refuse the temptation to guess.\n', 'There should be one-- and preferably only one --obvious way to do it.\n', "Although that way may not be obvious at first unless you're Dutch.\n", 'Now is better than never.\n', 'Although never is often better than *right* now.\n', "If the implementation is hard to explain, it's a bad idea.\n", 'If the implementation is easy to explain, it may be a good idea.\n', "Namespaces are one honking great idea -- let's do more of those!"] print('写入字符串(不会自动换行)：',file.write('\n'+"perfect!"))# 写入字符串(不会自动换行)： 9 file.writelines(['2','1','2','3','4'])# perfect!21234 常用的读写操作代码12345678910# 如果只读模式为r，如果读写则r+with open('demo.txt','r+') as file: for line in file.readlines(): # 一些对文本的操作代码 print(line)# 相当于创建demo.txt文件，并写入数据，# demo文件原数据会被请客，追加的话模式修改为awith open('demo.txt','a') as file: file.write("demo"+'\n') CSV读写操作 第一种方法使用reader函数，接收一个可迭代的对象（比如csv文件），能返回一个生成器，就可以从其中解析出csv的内容。 第二种方法是使用DictReader，和reader函数类似，接收一个可迭代的对象，能返回一个生成器。这里版本不一样可能结果不一样，在版本3.6中更改：返回的行现在是类型OrderedDict， 测试的csv文件内容如下：12345No,Name,Age,Score1,mayi,18,992,jack,21,893,tom,25,954,rain,19,80 两种方法的读取的代码：1234567891011121314151617181920import csvwith open('demo.csv','r') as file: reader = csv.reader(file) for info in reader: print(info)with open('demo.csv','r') as file: reader = csv.DictReader(file) for info in reader: print(info)# output：# ['No', 'Name', 'Age', 'Score']# ['1', 'mayi', '18', '99']# ['2', 'jack', '21', '89']# ['3', 'tom', '25', '95']# ['4', 'rain', '19', '80']# OrderedDict([('No', '1'), ('Name', 'mayi'), ('Age', '18'), ('Score', '99')])# OrderedDict([('No', '2'), ('Name', 'jack'), ('Age', '21'), ('Score', '89')])# OrderedDict([('No', '3'), ('Name', 'tom'), ('Age', '25'), ('Score', '95')])# OrderedDict([('No', '4'), ('Name', 'rain'), ('Age', '19'), ('Score', '80')]) 数据写入csv的代码如下： csv.writer（csvfile，dialect =’excel’，** fmtparams ）返回一个编写器对象，负责将用户的数据转换为给定类文件对象上的分隔字符串。 csvwriter.writerow（row ）将行参数写入文件对象，根据当前的格式化设置。 在版本3.5中进行了更改：添加了对任意迭代的支持。csvwriter.writerows（row）将行中的所有元素（如上所述的行对象的迭代）写入文件对象，根据当前的格式化设置。 123456789101112131415# 注意这里的newline=''一定加上不然会多出空格with open('demo.csv','a',newline='') as file: write = csv.writer(file) write.writerow([5, 'yu', '26', '90']) write.writerows(['5', 'yu', '26', '90'])# Output,比如两者的区别# 1,mayi,18,99# 2,jack,21,89# 3,tom,25,95# 4,rain,19,805# 5,yu,26,90# 5# y,u# 2,6# 9,0 JSON读写操作见JSON的序列化操作 XLS文件操作 xlrd：是用来从Excel中读写数据的，但常用只进行读操作，写操作会遇到些问题。用xlrd进行读取比较方便，流程和平常手动操作Excel一样，打开工作簿(Workbook)，选择工作表(sheets)，然后操作单元格(cell)。常用操作： 1234567891011121314151617181920212223242526272829303132# 打开Excel工作簿data=xlrd.open_workbook(filename)#查看工作簿中所有sheet的名称data.sheet_names()# 选择某一个工作表（通过索引或表名称）#获取第一个工作表table=data.sheets()[0]#通过索引获取第一个工作表table=data.sheet_by_index(0)#通过表名称选择工作表table=data.sheet_by_name(u'哈哈')# 获取表格的行数和列数nrows=table.nrowsncols=table.ncols# 获取整行和整列的值table.row_values(number)table.column_values(number)# 通过循环读取表格的所有行for rownum in xrange(table.nrows): print table.row_values(rownum)# 获取单元格的值 cell_A1=table.row(0)[0].value#或者像下面这样cell_A1=table.cell(0,0).value#或者像下面这样通过列索引cell_A1=table.col(0)[0].value xlwt：如果说xlrd不是一个单纯的Reader（如果把xlrd中的后两个字符看成Reader，那么xlwt后两个字符类似看成Writer），那么xlwt就是一个纯粹的Writer了，因为它只能对Excel进行写操作。xlwt和xlrd不光名字像，连很多函数和操作格式也是完全相同。常用操作： 1234567891011# 新建一个Excel文件（只能通过新建写入）data=xlwt.Workbook()# 新建一个工作表table=data.add_sheet('name')# 写入数据到A1单元格table.write(0,0,u'呵呵')# 保存文件data.save('test.xls') openpyxl：该模块支持最新版的Excel文件格式，对Excel文件具有响应的读写操作，对此有专门的Reader和Writer两个类，便于对Excel文件的操作。常用操作： 12345678910111213141516171819202122232425#读取Excel文件from openpyxl.reader.excel import load_workbookwb=load_workbook(filename)# 显示工作表的索引范围wb.get_named_ranges()# 显示所有工作表的名字wb.get_sheet_names()# sheetnames = wb.get_sheet_names() ws = wb.get_sheet_by_name(sheetnames[0])# 获取表名ws.title# 获取表的列数ws.get_highest_column()#读取B1单元格中的内容ws.cell(0,1).value#当然也支持通过Excel坐标来读取数据，代码如下#读取B1单元格中的内容ws.cell("B1").value 写文件，只有一种操作方式，就是通过坐标。例如要向单元格C1写数据，就要用类似ws.cell(“C1”).value=something这样的方式。一般推荐的方式是用openpyxl中的Writer类来实现。代码类似下面这样： 12345678910111213141516171819202122232425262728from openpyxl.workbook import Workbook#ExcelWriter,里面封装好了对Excel的写操作from openpyxl.writer.excel import ExcelWriter #get_column_letter函数将数字转换为相应的字母，如1--&gt;A,2--&gt;B from openpyxl.cell import get_column_letter #新建一个workbook wb = Workbook() #新建一个excelWriter ew = ExcelWriter(workbook = wb) #设置文件输出路径与名称 dest_filename = r'empty_book.xlsx' #第一个sheet是ws ws = wb.worksheets[0] #设置ws的名称 ws.title = "range names"#向某个单元格中写入数据ws.cell("C1").value=u'哈哈'#最后保存文件ew.save(filename=dest_filename) 向某个单元格内写文件时要先知道它对应的行数和列数，这里注意行数是从1开始计数的，而列则是从字母A开始，因此第一行第一列是A1，这实际上是采用坐标方式操作Excel。 1234567891011121314151617from openpyxl import Workbookfrom openpyxl.cell import get_column_letterimport numpy as np#生成一个对角阵a=np.diag([1,2,3,4,5])#新建一个工作簿wb=Workbook()#使用当前激活的工作表（默认就是Excel中的第一张表）ws=wb.active#下面是对a的遍历，注意cell中行和列从1开始，a中索引从0开始。for row in xrange(1,a.shape[0]+1): for col in xrange(1,a.shape[1]+1): col_letter=get_column_letter(col) ws.cell('%s%s'%(col_letter,row)).value=a[row-1,col-1]wb.save('test.xlsx') Pandas：高效的数据科学处理库，将在后面详细的说明。 文件目录操作 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有关文件夹与文件的查找，删除等功能 在 os 模块中实现。使用时需先导入这个模块：import os常用的命令如下： 命令 作用 示例 os.getcwd() 取得当前目录 s=os.getcwd() os.makedirs(“path”) 创建子目录 os.makedirs(“C:\temp\test”) os.chdir(“path”) 更改当前目录 os.chdir(‘c:\‘) os.path.split(“path”) 将路径分解为目录名和文件名 a,b=os.path.splitext(“c:\dir1\dir2\file.txt”) os.path.exists(“path”) 判断一个路径（目录或文件）是否存在 os.path.exists(“c:\data\demo.txt”) os.path.isfile(“path”) 检验给出的路径是否是一个文件 os.path.isfile(“c:\data”) os.path.isdir(“path”) 检验给出的路径是否是一个目录 os.path.isfile(“c:\data”) os.listdir(“path”) 获取目录中的文件及子目录的列表 os.listdir(“C:\“) os.remove(“path”) 函数用来删除一个文件 os.remove(“d:\demo.txt”) os.path.dirname(“path”) 获取路径名 os.path.dirname(“c:\data\demo.txt”) os.path.basename(“path”) 获取文件名 os.path.dirname(“c:\data\demo.txt”) os.system(“shell”) 运行shell命令 os.system(‘ipconfig’) os.path.getsize（filename） 获取文件大小 os.path.getsize（”c:\demo.txt”） os.stat(file) 获取文件属性 os.stat(“c:\demo.txt”) os.rename(old， new) 重命名 os.rename(old， new) 序列化操作 概述现实需求&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每种编程语言都有各自的数据类型，就、其中面向对象的编程语言还允许开发者自定义数据类型（如：自定义类），Python也是一样。很多时候我们会有这样的需求： 把内存中的各种数据类型的数据通过网络传送给其它机器或客户端； 把内存中的各种数据类型的数据保存到本地磁盘持久化。序列化/反序列化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;序列化将对象转换为可通过网络传输或可以存储到本地磁盘的数据格式（如：XML、JSON或特定格式的字节串）的过程称；反之，则称为反序列化。 相关模块 模块名称 描述 提供的api json 实现Python数据类型与通用（json）字符串的转换 dumps()、dump()、load()、loads() pickle 实现Python数据类型与Python特定二进制格式之间的转换 dumps()、dump()、loads()、load() shelve 门用于将Python数据类型的数据持久化到磁盘，shelve是一个类似dict的对象，操作十分便捷 open() json模块序列化与反序列化Python的JSON模块序列化与反序列化的过程分别叫做：encoding 和 decoding。 encoding：把Python对象转换成JSON字符串。 decoding：把JSON字符串转换成python对象。 json模块提供了以下两个方法来进行序列化和反序列化操作：12345# 序列化：将Python对象转换成json字符串dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)# 反序列化：将json字符串转换成Python对象loads(s, encoding=None, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw) 除此之外，json模块还提供了两个额外的方法允许我们直接将序列化后得到的json数据保存到文件中，以及直接读取文件中的json数据进行反序列化操作：12345# 序列化：将Python对象转换成json字符串并存储到文件中dump(obj, fp, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, **kw)# 反序列化：读取指定文件中的json字符串并转换成Python对象load(fp, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw) Json与Python之间数据类型对应关系 注意事项 Python dict中的非字符串key被转换成JSON字符串时都会被转换为小写字符串； Python中的tuple，在序列化时会被转换为array，但是反序列化时，array会被转化为list； 由以上两点可知，当Python对象中包含tuple数据或者包含dict，且dict中存在非字符串的key时，反序列化后得到的结果与原来的Python对象是不一致的； 对于Python内置的数据类型（如：str, unicode, int, float, bool, None, list, tuple, dict）json模块可以直接进行序列化/反序列化处理；对于自定义类的对象进行序列化和反序列化时，需要我们自己定义一个方法来完成定义object和dict之间进行转化。 代码示例1234567891011121314151617181920212223242526272829import json# 序列化# python对象-&gt;josn的字符串demo = &#123;'h': '中国', 'a': 'sTr', 'c': True, 'e': 10, 'b': 11.1, 'd': None, 'f': [1, 2, 3], 'g': (4, 5, 6)&#125;print(type(demo), demo)print('python对象-&gt;josn的字符串:', )js_np = json.dumps(demo)print(type(js_np), js_np)js_p = json.dumps(demo, sort_keys=True, separators=(',', ';'),ensure_ascii=False,indent=4)print(type(js_p), js_p)# python对象-&gt;文件中with open('test.json', 'w', encoding='utf8') as file: json.dump(demo, file, indent=4, ensure_ascii=False) print("python对象-&gt;文件中",":保存成功！")# 反序列化# 文件对象-&gt;python对象with open('demo.json', 'r') as file: py_obj = json.load(file) print("文件对象-&gt;python对象:") print(type(py_obj), py_obj)# 字符串-&gt;python对象with open('demo.json', 'r') as file: str_in = file.readlines()[0] str_obj = json.loads(str_in) print("字符串-&gt;python对象:") print(type(str_obj), str_obj) 输出的结果如下：12345678910111213141516171819202122232425262728&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;sTr&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: (4, 5, 6)&#125;python对象-&gt;josn的字符串:&lt;class &apos;str&apos;&gt; &#123;&quot;h&quot;: &quot;\u4e2d\u56fd&quot;, &quot;a&quot;: &quot;sTr&quot;, &quot;c&quot;: true, &quot;e&quot;: 10, &quot;b&quot;: 11.1, &quot;d&quot;: null, &quot;f&quot;: [1, 2, 3], &quot;g&quot;: [4, 5, 6]&#125;&lt;class &apos;str&apos;&gt; &#123; &quot;a&quot;;&quot;str&quot;, &quot;b&quot;;11.1, &quot;c&quot;;true, &quot;d&quot;;null, &quot;e&quot;;10, &quot;f&quot;;[ 1, 2, 3 ], &quot;g&quot;;[ 4, 5, 6 ], &quot;h&quot;;&quot;中国&quot;&#125;python对象-&gt;文件中 :保存成功！文件对象-&gt;python对象:&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;str&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: [4, 5, 6]&#125;字符串-&gt;python对象:&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;str&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: [4, 5, 6]&#125;Process finished with exit code 0 输出的结果分析： pickle模块&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pickle模块实现了用于对Python对象结构进行序列化和反序列化的二进制协议，与json模块不同的是pickle模块序列化和反序列化的过程分别叫做pickling和unpickling： pickling：是将Python对象转换为字节流的过程； unpickling：是将字节流二进制文件或字节对象转换回Python对象的过程；pickle模块与json模块对比 JSON是一种文本序列化格式（它输出的是unicode文件，大多数时候会被编码为utf-8），而pickle是一个二进制序列化格式; JOSN是我们可以读懂的数据格式，而pickle是二进制格式，我们无法读懂； JSON是与特定的编程语言或系统无关的，且它在Python生态系统之外被广泛使用，而pickle使用的数据格式是特定于Python的； 默认情况下，JSON只能表示Python内建数据类型，对于自定义数据类型需要一些额外的工作来完成；pickle可以直接表示大量的Python数据类型，包括自定数据类型（其中，许多是通过巧妙地使用Python内省功能自动实现的；复杂的情况可以通过实现specific object API来解决）。pickle模块提供的相关函数pickle模块提供的几个序列化/反序列化的函数与json模块基本一致：1234567891011# 将指定的Python对象通过pickle序列化作为bytes对象返回，而不是将其写入文件dumps(obj, protocol=None, fix_imports=True)# 将通过pickle序列化后得到的字节对象进行反序列化，转换为Python对象并返回loads(bytes_object, fix_imports=True, encoding="ASCII", errors="strict")# 将指定的Python对象通过pickle序列化后写入打开的文件对象中，等价于`Pickler(file, protocol).dump(obj)`dump(obj, file, protocol=None,fix_imports=True)# 从打开的文件对象中读取pickled对象表现形式并返回通过pickle反序列化后得到的Python对象load(file, ix_imports=True, encoding="ASCII", errors="strict") Python 3.x的pickle代码示例123456789101112131415161718192021222324252627import pickle# 序列化# python对象-&gt;pickle的二进制demo = &#123;'h': '中国', 'a': 'sTr', 'c': True, 'e': 10, 'b': 11.1, 'd': None, 'f': [1, 2, 3], 'g': (4, 5, 6)&#125;print(type(demo), demo)print('python对象-&gt;pickle的二进制:', )js_p = pickle.dumps(demo)print(type(js_p), js_p)# python对象-&gt;文件中with open('pickle.txt', 'wb') as file: pickle.dump(demo, file,) print("python对象-&gt;文件中", ":保存成功！")# 反序列化# 文件对象-&gt;python对象with open('pickle.txt', 'rb') as file: py_obj = pickle.load(file) print("文件对象-&gt;python对象:") print(type(py_obj), py_obj)# 二进制-&gt;python对象with open('pickle.txt', 'rb') as file: str_obj = pickle.loads(file.read()) print("二进制-&gt;python对象:") print(type(str_obj), str_obj) 运行的结果：12345678910&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;sTr&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: (4, 5, 6)&#125;python对象-&gt;pickle的二进制:&lt;class &apos;bytes&apos;&gt; b&apos;\x80\x03&#125;q\x00(X\x01\x00\x00\x00hq\x01X\x06\x00\x00\x00\xe4\xb8\xad\xe5\x9b\xbdq\x02X\x01\x00\x00\x00aq\x03X\x03\x00\x00\x00sTrq\x04X\x01\x00\x00\x00cq\x05\x88X\x01\x00\x00\x00eq\x06K\nX\x01\x00\x00\x00bq\x07G@&amp;333333X\x01\x00\x00\x00dq\x08NX\x01\x00\x00\x00fq\t]q\n(K\x01K\x02K\x03eX\x01\x00\x00\x00gq\x0bK\x04K\x05K\x06\x87q\x0cu.&apos;python对象-&gt;文件中 :保存成功！文件对象-&gt;python对象:&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;sTr&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: (4, 5, 6)&#125;字符串-&gt;python对象:&lt;class &apos;dict&apos;&gt; &#123;&apos;h&apos;: &apos;中国&apos;, &apos;a&apos;: &apos;sTr&apos;, &apos;c&apos;: True, &apos;e&apos;: 10, &apos;b&apos;: 11.1, &apos;d&apos;: None, &apos;f&apos;: [1, 2, 3], &apos;g&apos;: (4, 5, 6)&#125;Process finished with exit code 0 注意点： 读写时记得模式加上b shelve模块&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shelve是一个简单的数据存储方案，类似key-value数据库，可以很方便的保存python对象，其内部是通过pickle协议来实现数据序列化。shelve只有一个open()函数，这个函数用于打开指定的文件（一个持久的字典），然后返回一个shelf对象。shelf是一种持久的、类似字典的对象。它与“dbm”的不同之处在于，其values值可以是任意基本Python对象–pickle模块可以处理的任何数据。这包括大多数类实例、递归数据类型和包含很多共享子对象的对象。keys还是普通的字符串。1open(filename, flag='c', protocol=None, writeback=False) flag 参数表示打开数据存储文件的格式； protocol 参数表示序列化数据所使用的协议版本，默认是pickle v3； writeback 参数表示是否开启回写功能。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以把shelf对象当dict来使用–存储、更改、查询某个key对应的数据，当操作完成之后，调用shelf对象的close()函数即可。当然，也可以使用上下文管理器（with语句），避免每次都要手动调用close()方法。代码示例123456789101112import shelve# 保存数据with shelve.open('student') as db: db['name'] = 'Tom' db['age'] = 19 db['hobby'] = ['篮球', '看电影', '弹吉他'] db['other_info'] = &#123;'sno': 1, 'addr': 'china'&#125;# 读取数据with shelve.open('student') as db: for key, value in db.items(): print(key, ': ', value) 结果显示：123456name : Tomage : 19hobby : [&apos;篮球&apos;, &apos;看电影&apos;, &apos;弹吉他&apos;]other_info : &#123;&apos;sno&apos;: 1, &apos;addr&apos;: &apos;china&apos;&#125;Process finished with exit code 0 自定义数据类型操作12345678910111213141516171819202122# 自定义classclass Student(object): def __init__(self, name, age, sno): self.name = name self.age = age self.sno = sno def __repr__(self): return 'Student [name: %s, age: %d, sno: %d]' % (self.name, self.age, self.sno)# 保存数据tom = Student('Tom', 19, 1)jerry = Student('Jerry', 17, 2)with shelve.open("stu.db") as db: db['Tom'] = tom db['Jerry'] = jerry# 读取数据with shelve.open("stu.db") as db: print(db['Tom']) print(db['Jerry']) 结果显示：12Student [name: Tom, age: 19, sno: 1]Student [name: Jerry, age: 17, sno: 2] 总结对比 json模块常用于编写web接口，将Python数据转换为通用的json格式传递给其它系统或客户端；也可以用于将Python数据保存到本地文件中，缺点是明文保存，保密性差。另外，如果需要保存非内置数据类型需要编写额外的转换函数或自定义类。 pickle模块和shelve模块由于使用其特有的序列化协议，其序列化之后的数据只能被Python识别，因此只能用于Python系统内部。另外，Python 2.x 和 Python3.x 默认使用的序列化协议也不同，如果需要互相兼容需要在序列化时通过protocol参数指定协议版本。除了上面这些缺点外，pickle模块和shelve模块相对于json模块的优点在于对于自定义数据类型可以直接序列化和反序列化，不需要编写额外的转换函数或类。 shelve模块可以看做是pickle模块的升级版，因为shelve使用的就是pickle的序列化协议，但是shelve比pickle提供的操作方式更加简单、方便。shelve模块相对于其它两个模块在将Python数据持久化到本地磁盘时有一个很明显的优点就是，它允许我们可以像操作dict一样操作被序列化的数据，而不必一次性的保存或读取所有数据。 建议 需要与外部系统交互时用json模块； 需要将少量、简单Python数据持久化到本地磁盘文件时可以考虑用pickle模块； 需要将大量Python数据持久化到本地磁盘文件或需要一些简单的类似数据库的增删改查功能时，可以考虑用shelve模块。 方法总览 参考链接 1.Python之文件读写2.python3 writerow CSV文件多一个空行3.python写入csv文件的几种方法总结4.Python 读取csv的某行5.csv模块的使用6.使用Python对Csv文件操作7.Python读写txt、csv文件8.python3（十三）File对象的属性9.Python3基础（七） I/O操作10.Python文件操作详解11.CSV文件读取和写入12.Python操作excel的几种方式–xlrd、xlwt、openpyxl13.关于python文件操作14.python学习笔记（七）——文件和目录操作15.Python之数据序列化（json、pickle、shelve）16.Python序列化和反序列化17.序列化Python对象]]></content>
      <categories>
        <category>Python语言</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>文件操作</tag>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据分析（四）——挖掘建模]]></title>
    <url>%2F2018%2F06%2F27%2F%E6%8C%96%E6%8E%98%E5%BB%BA%E6%A8%A1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;经过数据探索与数据预处理，得到了可以直接建模的数据。根据挖掘目标和数据形式可以建立分类与预测、聚类分析、关联规则、时序模式和离群点识别等模型。 分类与预测 分类和预测是预测问题的两种主要类型： 分类主要是预测分类标号（离散属性）； 预测主要是建立连续值函数模型，预测给定自变量对应因变量的值。监督学习的框架图 实现过程 分类是构造一个分类模型，输入样本的属性值，输出对应的类别，将每个样本映射到预先定义好的类别。垃圾邮件的过滤 After the system has been trained to identify emails, when new emails strike your inbox, it’ll automatically be classified as spam or not spam.Classification problems, requires items to be divided into different categories, based on past data. In a way, we’re solving a yes/no problem. Whether something meets its required standards, or whether it’s broken or not and so on. 训练一个识别垃圾邮件的系统,当系统接受到新邮件，将会自动的对新邮件进行是否是垃圾邮件的分类。分类问题是基于过去的数据，将事物划分成不同的类别，总而言之，有点类似“是”或“不是”的问题。或者某件事物是符合标准的还是不符合标准的等等。 预测是指建立两种或两种以上变量间相互依赖的函数模型，然后进行预测或控制天气的预测 Now with regression problem, the system attempts to predict a value for an input based on past data. You see, unlike classification, we’re predicting a value based on past data, rather than classifying them into different categories. Say you wanted to predict whether it would rain, and if it does, how much rain you would get. 对于回归问题，系统基于过去的数据输入，期望预测出一个值。不同于分类，我们基于数据预测的值，而不是将其划分成不同的类别。想预测是否会下雨,如果会下雨,将会得到多少雨量。 两者的区别 :fa-quora:上Waleed Kadous给出的答案： The key difference is that the output.For classification is one of a discrete set (e.g. “what type of fruit is this?” or “what medical condition is the person suffering from?”)For regression the output is a continuous number (e.g. “what’s the expected amount the stock market will go up or down today?” or “how carcinogenic is this compound?”).A special case of regression is when the output is not just any number, but a number between 0 and 1 where 0 means “this is not going to happen” to 1 being “this will definitely happen”.Some learning algorithms are targeted at one, others at the other. Many of them have the same core algorithm, but with minor modifications – e.g. decision trees can be easily modified to support regression instead. Andrew Ng的Machine Learning课程给出两者的解释: Supervised learning problems are categorized into “regression” and “classification” problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in adiscrete output. In other words, we are trying to map input variables into discrete categories. 总结一下：分类模型和回归模型本质一样，分类模型可将回归模型的输出离散化，回归模型也可将分类模型的输出连续化。 常用的分类和预测算法 回归分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;回归分析是通过建立模型来研究变量之间相互关系的密切程度、结构状态及进行模型预测的一种有效工具，在工商管理、经济、社会、医学和生物学等领域应用十分广泛。从19世纪初高斯提出最小二乘估计起，回归分析的历史已有200多年。从经典的回归分析方法到近代的回归分析方法，安装研究方法划分，回归分析研究的范围大致如下。回归模型 主要回归模型 决策树&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;决策树方法在分类、预测、规则提取等领域有着广泛的应用。决策树是一种树状结构，它的每一个叶节点对应着一个分类，非叶节点对应着在某个属性上的划分，根据样本在该属性上的不同取值将其划分成若干个子集。对于非纯的叶节点，多数类的标号给出到达这个节点的样本所属的类。构造决策树的核心问题是在每一步如何选择适当的属性对样本做拆分。对于一个分类问题，从已知标记的训练样本中学习并构造出决策树是一个自上而下，分而治之的过程。 人工神经网络&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工神经网络（ANN）,是模拟生物神经网络进行信息处理的一种数学模型。它以大脑的生理研究成果为基础，其目的在于模拟大脑的某些机理与机制，实现一些特定的功能。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;人工神经紊乱的学习也成为训练，指的是神经网络在受到外部环境的刺激下调整神经网络的参数，是神经网络以一种新的方式对外部环境做出反应的一个过程。在分类与预测中，人工神经网络主要使用有指导的学习方式，即给定的训练样本，调整人工神经网络的参数使网络输出接近于已知的样本标记或其它形式的因变量。神经元模型 激活函数：就是将权值结果转化成分类结果 常见神经网络 算法评价&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分类与预测模型对训练集进行预测而得出的准确率并不能很好地反映预测模型未来的泛化能力，为了有效判断一个预测模型的性能表示，需要一组咩有参予预测模型建立的数据集，并在该数据集上评价预测模型准确率，这组独立的数据集叫作测试集。 回归指标 绝对误差和相对误差设$Y$表示实际值，$\bar{Y}$表示预测值，则称$E$为绝对误差（Absolute Error），计算公式如下：$$E=Y-\bar{Y}$$$e$为相对误差（Relative Error），计算公式如下$$e=\frac{Y-\bar{Y}}{Y}*100\%$$这是一种直观的误差表示方法。 平均绝对误差（MeanAbsoluter，MAE）定义如下：$$MAE=\frac{1}{n}\sum_{i=1}^{n}|E_{i}|=\sum_{i=1}^{n}|Y_{i}-\bar Y_{i}|$$式中的各项含义如下： $MAE:$平均绝对误差。 $E_{i}:$第i个实际值与预测值的绝对误差。 $Y_{i}:$第i个实际值。 $\bar Y_{i}:$第i个预测值。由于误差有正负，为了避免正负相抵销，故取误差的绝对值进行综合并取其平均数，这是误差分析的综合指标之一。 均方误差（Mean Squared Error，MSE）定义如下：$$MSE=\frac{1}{n}\sum_{i=1}^{n}E_{i}^{2}=\frac{1}{n}\sum_{i=1}^{n}(Y_{i}-\bar Y_{i})^{2}$$在上式中，$MSE$表示均方差，其他符号同前。均方误差是预测误差平方之和的平均数，它避免了正负误差不能相加的问题。由于对误差$E$进行了平方，加强了数值大的误差在指标中的作用，从而提高了这个指标的灵敏度，是一大优点。均方误差是误差分析的综合指标之一。 均方根误差（Root Mean Squared Error，RMSE）定义如下。$$RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{2}E_{i}^2}=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(Y_{i}-\bar Y_{i})^2}$$上式中，$RMSE$表示均方根误差，其他符合同前。这是均分误差的平方根，代表了预测值的离散程度，也称为标准误差，最佳拟合情况为$RMSE$=0。均方根误差也是误差分析的综合指标之一。 平均绝对百分误差（平均绝对百分误差Mean Absolute Percentage Error，MAPE）定义如下：$$MAPE=\frac{1}{n}\sum_{i=1}^{n}|\frac{E_{i}}{Y_{i}}|=\frac{1}{n}\sum_{i=1}^{n}|\frac{Y_{i}-\bar Y{i}}{Y_{i}}|$$上式中，$MAPE$表示平均绝对百分误差。一般认为$MAPE$小于10时，预测精度较高。分类指标 Kappa统计&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Kappa统计是比较两个或多个观测者对同一事物，或观测者对同一事物的两次或多次观测结果是否一致，以由于机遇造成的一致性和实际观测的一致性之间的差别大小作为评价基础的统计指标。Kappa统计量和加权统计量不仅可以用于无序和有序分类变量资料的一致性、重现性检验，而且能给出一个反映一致性大小的“量”值。 不带加权的Kappa值 $$Kappa=\frac{P_{0}-P_{e}}{1-P_{e}},P_{0}=\frac{a+d}{n},P_{e}=\frac{(a+b)(a+c)+(c+d)(b+d)}{n^2}$$ PRF值 Accuracy(精度)：预测正确的比例，$$Accuracy=\frac{TP+TN}{P+N}$$ TP rate(真正率)-ROC的Y轴：$$TPR=\frac{TP}{P}$$ FP rate(假正率)-ROC的X轴：$$FPR=\frac{FP}{N}$$ Precision(准确率)：预测值是Positive的集合中，真正是Positive的比例:$$Precision=\frac{TP}{TP+FN}$$ Recall(召回率)：观测值为Positive的集合中，被正确判定为Positive的比例:$$recall=\frac{TP}{P}$$ F值：融合准确度和召回率，$$F-measure=\frac{1}{\frac{1}{precision}+\frac{1}{recall}}$$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图这些都属于静态的指标，当正负样本不平衡时它会存在着严重的问题。极端情况下比如正负样本比例为1:99（这在有些领域并不少见），那么一个基 准分类器只要把所有样本都判为负，它就拥有了99%的精确度，但这时的评价指标是不具有参考价值的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外就是，现代分类器很多都不是简单地给出一个0或1的分类判定，而是给出一个分类的倾向程度，比如贝叶斯分类器输出的分类概率。对于这些分类器，当你取不同阈值，就可以得到不同的分类结果及分类器评价指标，依此人们又发明出来ROC曲线以及AUC（曲线包围面积）指标来衡量分类器的总体可信度。 ROC曲线&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;受试者工作特征（Receiver Operating Chatacteristic，ROC）曲线是一种非常有效的模型评价方法，可为选定临界值给出定量提示。将灵敏度（Sensitivity）设在纵轴，特异性（Specificity）设在横轴，就可得出ROC曲线图。该曲线下的积分面积（Area）大小与每种方法优劣密切相关，反映分类器正确分类的统计概率，其值越接近1说明算法效果越好。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在一个二分类模型中，对于所得到的连续结果，假设已确定一个阀值，比如说 0.6，大于这个值的实例划归为正类，小于这个值则划到负类中。如果减小阀值，减到0.5，固然能识别出更多的正类，也就是提高了识别出的正例占所有正例的比类，即TPR,但同时也将更多的负实例当作了正实例，即提高了FPR。为了形象化这一变化，在此引入ROC，ROC曲线可以用于评价一个分类器。 （a）中可以看出，在理想情况下，TPR应该接近1，FPR应该接近0。ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=0，对应于右上角的点(1,1)（b）中显示，随着阈值$\theta$增加，TP和FP都减小，TPR和FPR也减小，ROC点向左下移动。 Python分类预测模型的特点 模型 模型特点 位于 逻辑回归 比较基础的线性分类模型，很多时候是简单有效的选择 sklearn.linear_model 决策树 强大的模型，可以用来回归、预测、分类等，而更具选取不同的核函数。模型可以是线性/非线性的 sklearn.svm 决策树 基于“分类讨论、逐步细化”思想的分类模型，模型直观，易解释。 sklearn.tree 随机森林 思想跟决策树类似，精度通常比决策树要高，缺点是由于其随机性，丧尸了决策树的可解释性。 sklearn.ensemble 朴素贝叶斯 基于概率思想的简单有效的分类模型，能够给出容易理解的概率解释 sklearn.naive_bayes 神经网络 具有强大的拟合能力，可以用于拟合、分类等，它有很多增强版本，如递归神经网络、卷积神经网络、自编码器等，这些是深度学习的模型基础 Keras 聚类分析聚类分析框架 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;与分类不同，聚类分析是在没有给定划分类别的情况下，根据数据相似度进行样本分组的一种方法。与分类模型需要使用有类别标记样本构成的训练数据不同，聚类模型可建立在无类别标记的数据上，是一种非监督的学习算法。聚类的输入是一组未被标记的样本，聚类根据数据自身的距离或相似度将其划分为若干组，划分的原则是组内距离最小化而组间距离最大化。聚类分析原理 距离或相似度度量&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据数据特性的不同，可以采用不同的度量方法。一般而言，定义一个距离函数 $d(x,y)$, 需要满足下面几个准则： $d(x,x) = 0$ ，到自己的距离为0 $d(x,y) &gt;= 0$ ，距离非负 $d(x,y) = d(y,x)$ ，对称性:如果A到B距离是 a，那么B到A的距离也应该是a $d(x,k)+ d(k,y) &gt;= d(x,y)$ ，三角形法则：(两边之和大于第三边) 闵可夫斯基距离（连续属性）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;闵可夫斯基距离（Minkowski distance）是衡量数值点之间距离的一种非常常见的方法，假设数值点 $P$ 和 $Q$ 坐标如下：$$P=(x_{1},x_{1},…,x_{n}) and Q=(y_{1},y_{1},…,y_{n})$$那么，闵可夫斯基距离定义为：$$d(P,Q)=(\sum_{i=1}^{n}|x_{i}-y_{i}|^p)^\frac{1}{n}$$ 当p=1，是曼哈顿距离（Manhattan distance）。 当p=2，是欧几里得距离（Euclidean distance）。假设在曼哈顿街区乘坐出租车从 $P $点到$ Q $点，白色表示高楼大厦，灰色表示街道： 绿色的斜线表示欧几里得距离，在现实中是不可能的。其他三条折线表示了曼哈顿距离，这三条折线的长度是相等的。当$p$趋近于无穷大时，闵可夫斯基距离转化成切比雪夫距离（Chebyshev distance）：$$\lim_{p\rightarrow \infty}(\sum_{i=1}^{n}|x_{i}-y_{i}|^p)^\frac{1}{p}=\overset{n}{\underset{i=1}{max}}|x_{i}-y_{i}|$$我们知道平面上到原点欧几里得距离（p = 2）为 1 的点所组成的形状是一个圆，当 p 取其他数值的时候呢？ 注意：当$ p &lt; 1$ 时，闵可夫斯基距离不再符合三角形法则，举个例子：当 $p &lt; 1$, (0,0) 到 (1,1) 的距离等于 $(1+1)^{1/p} &gt; 2$, 而 (0,1) 到这两个点的距离都是1，因此不能取值小于1的p值作为距离度量。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;闵可夫斯基距离比较直观，但是它与数据的分布无关，具有一定的局限性，如果 $x $方向的幅值远远大于 $y $方向的值，这个距离公式就会过度放大 $x $维度的作用。所以，在计算距离之前，我们可能还需要对数据进行 z-transform 处理，即减去均值，除以标准差：$$(x_{1}-y_{1})\rightarrow(\frac{x_{1}-\mu_{x}}{\sigma_{x}},\frac{y_{1}-\mu_{y}}{\sigma_{y}})$$ $\mu$：该维度上的均值。 $\sigma$：该维度上的标准差。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，上述处理开始体现数据的统计特性了。这种方法在假设数据各个维度不相关的情况下利用数据分布的特性计算出不同的距离。如果维度相互之间数据相关（例如：身高较高的信息很有可能会带来体重较重的信息，因为两者是有关联的，此距离就失效。 向量内积（离散向量化属性）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;量内积是线性代数里最为常见的计算，实际上它还是一种有效并且直观的相似性测量手段。向量内积的定义如下：$$Inner(x,y)=&lt;x,y&gt;=\sum_{i}x_{i}y_{i}$$向量内积的结果是没有界限的，一种解决办法是除以长度之后再求内积，这就是应用十分广泛的余弦相似度（Cosine similarity）：$$CosSim(x,y)=\frac{\sum_{i}x_{i}y_{i}}{\sqrt{\sum_{i}x_{i}^2}\sqrt{\sum_{i}y_{i}^2}}=\frac{&lt;x,y&gt;}{||x||||y||}$$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;余弦相似度与向量的幅值无关，只与向量的方向相关.需要注意一点的是，余弦相似度受到向量的平移影响，上式如果将 x 平移到 x+1, 余弦值就会改变。怎样才能实现平移不变性？这就是下面要说的皮尔逊相关系数（Pearson correlation），有时候也直接叫相关系数:$$Corr(x,y)=\frac{\sum_{i}(x_{i}-\bar x)(y_{i}-\bar y)}{\sqrt{\sum_{i}(x_{i}-\bar x)^2}\sqrt{\sum_{i}(y_{i}-\bar y)^2}}=CosSim(x-\bar x)(y-\bar y)$$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;皮尔逊相关系数具有平移不变性和尺度不变性，计算出了两个向量（维度）的相关性。不过，一般我们在谈论相关系数的时候，将 x 与 y 对应位置的两个数值看作一个样本点，皮尔逊系数用来表示这些样本点分布的相关性。 常用的聚类分析算法 算法名称 算法描述 K-Means K-均值聚类也称为快速聚类法，在最小化误差函数的基础上将数据划分为预定的类数K。该算法原理简单并便于处理大量数据。 K-中心点 K-均值算法对孤立点的敏感性，K-中心点算法不采用簇中对象的平均值作为簇中心，而选用簇中离平均值最佳的对象作为簇中心。 系统聚类 系统聚类也称为层次聚类，分类的单位由高到低呈树形结构，且所处的位置越低，其所包含的对象就越少，但这些对象间的共同特征越多。该聚类方法只适合在小数据量的时候使用，数据量大的时候速度会非常慢。 聚类分析算法评价&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;聚类分析仅根据样本数据本身将样本分组。其目标是组内的对象相互之间是相似的（相关的），而不同组中的对象时不同的（不相关的）。组内的相似性越大，组间差别越大，聚类效果就越好。 purity评价法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purity方法是极为简单的一种聚类评价方法，只需计算正确聚类占总数的比例。$$purity(X,Y)=\frac{1}{n}\sum_{k}max|x_{k}\bigcap y_{k}|$$其中，$x=(x_{1},x_{2},…,x_{k})$是聚类的集合。$x_{k}$表示第$k$个聚类的集合。$y=(y_{1},y_{2},…,y_{k})$表示需要被聚类的集合，$y_{i}$表示第$i$个聚类对象。$n$表示被聚类集合对象的总数。 RI评价法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实际上，这是一种用排列组合原理来对聚类进行评价的手段，RI评价公式如下：$$RI=\frac{R+W}{R+M+D+W}$$其中， R是指被聚在一类的两个对象被正确的分类。 W是指不应该被聚在一类的两个对象被正确分开。 M指不应该放在一类的对象被错误的放在了一类。 D值不应该分开的对象被错误的分开。 F值评价法这是基于RI方法衍生出的一个方法，F评价公式如下：$$F_{\alpha}=\frac{(1+\alpha^{2})pr}{\alpha^2p+r}$$其中，$p=\frac{R}{R+M},r=\frac{R}{R+D}$&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实际上$RI$方法就是把准确率$p$和召回率$r$看得同等重要，事实上，有时候我们可能需要某一特性更多一点，这时候就适合使用$F$值方法。 Python主要聚类分析算法 对象名 函数功能 所属工具箱 KMeans K均值 sklearn.cluster AffinityPropagation 吸引力传播聚类，2007提出，几乎优于所有其他方法，不需要指定聚类数，但运行效率较低 sklearn.cluster MeanShift 均值漂移聚类算法 Clustering Spectral 谱聚类，具有效果比均值好，速度比K均值快等特点 sklearn.cluster AgglomeartiveClustering 层次聚类，给出一棵聚类层次树 sklearn.cluster DBSCAN 具有噪声的基于密度的聚类方法 sklearn.cluster BIRCH 综合的层次聚类算法，可处理大规模数据的聚类 sklearn.cluster 关联规则 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关联规则分析也称购物篮分析，最早是为了发现超市销售数据库中不同的商品之间的关联关系。例如，一个超市的经理想要更多地了解顾客的购物习惯，比如“哪组商品可能会在一次购物中同时购买？”或者“某顾客购买了个人电脑，那该顾客三个月后购买数码相机的购率有多大？”他可能会发现如果购买了面包的顾客同时非常有可能会购买牛奶，这就导出了一条关联规则“面包=&gt;牛奶”，其中面包称为规则的前项，而牛奶称为后项。通过对面包降低售价进行促销，而适当提高牛奶的售价，关联销售的牛奶就有可能增加超市整体的利润。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关联规则分析是数据挖掘中最活跃的研究方法之一，目的是在一个数据集中找出各项之间的关联关系，而这种关系并没有在数据中直接表示出来。 常用关联规则算法 算法名称 算法描述 Apriori 关联规则最常用也是最经典的挖掘频繁项集的算法，其核心思想是通过连接产生候选项及其支持度然后通过剪枝生成频繁项集。 FP-Tree 针对Apriori算法的固有的多次扫描事物数据集的缺陷，提出的不产生候选频繁项集的方法。Apriori和FP-Tree都是寻找频繁项集的算法。 Eclat算法 Eclat算法是一种深度优先算法，采用垂直数据表示形式，在概念格理论的基础上利用基于前缀的等价关系将搜索空间划分为较小的子空间。 灰色关联法 分析和确定各因素之间的影响程度或是若干个因素（子序列）对主因素（母序列）的贡献度而进行的一种分析方法。 关联规则和频繁项集 关联规则的一般形式项集A、B同时发生的概率称为关联规则的支持度（也称相对支持度）$$Support(A=&gt;B)=P(A\bigcup B)$$项集A发现，则项集B发现的概率为关联规则的置信度。$$Confidence(A=&gt;B)=P(B|A)$$ 最小支持度和最小置信度最小支持度是用户或专家定义的衡量支持度的一个阈值，表示项目集在统计意义上的最低重要性；最小置信度是用户或专家定义衡量置信度的一个阈值，表示关联规则的最低可靠性。同时满足最小支持度阈值和最小置信度阈值的规则称为强规则。 项集项集是项的集合。包含$k$个项的项集称为$k$项集，如集合{牛奶，麦片，糖}是一个3项集。项集出现频率是所有包含项集的事物计数，又称作绝对支持度或支持度计数。如果项集I的相对支持度满足预定义的最小支持度阈值，则I是频繁项集。频繁$k$项集通常记作$k$。 支持度计数项集A的支持度计数是事物数据集中包含项集A的事物个数，简称为项集的频率或计数。已知项集的支持度计数，则规则A=&gt;B的支持度和置信度很容易从所有事物计数、项集A和项集$A\bigcup B$的支持度计数推出。$$Support(A=&gt;B)=\frac{Support-count(A\bigcap B)}{Total-count(A)}$$$$Confidence(A=&gt;B)=P(A|B)=\frac{Support-count(A\bigcap B)}{Support-count(A)}$$也就是说，一旦得到所有事物个数，A,B和$A\bigcap B$的支持度计数，就可以导出对应的关联规则A=&gt;B和B=&gt;A，并可以检查该规则是否是强规则。 时序模式 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;常用按时间顺序排列的一组随机变量$X_{1},X_{2},…,X_{t}$来表示一个随机时间的时间序列，简记为$X_{t}$：用$x_{1},x_{2},…,x_{n}$或${x_{t},t=1,2,…,n}$表示该随机序列的$n$个有序观察值，称之为序列长度为$n$的观察值序列。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;时间训练分析的目的就是给定一个已被观测了的时间序列，预测该序列的未来值。 常用时间序列模型 模型名称 描述 平滑法 平滑法常用于趋势分析和预测，利用修匀技术，削弱短期随机波动对序列的影响，是序列平滑化。根据所用平滑技术的不同，可具体分为移动平均和指数平滑化。 趋势拟合法 趋势拟合法把时间作为自变量，相应的序列观察值作为因变量，建立回归模型。根据序列的特征，可具体分为线性拟合和曲线拟合。 组合模型 时间序列的变化主要受到长期趋势（$T$）、季节变动（$S$）、周期变动（$C$）和不规则变动（$\varepsilon$）这4个因素的影响。根据序列的特点，可以构建加法模型和乘法模型加法模型：$$x_{t}=T_{t}+S_{t}+C_{t}+\varepsilon_{t}$$乘法模型：$$x_{t}=T_{t}\times S_{t}\times C_{t}\times \varepsilon_{t}$$ AR模型 $$x_{t}=\phi_{0}+\phi_{1}x_{t-1}+\phi_{2}x_{t-2}+…+\phi_{p}x_{t-p}+\varepsilon_{t}$$以前p期的序列值$x_{t-1},x_{t-2},…,x_{t-p}$为自变量、随机变量$X_{t}$的取值$x_{t}$为因变量建立线性回归模型 MA模型 $$x_{t}=\mu+\varepsilon_{t}-\theta_{1}\varepsilon_{t-1}-\theta_{2}\varepsilon_{t-2}-…-\theta_{q}\varepsilon_{t-q}$$随机变量$X_{t}$的取值$x_{t}$与以前各期的序列值无关，建立$x_{t}$与前$q$期的随机扰动$\varepsilon_{t-1},\varepsilon_{t-2},…,\varepsilon_{t-q}$ ARMA模型 $$x_{t}=\phi_{0}+\phi_{1}x_{t-1}+\phi_{2}x_{t-2}+…+\phi_{p}x_{t-p}+\varepsilon_{t}-\theta_{1}\varepsilon_{t-1}-\theta_{2}\varepsilon_{t-2}-…-\theta_{q}\varepsilon_{t-q}$$随机变量$X_{t}$的取值$x_{t}$不仅与以前$p$期的序列值有关，还与前$q$期的随机扰动有关 ARIMA模型 许多非平稳序列差分后会显示出平稳序列的性质，称这个非平稳序列为差分平稳序列。对差分平稳序列可以使用ARIMA模型进行拟合 ARCH模型 ARCH模型能够准确地模拟时间序列变量的波动性的变化，适用于序列具有异方差性并且异方差函数短期自相关 GARCH模型及其衍生模型 GARCH模型称为广义ARCH模型，是ARCH模型的拓展。相比于ARCH模型，GARCH模型及其衍生模型更能反映实际序列中长期记忆性、信息的非对称性等性质。 时间序列的预处理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;拿到一个观测值序列后，首先对它的纯随机性和平稳性进行检验，这两个重要的检验称为序列的预处理。根据检验的结果可以将序列氛围不同的类型，对不同类型的序列会采用不同分析方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于纯随机序列，又称为白噪声序列，序列的各项之间没有任何相关关系，序列在进行完全无序的随机波动，可终止对该序列的分析。白噪声序列是没有信息可以提取的平稳序列。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于非平稳非白噪声序列，它的均值和方差是常数，现已有一套非常成熟的平稳序列的建模方法。通常是建立一个线性模型来拟合该序列的发展，借此提取该序列的有用信息。ARMA模型时最常用的平稳序列拟合模型。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于非平稳序列，由于它的均值和方差不稳定，处理方法一般是将其转变为平稳序列，这样就可以应用有关平稳序列差分运算后具有平稳性，则该序列为差分平稳序列，可以使用ARIMA模型进行分析。 平稳性检验 平稳时间序列的定义&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于随机变量$X$,可以计算其均值（数学期望）$\mu$、方差$\sigma^{2}$；对于两个随机变量X和Y，可以计算$X,Y$的协方差$$cov(X,Y)=E[(X-\mu_{X})(Y-\mu_{Y})]$$ 和相关系数 $$\rho (X,Y)=\frac{cov(X,Y)}{\sigma ^{X}\sigma ^{Y}}$$,它们度量了两个不同事件之间的相互影响程度。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于时间序列${X_{t},t\in T}$,任意时刻的序列值$X_{t}$都是一个随机变量，每一个随机变量，每一个随机变量都会有均值和方差，记$X_{t}$的均值为$\mu_{t}$，方差为$\sigma_{t}$;任取$t,s\in T$,定义序列${X_{t}}$的自协方差函数$$\gamma(t,s)=E[(X_{t}-\mu_{t})(Y_{s}-\mu_{s})]$$和自相关系数$$\rho(t,s)=\frac{cov(X_{t},Y_{t})}{\sigma_{t}\sigma_{s}}$$之所以称它们为自协方差函数和自相关函数，是因为他们衡量的是同一个事件在两个不同时期（时刻t和s）之间的相关程度，形象地讲就是度量自己过去的行为对自己现在的影响。 平稳性的检验&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对序列的平稳性的检验有两种方法， 一种是根据时序图和自相关图的特征作出判断的图检验，该方法操作简单、应用广泛，缺点是带有主观性； 另一种是构造检验统计量进行检验的方法，目前最常用的方法是单位根检验。 纯随机性检验&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果一个序列是纯随机序列，那么它的序列值之间应该没有任何关系，即满足$\gamma(k)=0,k\neq0$这是一种理论上才会出现的假想状态，实际上纯随机序列的样本自相关系数不会绝对为零，但是很接近零，并在零附近随机波动。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;纯随机性检验也称白噪声检验，一般是构造检验统计量来检验序列的纯随机性，常用的检验统计量$Q$统计量、$LB$统计量，由于样本个延迟期数的自相关系数可以计算得到检验统计量，然后计算出对应的$p$的值，如果$p$的值显著大于显著性水平$\alpha$,则表示该序列不能拒绝纯随机的原假设，可以停止对该序列的分析。 Python主要时序模式算法 函数名 函数功能 所属工具箱 acf() 计算自相关系数 statsmodels.tsa.stattools plot_acf() 画自相关系数图 statsmodels.graphics.tsaplots pacf() 画偏相关系数图 statsmodels.graphics.tsaplots adfuller() 对观测值序列进行单位根检验 statsmodels.tsa.stattools diff() 对观测值序列进行差分计算 Pandas对象自带的方法 ARIMA() 创建一个ARIMA时序模型 statsmodels.tsa.arima_model summary() ARIMA模型对象报告 ARIMA模型对象自带方法 aic/bic/hqic() 计算ARIMA模型的AIC/BIC/HQIC指标值 ARIMA模型对象自带方法 forecast() 应用构建的时序模型进行预测 ARIMA模型对象自带方法 acor_ljungbox() Ljung-Box检验，检验是否是白噪声 statsmodels.stats.diagnoostic 离群点检测 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;离群点检测是数据挖掘中重要的一部分，它的任务是发现与大部分其他对象显著不同对象。大部分数据挖掘方法都将这种差异信息视为噪声而丢弃，然而在一些应用中，罕见的数据可能蕴含着更大的研究价值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;离群点检测已经被广泛应用于电信和信用卡的诈骗检测、贷款审批、电子商务、网络入侵和天气预报等领域。例如，可以利用离群点检测分析运动员的统计数据，以发现异常的运动员。 离群点的成因离群点主要成因有：数据来源于不同的类、自然变异、数据测量和搜集误差。 离群点的类型 全局离群点和局部离群点 数据型离群点和分类型离群点 一维离群点和多维离群点 常用离群点检测方法 离群点检测方法 方法描述 方法 基于统计 大部分的基于统计的离群点检测方法是构建一个概率分布模型，并计算对象符合模型概率，把具有低概率的对象视为离群点。 基于统计模型的利群带你检测方法的前提是必须知道数据集服从什么分布；对于高维数据，检验效果可能很差 基于邻近度 通常可以在数据对象之间定义邻近性度量，把远离大部分点的对象视为离群点 简单，二维或三维的数据可以做散点图观察；大数据集不适用；对参数选择敏感；具有全局阈值，不能处理具有不同密度区域的数据集 基于密度 考虑数据集可能存在不同密度区域这一事实，从基于密度的观点分析，离群点是在低密度区域中的对象。一个对象的离群点得分是该对象周围密度的逆。 给出了对象时离群点的定量度量，并且即使数据具有不同的区域也能够很好处理；大数据集不适用；参数选择是困难的 基于聚类 一种利用聚类检测离群点的方法是丢弃远离其他簇的小簇；另一种更系统的方法，首先聚类所有对象，然后评估对象属于簇的程度（离群点得分） 基于聚类技术发现离群点可能是高度有效的；聚类算法产生簇的质量对该算法产生的离群点的质量影响非常大。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据分析（三）——数据预处理]]></title>
    <url>%2F2018%2F06%2F22%2F%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据挖掘中，海量的原始数据中存在着这大量不完整（有缺失值）、不一致、有异常的数据，严重影响到数据挖掘建模的执行效率，甚至可能导致挖掘结果的偏差，所以进行数据清洗就显得尤为重要，数据清洗完成后接着进行或者同时进行数据继承、转换、规约等一系列的处理，该过程就是数据预处理。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据预处理一方面是要提高数据的质量，另一个方面是要让数据更好地适应特定挖掘技术或工具。统计发现，在数据挖掘的过程中，数据预处理工作量占到了整个过程的60%。 数据预处理框架图 数据清洗&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据清洗主要是删除原始数据集中的无关数据、重复数据，平滑噪声数据，筛选掉与挖掘主题无关的数据，处理缺失值、异常值等。 缺失值的处理处理缺失值的方法可以分为三类： 删除记录 数据插补 不处理 常用的插补方法 插值法： 拉格朗日插值法 Hermite插值 牛顿插值法 分段插值 样条插值 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果通过简单的删除小部分记录达到既定的目标，那么删除含有缺失值的记录的方法是最有效的。然而，这种方法却有很大的局限性。它是以减少历史数据来换取数据的完备，会造成资源的大量浪费，将丢弃了大量隐藏在这些记录中的信息。尤其是在数据集本来就包含很少纪录的情况下，删除少量记录可能会严重影响到分析结果的客观性和正确性。一些模型可以将缺失值视作一种特殊的取值，允许直接在含有缺失值的数据上进行建模。 异常值处理&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据预处理时，异常值是否剔除，需视具体情况而定，因为有些异常值可能蕴含着有用的信息。 异常值处理常用方法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将含有异常值的记录直接删除的方法简单易行，但缺点也很明显，在观测值很少的情况下，这种删除会造成样本量不足，可能会改变变量的原有分布，从而造成分析结果的不准确。视为缺失值处理的好处是可以利用现有变量的信息，对异常值（缺失值）进行填补。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在很多情况下，要先分析异常值出现的可能原因，在判断异常值是否应该舍弃，如果是正确的数据，可以直接在具有异常值的数据集上进行挖掘建模。 数据集成&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据挖掘需要的数据往往分布在不同的数据源中，数据集成就是将多个数据源合并存放在一个一致的数据存储（数据仓库）中的过程。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据集成时，来自多个数据源的现实世界实体的表达形式是不一样的，有可能不匹配，要考虑实体识别问题和属性冗余问题，从而将数据源在最底层上加以转换、提炼和集成。 实体识别实体识别是指从不同数据源识别出现实世界的实体，它的任务是统一不同源数据的矛盾之处，常见形式如下： 同名异义数据源A中的属性ID和数据源中的属性ID分别描述的是学生编号和科目编号，即描述的是不同的实体。 异名同义数据源A中dt和数据源B中的date都是描述日期的。 单位不统一描述同一个实体分别用的是国际单位和中国传统的计量单位，检测和解决这些冲突就是实体识别的任务。 冗余属性识别数据冗余情况： 同一属性多次出现。 同一属性命名不一致导致重复。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;仔细整合不同数据源减少甚至避免数据冗余与不一致，从而提高数据挖掘的速度和质量。对于冗余属性要先分析，检测到后再将其删除。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有些冗余属性可以用相关分析检测。给定两个数值型A和B，根据其属性值，用相关系数度量一个属性在多大程度上蕴含另一个属性。 数据变换&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据变换主要是对数据进行规范化处理，将数据转化成“适当的”形式，以适用于挖掘任务及算法的需要。 方便置信区间分析或者可视化 (缩放数据， 对称分布)。 为了获取更容易解释的特征 (获取线性特征)。 降低数据的维度或者复杂度。 方便使用简单的回归模型。 简单的数据变换&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单的函数变换常用来将不具有正态分布非数据变换成具有正态分布的数据。在时间序列分析中，有时简单的对数变换或者差分运算就可以将非平稳序列转换成平稳序列。 常用简单的函数表 规范化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据规范化（归一化）处理是数据挖掘的一项基础工作。不同评价指标往往具有不同的量纲， 数之间的差别可能很大，不进行处理会影响到数据分析的结果。为了消除指标之间的量纲和取值范围差异的影响，需要进行标准化处理，将数据按照比例进行缩放，使之落入特定的区域，便于进行综合分析。 把数据映射到[0,1]的区间中。 把有量纲形式变成无量纲形式 。常用的规范化方法 连续属性离散化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一些数据挖掘算法，特别是某些分类算法（ID3算法、Apripri算法等）、要求数据是分类属性形式。这样，常常需要将连续属性变换换成分类属性，即连续属性离散化。 离散化过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;连续属性的离散化就是在数据的取值范围内设定若干个离散的划分点，将取值范围划分为一些离散化的区间，最后用不同的符号或整数值代表落在每个子区间中的数据值。所以，离散化涉及两个任务：确定分类数以及如何将连续属性值映射到这些分类值。 常用的离散化方法 属性构造&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据挖掘的过程中，为了提取更有用的信息，挖掘更深层次的模式，提高挖掘结果的精度，需要利用已有的属性集构造出新的属性，并加入到现有的属性集合中。 数据规约&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在大数据集上进行复杂的数据分析和挖掘需要很长的时间，数据归约产生更小但保持原数据完整性的新数据集。在规约后的数据集上进行分析和挖掘将更有效率。数据规约的意义： 降低无效、错误数据对建模的影响，提高建模的准确性。 少量且代表性的数据将大幅缩减数据挖掘所需的时间。 降低存储数据的成本 属性规约&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;属性规约通过属性合并来创建新属性维数，或者直接通过删除不相关（维）来减少数据维数，从而提高数据挖掘的效率、降低计算成本。属性规约的目标是寻找出最小的属性子集并确保新数据子集的概率分布尽可能地接近原来数据集的概率分布。 数值规约&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值规约值通过选择替代的、较少的数据来减少数据量，包括有参数和无参数方法两类。有参数方法是使用一个模型来评估数据，只需存放参数，而不需要存放实际数据，例如回归和对数线性模型。无参数方法就需要存放实际数据。 直方图直方图使用分箱来近似数据分布，是一种流行的数据归约形式。 聚类聚类技术将数据元组（即记录，数据表中的一行）视为对象。它将对象划分为簇，使一个簇中的对象相互“相似”，而与其他簇中的对象“相异”。在数据规约中，用数据的簇替换实际数据。该技术的有效性依赖于簇的定义是否符合数据的分布性质。 抽样抽样也是一种数据规约技术，它用比原始数据小得多的随机样本（子集）表示原始数据集。假定原始数据集D包含N个元组，可以采用抽样方法对D进行抽样。 s个样本无放回简单随机抽样 s个样本有放回简单随机抽样 聚类抽样 分层抽样 参数回归简单线性模型和对数线性模型可以用来近似描述给定的数据。线性模型对数据建模，使之拟合一条直线。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据分析（二）——数据探索]]></title>
    <url>%2F2018%2F06%2F20%2F%E6%95%B0%E6%8D%AE%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[数据探索框架图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过检验数据集的数据质量、绘制图表、计算某些特征量等手段，对样本数据集的结构和规律进行分析的过程就是数据探索。数据探索有助于选择合适的数据预处理和建模方法，甚至可以完成一些通常由数据挖掘解决的问题。 数据质量分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据质量分析是数据挖掘中数据准备过程的重要一环，是数据预处理的前提，也是数据挖掘分析结论有效性和准确性的基础，没有可信的数据，数据挖掘构建的模型将是空中楼阁。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据质量分析的主要任务是检查原始数据中是否存在脏数据，脏数据一般是指不符合要求，以及不能直接进行相应分析的数据，赃数据包括如下内容： 缺失值 异常值 不一致得值 重复数据及含有特殊符号缺失值&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据的缺失主要包括记录的缺失和记录中某个字段信息的缺失，两者都会造成分析结果的不准确。 缺失值的原因： 信息暂时无法获取，或者获取信息的代价太大。 信息被遗漏，人为的输入遗漏或者数据采集设备的遗漏。 属性不存在，在某些情况下，缺失值并不意味着数据有错误，对一些对象来说某些属性值是不存在的，如未婚者的配偶姓名、儿童的固定收入等。 缺失值的影响 数据挖掘建模将丢失大量的有用信息。 数据挖掘模型所表现出的不确定性更加显著，模型中蕴含的规律更难把握。 包含空值的数据会使建模过程陷入混乱，导致不可靠的输出。 缺失值的分析 使用简单的统计分析，可以得到含有缺失值的属性的个数，以及每个属性的未缺失数、缺失数与缺失率。 缺失值的处理 删除存在的缺失值的记录。 对可能值进行插补。 不处理情况。 构造新特征是否存在缺失值。 异常值&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异常值分析是检验数据是否有录入错误以及含有不合常理的数据。忽视异常值的存在是十分危险的，不加剔除地把异常值包括进数据的计算分析过程中，对结果会产生不良影响。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;异常值是指样本中的个别值，其数值明显偏离其余的观测值。异常值也称为离群点，异常值分析也称为离群点分析。 简单的计量分析 可以先对变量做一个描述性统计，进而查看哪些数据时不合理的。最常用的统计量是最大值和最小值，用来判断这个变量的取值是否超出了合理的范围。如年龄的最大值为150，则该变量的取值为异常值。 3σ原则如果数据服从正太分布，在3σ原则下，异常值被定义为一组测定值中与平均值的偏差超过3倍标准差的值。在正太太分布的假设下，距离平均值3σ之外的值出现的概率为P（|x-u|&gt;3σ）≤0.003，属于极个别的小概率事件。 箱线图分析箱线图是一种直观简洁的方式去呈现一组数据的分布. 因其形状如箱子而得名。箱线图广泛用于各个数据分析领域, 其中包括品质管理。箱形图最大的优点就是不受异常值的影响，能够准确稳定地描绘出数据的离散分布情况，同时也利于数据的清洗。箱线图是由美国著名统计学家John Tukey发明。它能非常简单明了地显示一组数据中5个重要数值： 最小值(Minimum Value, Min) 下四分位数(First Quartile, Q1) 中位数(Median Value, Med) 上四分位数(Third Quartile, Q3) 最大值(Maximum Value, Max) 四分位间距(Interquartile Range, IQR) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;箱线图为我们提供了识别异常值的一个标准：异常值被定义为小于Q1－5IQR或大于Q3＋1.5IQR的值。 一致性分析 数据不一致是指数据进行挖掘，可能会产生与实际相违背的挖掘结果。 不一致数据的产生主要发生在数据集成的过程中，这是由于不同的数据源，对于重复存放的数据未能进行一致性更新造成的。数据特征分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要通过绘制图表、计算某些特征量等手段进行数据特征分析。分布分析分布分析揭示数据的分布特征和分布类型。 对于定量数据，了解其分布形式是对称的还是非对称的，发现某些特大或特小的可疑值，可通过绘制频率分布表、频率分布直方图、茎叶图进行直观分析。 对于定性分类，可用饼图和条形图。 定量数据的分布分析遵循的主要原则： 各组之间必须是相互排斥的。 各组必须将所有的数据包含在内。 各组的组宽最好相等。对比分析&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对比分析法也称比较分析法，是把客观事物加以比较，以达到认识事物的本质和规律并做出正确的评价。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对比分析法通常是把两个相互联系的指标数据进行比较，从数量上展示和说明研究对象规模的大小，水平的高低，速度的快慢，以及各种关系是否协调。在对比分析中，选择合适的对比标准是十分关键的步骤，选择的合适，才能做出客观的评价，选择不合适，评价可能得出错误的结论。 绝对数比较 它是利用绝对数进行对比，从而寻找差异的一种方法。 相对数比较它是由两个有联系的指标对比计算的，用以反映客观现象之间数量联系程度的综合指标，其数值表现为相对数。由于研究目的和对比基础不同，相对数可以分为以下几种： 结构相对数（部分与总体关系）：将同一总体内的部分数值与全部数值对比求得比重，用以说明事物的性质、结构或质量。如,居民食品支出额占消费支出总额比重、产品合格率等。 比例相对数（部分与部分关系）：将同一总体内不同部分的数值对*，表明总体内各部分的比例关系，如,人口性别比例、投资与消费比例等。 比较相对数（横向对比关系）：将同一时期两个性质相同的指标数值对比，说明同类现象在不同空间条件下的数量对比关系。如,不同地区商品价格对比，不同行业、不同企业间某项指标对比等。 动态相对数（纵向对比关系）：将同一现象在不同时期的指标数值对比，用以说明发展方向和变化的速度。如,发展速度、增长速度等。 强度相对数（关联指标间关系）：将两个性质不同但有一定联系的总量指标对比，用以说明现象的强度、密度和普遍程度。如,人均国内生产总值用”元/人”表示，人口密度用”人/平方公里”表示，也有用百分数或千分数表示的，如,人口出生率用‰表示。 计划完成程度相对数（实际与计划关系）：是某一时期实际完成数与计划数对比，用以说明计划完成程度。 统计量分析用统计指标对定量数据进行统计描述，常从集中趋势和离中趋势两个方面进行分析。 平均水平的指标是对个体集中趋势的度量，使用最广泛的是均值和中位数。 反应变异程度的指标是对个体离开平均水平的度量，使用较广泛的是标准差（方差）、四分位间距。 集中趋势度量 算数平均数观测值的总和除以观测值的个数，即 常简称为平均数，也往往是背后机率分布的期望值之不偏估计。 中位数将所有观测值按大小排序后在顺序上居中的数值。实数数列x=(x1,x2,…,xn)的中位数: 众数出现最多次的观测值,用众数代表一组数据，适合于数据量较多时使用，且众数不受极端数据的影响. 几何平均数观测值的乘积之观测值个数方根，即 调和平均数观测值个数除以观测值倒数的总和，即 加权平均数考虑不同群资料贡献程度不同时的算数平均数 截尾平均数（truncated mean）忽略特定比例或特定数值之外的极端值后所得的平均数。例如，四分平均数（interquartile mean）正是忽略25%前及75%后的资料后所得的算数平均数。 全距中点（midrange）最大值与最小值的算数平均数，即 中枢纽（midhinge）第一四分位数与第三四分位数的算数平均数，即 三均值（trimean）考虑三个四分位数的加权平均数，即 极端值调整平均数（winsorized mean）以最接近的观测值取代特定比例的极端值后取得的算数平均数。举例来说，考虑10个观测值（由小到大排列为 由小到大列为x1至x10的情况下，10%的极端值调整平均数为 以上的统计量在多维变数中仍可单独地被套用在各个维度上进行，但并不能保证在转轴后仍维持一致的结果。 离中趋势度量 极差极差=最大值-最小值极差为离散程度的最简单测度值，易受极端值影响。 标准差标准差（又称标准偏差、均方差，英语：Standard Deviation，缩写SD），数学符号σ（sigma）），在概率统计中最常使用作为测量一组数值的离散程度之用。标准差定义：为方差开算术平方根，反映组内个体间的离散程度。 变异系数在概率论和统计学中，变异系数，又称“离散系数”（英文：coefficient of variation），是概率分布离散程度的一个归一化量度，其定义为标准差与平均值之比: 特点：当需要比较两组数据离散程度大小的时候，如果两组数据的测量尺度相差太大，或者数据量纲的不同,直接使用标准差来进行比较不合适，此时就应当消除测量尺度和量纲的影响，而变异系数可以做到这一点，它是原始数据标准差与原始数据平均数的比。CV没有量纲，这样就可以进行客观比较了。 四分位间距四分位距（interquartile range, IQR）。是描述统计学中的一种方法，以确定第三四分位数和第一四分位数的分别（即Q_{1}, Q_{3}的差距）。与变异数、标准差一样，表示统计资料中各变量分散情形，但四分差更多为一种稳健统计（robust statistic）。四分位差（Quartile Deviation, QD），是 Q_{1}, Q_{3}}的差距，即QD=(Q_{3}-Q_{1})。 周期性分析周期性分析是探索某个变量是否随着时间变化而呈现出某种周期变换趋势。时间尺度相对较长的周期性趋势有年度周期性趋势、季节性周期趋势，相对较短的有月度周期性趋势、周度周期性趋势，甚至更短的天、消失周期性趋势。 贡献度分析贡献度分析又称帕累托分析，它的原理是帕累托法则，又称20/80定律。同样的投入放在不同的地方会产生不同的效益。 相关性分析分析连续变量之间线性相关程度的强弱，并用适当的统计指标表示出来的过程称为相关性分析。 散点图绘制判断两个变量是否具有线性相关关系的最直观的方法是直接绘制散点图 绘制散点矩阵图需要同时考虑多个变量间的相关关系时，一一绘制它们间的简单散点图是十分麻烦的。此时利用散点矩阵同时绘制各变量间的散点图，从而快速发现多个变量间的主要相关性，在进行多元线性回归时显得尤为重要。 计算相关系数为了更加准确地描述变量之间的线性相关程度，可以通过计算相关系数来进行相关分析。在二元变量的相关性分析过程中比较常用的有Pearson相关系数、Spearman秩相关系数和判读系数。 Pearson相关系数 在统计学中，皮尔逊积矩相关系数（英语：Pearson product-moment correlation coefficient，又称作 PPMCC或PCCs, 文章中常用r或Pearson’s r表示）用于度量两个变量X和Y之间的相关（线性相关），其值介于-1与1之间。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商： 上式定义了总体相关系数，常用希腊小写字母ρ作为代表符号。估算样本的协方差和标准差，可得到样本相关系数(样本皮尔逊系数)，常用英文小写字母 r代表： 相关性强度： Spearnman秩相关系数 斯皮尔曼相关系数被定义成 等级变量之间的皮尔逊相关系数。 对于样本容量为 n的样本，n个 =原始数据Xi，Yi” style=”border:none;”&gt;被转换成等级数据xi,yi, 相关系数ρ为 原始数据依据其在总体数据中平均的降序位置，被分配了一个相应的等级。 如下表所示： 实际应用中， 变量间的连结是无关紧要的， 于是可以通过简单的步骤计算 ρ.[1][2] 被观测的两个变量的等级的差值 di=xi-yi， 则 ρ 为 判定系数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;决定系数（英语：coefficient of determination，记为R2或r2）在统计学中用于度量因变量的变异中可由自变量解释部分所占的比例，以此来判断统计模型的解释力。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;判定系数是相关系数的评分，用r2表示；判定系数取值范围：0≤r2≤1。r2越接近1，表明x与y之间的相关性越强；r2越接近于0，表明两个变量之间几乎没有直线相关关系。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于简单线性回归而言，决定系数为样本相关系数的平方。当加入其他回归自变量后，决定系数相应地变为多重相关系数的平方。]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python数据分析（一）——搭建Python平台]]></title>
    <url>%2F2018%2F06%2F19%2FPython%E5%BC%80%E5%8F%91%E5%B9%B3%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[考虑的问题 操作系统选择操作系统的问题，主要是Windows和Linux之间选择。Python是跨平台的语言，因此脚本可以跨平台运行。 不同的平台运行效率不一样，一般来说，在Linux下的运行速度比Windows快，而且是对于数据分析和挖掘任务。此外， 在Linux下搭建Python环境相对来说容易一些，很多Linux发行版自带了Python程序，并且在Linux下更容易解决第三方库的依赖问题。当然， Linux的操作门槛较高，可以先在Windows环境下熟悉，然后再考虑迁移到Linux环境中。 Python版本python 3.x是对python2.x一个较大的更新，并且越来越多的主流库已经开始支持3.x版本。 基础平台的搭建Python核心程序的安装，分为Windows和Linux介绍:最后介绍一个Python的科学计算发行版——Anaconda。 Windows在Windows系统中安装Python比较容易，直接到官方网站下载相应的msi安装包安装即可，和一般软件安装无异。 Linux大多数Linux发行版，如CentOS、Debian、Ubuntu等。 AnacondaAnaconda集成一些第三方扩展库，一个常用的科学计算发行版，避免安装一些第三库插件出错。Anaconda的特点如下： 包含了众多流行的科学、数学、工程、数据分析的Python包。 完全开源和免费。 额外的加速、优化是收费的，但对于学术用途可以申请免费的License。 全平台支持：Linux、Windows、Mac。因此，推荐安装此Python发行版。 第三方库的安装Python自带了很多库，但不一定可以满足我们的需求。就数据分析和数据挖掘而言，还需要添加一些第三方的库来扩展它的功能。 Python数据分析工具Python数据挖掘相关扩展库 相关扩展库简介NumpyPython并没有提供数组功能。虽然列表可以完成基本的数组功能，但它不是真正的数组，而且在数据量较大时，使用列表的速度就会慢得让人难以接受。为此，Numpy提供了真正的数组功能，以及对数据进行快速处理的函数。值得强调的是，Numpy内置函数处理数据的速度时C语言级别的，因此在编写程序的时候，应当尽量使用它们内置的函数，避免出现效率瓶颈的现象（尤其时涉及循环的问题）。 参考链接： http://www.numpy.org http://reverland.org/python/2012/08/22/numpy Pandas-1Pandas是Python下最强大的数据分析和探索工具。它包含高级的数据结构和精确的工具，使得在Python中处理数据非常快速和简单。Pandas构建在Numpy之上，它使得以Numpy为中心的应用很容易使用。 Pandas的功能非常强大： 支持类似于SQL的数据增、删、查、改，并且带有丰富的数据处理函数 支持时间序列分析功能 支持灵活处理缺失数据 参考链接 http://pandas.pydata.org/pandas-docs/stable http://jingyan.baidu.com/season/43456 Pandas-2 Pandas-3 Keras虽然Scikit-learn足够强大，但是它并没有包含一种强大的模型——人工神经网络。人工神经网络是功能强大的、但是原理相当简单的模型，在语言处理、图像识别等领域有着重要的作用。“深度学习”算法，本质也就是一种神经网络。 Keras库来搭建神经网络。事实上，Keras并非简单的神经网络库，而是基于Theano的强大的深度学习库，利用它不仅仅可以搭建普通的神经网络，还可以搭建各种深度学习模型，如自编码器、循环神经网络、递归神经网络、卷积神经网络等。由于它是基于Theano的，因此速度也相当快。 参考链接： https://github.com/fchollet/Keras http://radimrehurek.com/gensim Matplotlib无论是数据挖掘还是数据挖掘，都免不了数据可视化的问题。对于Python来说，Matplotlib是最著名的绘图库，它主要用于二维绘图，当然它也可以进行简单的三维绘图。 参考链接： http://pandas.pydata.org/pandas-docs/stable http://jingyan.baidu.com/season/43456 Scikit Learn一个机器学习相关的库,scikit-learn是Python下强大的机器学习库学习工具包，它提供了完善的机器学习工具箱，包括数据预处理、分类、回归、聚类、预测和模型分析等。 Scikit-learn依赖于Numpy、Scipy和Matplotlib，因此，需要提前安装好这几个库，然后安装Scikit-learn基本没有什么问题。 参考链接： http://Scikit-learn.org Scipy]]></content>
      <categories>
        <category>数据分析</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超详细的Hexo个人博客搭建]]></title>
    <url>%2F2018%2F06%2F18%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[前沿记录一下个人博客的搭建过程，总体搭建的过程相对比较顺利，注意一些命令以及报错的原因，搭建的环境是win10系统，如果系统不一样一些地方存在差异，但差异不是很大。个人博客的主要作用： 总结记录知识点 展示自己 自由度较高 搭建完成后的效果图 Github设置注册或者登陆github登陆github如果没有账号进行简单的注册即可，有的话直接登陆，下图是我的github账号,欢迎一起学习！ github建立个人仓库点击左上角头像旁边+号，下拉点击New repository（新建仓库或项目）： GitHub仓库的名称需要按照规定来写,规则如下： username.github.io 比如我的 GitHub 用户名是gofisher，那我就要填写 gofisher.github.io，接下来是对项目的简单的描述，然后选择Public模式，接着点击创建仓库按钮。 创建成功后，点击项目名进入项目的主页面，再点击Settings： 下拉滚动条到GitHub Pages区域，进行设置： 点击右下按钮继续设置： 最后选择选择一个网站的模版（可以任意选择，后面会进行更改），点击public按钮: 到此，已经完成github pages的设置，创建的项目增加了一些文件（下图是已经搭建好博客文件目录，现在其实没有这么多的文件）： 这个时候，就可以通过username.github.io来访问此页面，显示的应该是你选择的网页模版，如果显示成功说明github pages设置成功，如果无法显示，请仔细检查错误。 Git的安装和github-SSH KEY的配置git的安装git官网选择合适的git版本，进行下载： 下载完成，与普通的软件安装方式一致，安装完成后，点击菜单多出Git GUI Here和Git Base Here两项（具体作用请自己查询，本文用不到，可以不用理会，只是说明一下。）： Git系统环境变量的配置下图显示的win 10 系统的系统环境配置，不同系统的环境配置大同小异，注意一点就是git的配置是本地安装的目录： 测试Git是否配置成功，打开命令提示符，输入git命令，是否显示如下，如果有则配置成功： 设置Git的user name和email（初次）：在命令提示符中输入如下命令：1234# 这里的“gofisher&quot; 可以替换成自己的用户名git config --global user.name &quot;gofisher&quot;# 这里的邮箱493913124@qq.com替换成自己的邮箱,github的邮箱账号git config --global user.email &quot;493913124@qq.com&quot; 生成密钥12# 这里的邮箱493913124@qq.com替换成自己的邮箱ssh-keygen -t rsa -C &quot;gdutxiaoxu@163.com&quot; 密码是不显示符号，正确输入回车即可，输入两次，最后得到了两个文件：id_rsa和id_rsa.pub（密钥） 默认的存储路径是：C:\Users\GoFisher.ssh Gofisher是自己系统的用户名 登陆Github, 添加 ssh点击New SSH key,把id_rsa.pub文件里的内容复制进去： 测试1$ ssh -T git@github.com 如果需要输入密码，输入github的密码即可，如果看到Hi后面是你的用户名，就说明成功了： 使用hexo安装Node在Windows下，从 https://nodejs.org/en 下载以.msi为扩展名的安装包，如果不需要进行node相关开发的话，选LTS版本就够用了。 注意：然后也对node进行系统环境配置，步骤和上面一样，主要目的便于命令行的使用 **。 安装hexo12npm install -g hexo-clinpm install hexo-deployer-git --save # 安装部署站点的node功能包，hexo deploy命令需要 建立站点仓库123hexo init blog # 在合适的文件目录,初始化一个站点目录cd blognpm install 站点的目录文件一般hexo初始化后的站点目录结构如下：12345678910111213/blog |-- _config.yml # 站点配置文件 |-- scaffolds # 页面模板存放的目录 | |-- post.html # 博文模板 | |-- page.html # 分页模板 | \-- draft.html # 草稿模板 |-- source # 博文源文件目录 | |-- _posts # 存放博文的目录 | \-- _drafts # 存放草稿的目录 |-- themes # 存放主题文件夹的目录 |-- package.json |-- node_modules # 功能依赖包 \-- .gitignore # push的时候忽略node_modules文件夹等 修改_config.yml文件，整个站点的配置主要是在这个文件中修改:1234567891011title: 博客名description: 博客简述author: 作者名url: http(s)://your.site.comroot: /your/project/path or /deploy: type: git repo: git@github.com:userName/blog.git branch: gh-pages message: [自定义的提交信息] 站点的本地查看12hexo g # 生成编译后的静态站点文件hexo s # 打开服务，可以在本地查看点击生成的本地连接即可 站点的部署（所有修改后文件部署到github的命令套餐）123hexo clean #清除public文件夹（）hexo g # 生成编译后的静态站点文件hexo d # 部署到远程仓库 常用hexo命令12345678hexo init &lt;站点仓库的目录&gt; # 初始化一个站点目录hexo clean # 用于主题切换等涉及站点整体布局效果改变的行为时，清楚hexo原有缓存hexo new &apos;博文标题&apos; # 新增一篇博文hexo generate # 可简写为 hexo g ，编译生成静态页面文件hexo server # 可简写为 hexo s ，开启本地服务器预览与测试编译生成的静态页面效果hexo delpoy # 可简写为 hexo d ，部署站点到远程仓库hexo generate -d # 可简写为 hexo g -d ，编译生成静态页面文件并部署到远程仓库hexo deploy -g # 可简写为 hexo d -g ，同上 修改主题从hexo themes找到何意的主题，clone下来，放到站点本地仓库的themes目录下，修改_config.yml文件的theme字段为对应的主题名： theme: &lt;下载的主题名&gt; 博客的美化 主题的下载 主题的使用 第三方插件 更多的美化需要谷歌 注意事项 尽管GitHub个人网站项目是免费的，但是却有一些限制。总体来说，完全够用，甚至太多了。 单个仓库大小不超过1GB，上传单个文件大小不能超过100MB，如果通过浏览器上传不能超过25MB 个人网站项目也不例外，最大空间1GB 个人网站项目每个月访问请求数不能超过10万次，总流量不能超过100GB 个人网站项目一小时创建数量不能超过10个 参考链接 利用GitHub Pages建立项目或个人网站 git-ssh 配置和使用]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python机器学习基础教程]]></title>
    <url>%2F2018%2F06%2F17%2FPython%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[监督学习监督机器学习问题主要有两种问题，分别为叫作：分类（classification）和回归（regression） 泛化：在测试集上成功预测的能力。 过拟合和欠拟合：过于拟合训练集上的数据，过于选择简单的数据，最佳的模型应该是两者中间，才会使泛化能力最强。 模型复杂的与数据集大小的关系：数据集中包含的数据点的变化范围越大，在不发生过拟合的前提下你可以使用的模型就越复杂。收集更多数据，适当构建更复杂的模型，对监督学习任务往往特别有用。 一些样本数据集一个模拟的二分类数据集示例forge数据集，它有两个特征。下列代码将绘制一个散点图，将此数据集的所有数据点可视化。 1234import mglearnimport matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']plt.rcParams['axes.unicode_minus']=False 12#生成数据集x, y = mglearn.datasets.make_forge() 1234567#数据集绘制mglearn.discrete_scatter(x[:,0],x[:,1],y)plt.legend(["Class 0","Class 1"],loc=4)plt.xlabel('First feature')plt.ylabel('Second feature')plt.title('forge数据集的散点图')print("forge数据的样本数和特征维度:",x.shape) forge数据的样本数和特征维度: (26, 2) 12#回归数据集X,y = mglearn.datasets.make_wave(n_samples=40) 1234plt.plot(X,y,'o')plt.ylim(-3,3)plt.xlabel('特征')plt.ylabel('目标值') Text(0,0.5,&apos;目标值&apos;) 12#cancer数据集from sklearn.datasets import load_breast_cancer 1cancer = load_breast_cancer() 1print(cancer.DESCR) Breast Cancer Wisconsin (Diagnostic) Database ============================================= Notes ----- Data Set Characteristics: :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (&quot;coastline approximation&quot; - 1) The mean, standard error, and &quot;worst&quot; or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &quot;Decision Tree Construction Via Linear Programming.&quot; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: &quot;Robust Linear Programming Discrimination of Two Linearly Inseparable Sets&quot;, Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/ References ---------- - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. 1print(cancer.keys(),cancer['data'].shape,cancer['target_names'],set(cancer['target']),cancer['feature_names'],sep='\n') dict_keys([&apos;data&apos;, &apos;target&apos;, &apos;target_names&apos;, &apos;DESCR&apos;, &apos;feature_names&apos;]) (569, 30) [&apos;malignant&apos; &apos;benign&apos;] {0, 1} [&apos;mean radius&apos; &apos;mean texture&apos; &apos;mean perimeter&apos; &apos;mean area&apos; &apos;mean smoothness&apos; &apos;mean compactness&apos; &apos;mean concavity&apos; &apos;mean concave points&apos; &apos;mean symmetry&apos; &apos;mean fractal dimension&apos; &apos;radius error&apos; &apos;texture error&apos; &apos;perimeter error&apos; &apos;area error&apos; &apos;smoothness error&apos; &apos;compactness error&apos; &apos;concavity error&apos; &apos;concave points error&apos; &apos;symmetry error&apos; &apos;fractal dimension error&apos; &apos;worst radius&apos; &apos;worst texture&apos; &apos;worst perimeter&apos; &apos;worst area&apos; &apos;worst smoothness&apos; &apos;worst compactness&apos; &apos;worst concavity&apos; &apos;worst concave points&apos; &apos;worst symmetry&apos; &apos;worst fractal dimension&apos;] 1import numpy as np 1&#123;n:v for n,v in zip(cancer.target_names,np.bincount(cancer.target))&#125; {&apos;benign&apos;: 357, &apos;malignant&apos;: 212} 12# 波士顿房价数据集from sklearn.datasets import load_boston 1boston = load_boston() 1print(boston.DESCR) Boston House Prices dataset =========================== Notes ------ Data Set Characteristics: :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive :Median Value (attribute 14) is usually the target :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000&apos;s :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. http://archive.ics.uci.edu/ml/datasets/Housing This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. &apos;Hedonic prices and the demand for clean air&apos;, J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, &apos;Regression diagnostics ...&apos;, Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. **References** - Belsley, Kuh &amp; Welsch, &apos;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&apos;, Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing) K近邻K-NN算法可以说是最简单的机器学习算法。构建模型只需要保存训练数据集即可。想要对新数据点做出预测，算法会在训练数据集中找到最近的数据点，也就是它的“最近邻” K近邻分类12from sklearn.model_selection import train_test_splitfrom sklearn.neighbors import KNeighborsClassifier 123456#模型的训练X,y = mglearn.datasets.make_forge()X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)clf = KNeighborsClassifier(n_neighbors=3)#模型的训练clf.fit(X_train, y_train) KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=1, n_neighbors=3, p=2, weights=&apos;uniform&apos;) 12#模型的评估print('正确率:&#123;:2.2f&#125;%'.format(100*clf.score(X_test,y_test))) 正确率:85.71% 分析KNeighborsClassifier对于二维数据集，还可以在xy平面上画出所有可能的测试点的预测结果。我们根据平面中每个点所属的类别对平面进行着色。这样可以查看决策边界（decision boundary），即算法对类别0和类别1的分界线 123456789fig,axes = plt.subplots(1,3,figsize=(15,4))for n_neighbors,ax in zip([1,3,9],axes): clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X,y) mglearn.plots.plot_2d_separator(clf,X,fill=True,eps=0.5,ax=ax,alpha=0.4) mglearn.discrete_scatter(X[:,0],X[:,1],y,ax=ax) ax.set_title('&#123;&#125; neighbors(s)'.format(n_neighbors)) ax.set_xlabel('feature 0') ax.set_ylabel('feature 1')axes[0].legend(loc=3) &lt;matplotlib.legend.Legend at 0x240820c0fd0&gt; 从上图可以看出，使用单一邻居绘制的的决策边界紧跟着训练数据。随着邻居个数越来越多，决策边界也越来越平滑。更平滑的边界对应更简单的模型，复杂度越低。 1train_test_split? 1from sklearn.datasets import load_breast_cancer 1cancer = load_breast_cancer() 1X_train,X_test,y_train,y_test = train_test_split(cancer.data, cancer.target,stratify=cancer.target,random_state=66) 123training_accuracy=[]test_accuracy=[]neighbors_settings = range(1,11) 1234for n_neighbors in neighbors_settings: clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train,y_train) training_accuracy.append(clf.score(X_train,y_train)) test_accuracy.append(clf.score(X_test,y_test)) 12345plt.plot(neighbors_settings,training_accuracy,label='training accuracy')plt.plot(neighbors_settings,test_accuracy,label = 'test accuracy',linestyle = '-.')plt.ylabel('Accuracy')plt.xlabel('n_neighbors')plt.legend() &lt;matplotlib.legend.Legend at 0x24084117f28&gt; K近邻回归k近邻算法还可以用于回归。还是从单一近邻开始，这次使用wave数据集。添加了3个测试 数据点，在x轴上用绿色五角星表示。利用单一邻居的预测结果就是最近邻的目标值。 1import mglearn 1mglearn.plots.plot_knn_regression(n_neighbors=1) 1mglearn.plots.plot_knn_regression(n_neighbors=3) 12from sklearn.neighbors import KNeighborsRegressorfrom sklearn.model_selection import train_test_split 1X,y = mglearn.datasets.make_wave(n_samples=40) 12#数据划分X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0) 12#模型实例化，并将邻居个数设为3reg = KNeighborsRegressor(n_neighbors=3) 12#利用训练数据和训练目标来拟合模型reg.fit(X_train,y_train) KNeighborsRegressor(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;, metric_params=None, n_jobs=1, n_neighbors=3, p=2, weights=&apos;uniform&apos;) 1pre = reg.predict(X_test) 1pre array([-0.05396539, 0.35686046, 1.13671923, -1.89415682, -1.13881398, -1.63113382, 0.35686046, 0.91241374, -0.44680446, -1.13881398]) 1y_test array([ 0.37299129, 0.21778193, 0.96695428, -1.38773632, -1.05979555, -0.90496988, 0.43655826, 0.7789638 , -0.54114599, -0.95652133]) 1import matplotlib.pyplot as plt 12345plt.plot(range(1,len(y_test)+1),pre,label='predict')plt.plot(range(1,len(y_test)+1),y_test,label = 'real')plt.ylabel('Accuracy')plt.xlabel('numbers')plt.legend() &lt;matplotlib.legend.Legend at 0x1c012cb07f0&gt; 1reg.score(X_test,y_test) 0.8344172446249604 1import numpy as np 1234567891011121314fig,axes = plt.subplots(1,3,figsize = (15,4))# 创建1000个数据点，均匀分布在[-3,3]line = np.linspace(-3,3,1000).reshape(-1,1)for n_neighbors,ax in zip([1,3,9],axes): #利用1,3,9个邻居分别进行预测 reg = KNeighborsRegressor(n_neighbors=n_neighbors) reg.fit(X_train,y_train) ax.plot(line,reg.predict(line)) ax.plot(X_train,y_train,'^',c=mglearn.cm2(0),markersize = 8) ax.plot(X_test,y_test,'v',c=mglearn.cm2(1),markersize=8) ax.set_title("&#123;&#125; neighbor(s) \n train_score :&#123;:.2f&#125; test_score:&#123;:.2f&#125;".format(n_neighbors,reg.score(X_train,y_train),reg.score(X_test,y_test))) ax.set_xlabel("Feature") ax.set_ylabel("Target")axes[0].legend(["Model predictions","Training data/targrt","Test data/target"],loc = "best") &lt;matplotlib.legend.Legend at 0x1c013a1a2e8&gt; 从图中可以看出，仅使用单一邻居，训练集中的每个点都对预测结果有显著影响，预测结果的图像经过所有数据点。这导致预测结果非常不稳定。考虑更多的邻居之后，预测结果变得更加平滑，但对训练集数据拟合不是很好。 优点、缺点和参数 优点 模型很容易理解,通常不需要经过过多的调节就可以得到不错的性能。 构建最近邻模型的速度通常很快，但如果训练集过大（特征数很多或者样本数很大）,预测速度可能会比较慢。 缺点 虽然k近邻算法很容易理解，但由于预测速度慢且不能处理具有很多特征的数据集，所有在实践中往往不会用到。 参数 邻居的个数：K 数据点之间的距离的度量方法：欧式距离 归类的选择方法：投票法（少数服从多数） 线性回归线性模型是在实践中广泛使用的一类模型，几十年来被广泛研究。线性模型利用输入特征的线性函数进行预测。线性回归模型的主要类别： Ordinary Least Squares-线性回归（又名普通最小二乘法，OLS） Ridge Regression-岭回归 Lasso Elastic Net-弹性网 Least Angle Regression-最小角回归 Ordinary Least Squares-线性回归（又名普通最小二乘法，OLS）是回归问题最简单也是经典的线性方法，。线性回归寻找参数w和b，使得对训练集的预测值与真实值的回归目标值y之间的均方误差最小。均方误差是（mean squared error）是预测值和真实值之间的平方和除以样本数。线性回归不需要要手动给定参数（即没有调参），这是一个优点，但也因此无法控制模型的复杂度。并且普通最小二乘估计系数依赖于模型的独立。当条件相关,设计矩阵的列有近似线性关系,设计矩阵接近奇异和结果,随机误差的最小二乘估计变得高度敏感的观察到的反应,产生很大差异。这种情况下可能出现多重共线性的,例如,当数据收集没有实验设计。 123from sklearn.linear_model import LinearRegressionimport mglearnfrom sklearn.model_selection import train_test_split 12#构造数据集X,y = mglearn.datasets.make_wave(n_samples=60) 12345X_train,X_text,y_train,y_test = train_test_split(X,y)lr = LinearRegression().fit(X_train,y_train)pre = lr.predict(X_text)score = lr.score(X_text,y_test)print('拟合直线:y=&#123;0:.3f&#125;*x&#123;1:.3f&#125;\n的斜率:&#123;0:.3f&#125;,\n截距为:&#123;1:.3f&#125;,R方值：&#123;2:.2f&#125;'.format(lr.coef_[0],lr.intercept_,score)) 拟合直线:y=0.396*x-0.088 的斜率:0.396, 截距为:-0.088,R方值：0.72 123import matplotlib.pyplot as pltplt.rcParams['font.sans-serif']=['SimHei']plt.rcParams['axes.unicode_minus']=False 123456plt.scatter(X_train,y_train,color='black')plt.plot(X_text,pre)plt.xlabel('Feature')plt.ylabel('Target')plt.title('简单线性回归图\n 训练集拟合得分:&#123;:.3f&#125;,测试集拟合得分:&#123;:.3f&#125;'.format(lr.score(X_train,y_train),score))plt.legend(["数据点","拟合直线"],loc = 'best') &lt;matplotlib.legend.Legend at 0x2576d4db668&gt; 测试集上的得分为0.716，而且训练集和测试集的分数非常接近，这说明可能存在欠拟合，而不是过拟合。对于一维数据来说，过拟合的风险很小，因为模型非常简单（或受限）。然而，对于高维度的数据集（即有大量的特征的数据集），线性模型将变得更加强大，过拟合的可能性也会变大。 1from sklearn.datasets import load_boston 12# 查看数据datas = load_boston() 1print(datas.DESCR) Boston House Prices dataset =========================== Notes ------ Data Set Characteristics: :Number of Instances: 506 :Number of Attributes: 13 numeric/categorical predictive :Median Value (attribute 14) is usually the target :Attribute Information (in order): - CRIM per capita crime rate by town - ZN proportion of residential land zoned for lots over 25,000 sq.ft. - INDUS proportion of non-retail business acres per town - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) - NOX nitric oxides concentration (parts per 10 million) - RM average number of rooms per dwelling - AGE proportion of owner-occupied units built prior to 1940 - DIS weighted distances to five Boston employment centres - RAD index of accessibility to radial highways - TAX full-value property-tax rate per $10,000 - PTRATIO pupil-teacher ratio by town - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town - LSTAT % lower status of the population - MEDV Median value of owner-occupied homes in $1000&apos;s :Missing Attribute Values: None :Creator: Harrison, D. and Rubinfeld, D.L. This is a copy of UCI ML housing dataset. http://archive.ics.uci.edu/ml/datasets/Housing This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The Boston house-price data of Harrison, D. and Rubinfeld, D.L. &apos;Hedonic prices and the demand for clean air&apos;, J. Environ. Economics &amp; Management, vol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, &apos;Regression diagnostics ...&apos;, Wiley, 1980. N.B. Various transformations are used in the table on pages 244-261 of the latter. The Boston house-price data has been used in many machine learning papers that address regression problems. **References** - Belsley, Kuh &amp; Welsch, &apos;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&apos;, Wiley, 1980. 244-261. - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing) 123#划分训练集和测试集X_train,X_test,y_train,y_test = train_test_split(datas.data,datas.target,random_state=0)print('训练集样本数:',len(X_train),',目标值个数:',len(y_train)) 训练集样本数: 379 ,目标值个数: 379 123#建立模型并进行训练lr = LinearRegression().fit(X_train,y_train)print(lr.coef_,lr.intercept_) [-1.16869578e-01 4.39939421e-02 -5.34808462e-03 2.39455391e+00 -1.56298371e+01 3.76145473e+00 -6.95007160e-03 -1.43520477e+00 2.39755946e-01 -1.12937318e-02 -9.86626289e-01 8.55687565e-03 -5.00029440e-01] 36.98045533762024 12#结果输入print('训练集得分&#123;:.2f&#125;,测试集得分:&#123;:.2f&#125;'.format(lr.score(X_train,y_train),lr.score(X_test,y_test))) 训练集得分0.77,测试集得分:0.64 如果训练集和测试集之间的性能差异过大是过拟合的明显标志，因此我们应该试图找到一个可以控制复杂度的模型。标注线性回归最常用的替代方法之一就是岭回归（ridge regression） Ridge Regression-岭回归Ridge回归通过对系数的大小施加惩罚来解决普通最小二乘的一些问题 。 1from sklearn.linear_model import RidgeCV 1RlrCV = RidgeCV(alphas=[a/10 for a in range(1,11)]).fit(X_train,y_train) 1pre = RlrCV.predict(X_test) 1'训练集得分:&#123;:.2f&#125;,测试集得分:&#123;:.2f&#125;,正则化参数&#123;&#125;'.format(RlrCV.score(X_train,y_train),RlrCV.score(X_test,y_test),RlrCV.alpha_) &apos;训练集得分:0.77,测试集得分:0.63,正则化参数0.1&apos; 1Rlr.coef_ array([-1.14800388e-01, 4.48854707e-02, -2.49113266e-02, 2.35025027e+00, -1.07096752e+01, 3.79227215e+00, -1.17800878e-02, -1.37038928e+00, 2.24039660e-01, -1.15836405e-02, -9.32419484e-01, 8.79786724e-03, -5.05077028e-01]) 1Rlr.intercept_ 33.577957038260564 Lasso除了Ridge,还有一种正则化的线性回归是Lasso。与岭回归相同，使用lasso也是约束系数使其接近于0，但用到的方法不同，叫作L1正则化 1from sklearn.linear_model import Lasso 1lasso = Lasso(alpha=0.01,max_iter=10000).fit(X_train,y_train) 1print(lasso.score(X_train,y_train),lasso.score(X_test,y_test)) 0.769304356071975 0.6315913583895181 1print(lasso.coef_!=0) [ True True True True True True True True True True True True True] Elastic Net-弹性网 1from sklearn.linear_model import ElasticNet 1en = ElasticNet(alpha=0.01,l1_ratio=0.4).fit(X_train,y_train) 1print(en.score(X_train,y_train),en.score(X_test,y_test)) 0.7655774760174687 0.620339161352674 在实践中，在两个模型中一般首选岭回归。但如果特征很多，你认为只有其中几个是重要的，那么选择Lasso可能会更好。同样，如果你想要一个容易解释的模型，Lasso可以给出更容易理解的模型，因为它只选择一部分输入特征。弹性网，是两种回归的结合，这种结合效果最好，不过代价是调节两个参数：一个用于L1正则化，一个用于L2正则化。 决策树决策树是广泛用于分类和回归任务的模型。本质上，它从一层层的if/else问题中进行学习，并得出结论。 构造决策树学习决策树，就是学习一系列if/else问题，使我们能够以最快的速度得到正确的答案。在机器学习中，这些问题叫作测试(不要与测试集弄混，测试集是用来测试模型泛化性能的数据)。为了构造决策树，算法搜遍所有可能的测试，找出对目标变量来说信息量最大的那一个。 控制决策树的复杂度通常来说，构造决策树知道所有叶节点都是纯的叶节点，这会导致模型非常复杂，并且对训练数据高度拟合。纯叶节点的存在说明这棵树在训练集上的精度是100%。训练集中的每个数据点都位于分类正确的叶节点中。防止过拟合有两种常见的策略： 预剪枝：及早停止树的生长，限制树的最大深度、限制叶节点的最大数目或者规定一个节点中数据点的最小数目来防止继续划分。 后剪枝(剪枝)：先构造树，随后删除或折叠信息量很少的节点 123from sklearn.tree import DecisionTreeClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.datasets import load_breast_cancer 1print(load_breast_cancer().DESCR) Breast Cancer Wisconsin (Diagnostic) Database ============================================= Notes ----- Data Set Characteristics: :Number of Instances: 569 :Number of Attributes: 30 numeric, predictive attributes and the class :Attribute Information: - radius (mean of distances from center to points on the perimeter) - texture (standard deviation of gray-scale values) - perimeter - area - smoothness (local variation in radius lengths) - compactness (perimeter^2 / area - 1.0) - concavity (severity of concave portions of the contour) - concave points (number of concave portions of the contour) - symmetry - fractal dimension (&quot;coastline approximation&quot; - 1) The mean, standard error, and &quot;worst&quot; or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius. - class: - WDBC-Malignant - WDBC-Benign :Summary Statistics: ===================================== ====== ====== Min Max ===================================== ====== ====== radius (mean): 6.981 28.11 texture (mean): 9.71 39.28 perimeter (mean): 43.79 188.5 area (mean): 143.5 2501.0 smoothness (mean): 0.053 0.163 compactness (mean): 0.019 0.345 concavity (mean): 0.0 0.427 concave points (mean): 0.0 0.201 symmetry (mean): 0.106 0.304 fractal dimension (mean): 0.05 0.097 radius (standard error): 0.112 2.873 texture (standard error): 0.36 4.885 perimeter (standard error): 0.757 21.98 area (standard error): 6.802 542.2 smoothness (standard error): 0.002 0.031 compactness (standard error): 0.002 0.135 concavity (standard error): 0.0 0.396 concave points (standard error): 0.0 0.053 symmetry (standard error): 0.008 0.079 fractal dimension (standard error): 0.001 0.03 radius (worst): 7.93 36.04 texture (worst): 12.02 49.54 perimeter (worst): 50.41 251.2 area (worst): 185.2 4254.0 smoothness (worst): 0.071 0.223 compactness (worst): 0.027 1.058 concavity (worst): 0.0 1.252 concave points (worst): 0.0 0.291 symmetry (worst): 0.156 0.664 fractal dimension (worst): 0.055 0.208 ===================================== ====== ====== :Missing Attribute Values: None :Class Distribution: 212 - Malignant, 357 - Benign :Creator: Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian :Donor: Nick Street :Date: November, 1995 This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets. https://goo.gl/U2Uwz2 Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, &quot;Decision Tree Construction Via Linear Programming.&quot; Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: &quot;Robust Linear Programming Discrimination of Two Linearly Inseparable Sets&quot;, Optimization Methods and Software 1, 1992, 23-34]. This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/ References ---------- - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995. - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171. 1234cancer = load_breast_cancer()X_train,X_test,y_train,y_test= train_test_split(cancer.data,cancer.target,stratify=cancer.target,random_state=42)detree = DecisionTreeClassifier(random_state=0).fit(X_train,y_train)print('测试集精度&#123;:.2f&#125;,训练集精度&#123;:.2f&#125;'.format(detree.score(X_train,y_train),detree.score(X_test,y_test))) 测试集精度1.00,训练集精度0.94 训练集上的精度是100%，这是因为叶节点都是纯的，树的深度很大，足以完美地记住训练数据的所有标签。测试集精度比之前讲过的线性模型略低，线性模型的精度约为95%。如果我们不限制决策树的深度，它的深度和复杂度都可以变得特别大。因此，未剪枝的树容易过拟合，对新数据的泛化性能不佳。可以在完美拟合训练数据之前树的展开。一种选择是达到一定深度后停止树的展开。可以通过设置max_depth=4，不然默认值是max_depth=None，会自动的扩大到纯节点。 Init signature: DecisionTreeClassifier(criterion=’gini’, splitter=’best’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)Docstring:A decision tree classifier. criterion : string, optional (default=”gini”) The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. splitter : string, optional (default=”best”) The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split. max_depth : int or None, optional (default=None) The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. 1tree = DecisionTreeClassifier(max_depth=4,random_state=0).fit(X_train,y_train) 分析决策树可以利用tree模块的export_graphviz函数来将树可视化。这个函数会生成一个.dot格式的文件，这是一种用于保存图形的文本文件格式。 12from sklearn.tree import export_graphvizdot_grap = export_graphviz(tree,out_file=None,class_names=['maligant','benign'],feature_names=cancer.feature_names,filled=True,rounded=True,special_characters=True) 利用graphviz模块读取这个文件并将其可视化（可以使用任何能够读取.dot文件的程序） 使用conda install python-graphviz进行安装 12import graphvizgraphviz.Source(dot_grap) 树的可视化有助于深入理解算法是如何进行预测的，也是易于向非专家解释的机器学习算法的优秀示例。 gini：gini基数 samples：给出了该节点的样本个数 values：给出的是每个类别的样本个数，[‘maligant’,’benign’] worst radius &lt;= 16.795：每个节点基于gini系数进行划分 class：此节点的类别 树的特征重要性查看整个树可能非常费劲，除此之外，还可以利用一些有用的属性来总结树的工作原理。其中最常用的是特征重要性，它为每个特征对树的决策的重要性进行排序。对于特征来说，是一个介于0和1之间的数字，其中0表示“根本没有用到”，1表示“完美预测目标值”。特征值重要性求和始终为1。 123456789import matplotlib.pyplot as pltimport numpy as npdef plot_feature_importances_cancer(model): n_features = cancer.data.shape[1] plt.barh(range(n_features),model.feature_importances_,align = 'center') plt.yticks(np.arange(n_features),cancer.feature_names) plt.xlabel('Feature importance') plt.ylabel('Feature')plot_feature_importances_cancer(tree) 这里可以看出，顶部划分用到的特征（“worst radius”）是最重要的特征，即第一层划分已经将两个类别区分得很好。但是，如果某个特征的feature_importance_很小，并不能说明这个特征没有提供任何信息。这只能说明咩有被树选中，可能是因为另一特征也包含了同样的信息。 总结决策树的一些优点是： 很容易理解和解释。树可以被可视化。 需要很少的数据准备。其他技术通常需要数据标准化，需要创建虚拟变量并删除空白值。但请注意，此模块不支持缺少的值。 使用树的成本（即预测数据）是用于训练树的数据点的数量的对数。 能够处理数字和分类数据。其他技术通常专门用于分析只有一种类型变量的数据集。查看更多信息的算法。 能够处理多输出问题。 使用白盒模型。如果给定的情况在模型中是可观察的，则条件的解释很容易通过布尔逻辑来解释。相比之下，在黑盒模型（例如，在人工神经网络中），结果可能更难以解释。 可以使用统计测试来验证模型。这可以说明模型的可靠性。 即使其假设受到数据生成的真实模型的某种程度的侵犯，也能很好地执行。 决策树的缺点包括： 决策树学习者可以创建过于复杂的树，不能很好地概括数据。这被称为过度拟合。修剪（目前不支持）等机制，设置叶节点所需的最小样本数或设置树的最大深度是避免此问题所必需的。 决策树可能不稳定，因为数据中的小变化可能会导致生成完全不同的树。通过在集合中使用决策树可以缓解这个问题。 学习最优决策树的问题在最优化的几个方面甚至简单的概念下被认为是NP完全的。因此，实际决策树学习算法基于启发式算法，例如在每个节点进行局部最优决策的贪心算法。这样的算法不能保证返回全局最优决策树。这可以通过在集合学习器中训练多棵树来缓解，其中特征和样本随机地用替换采样。 有些概念很难学，因为决策树不能很容易地表达它们，例如XOR，奇偶校验或多路复用器问题。 如果某些类占主导地位，决策树学习者会创建偏向性树。因此，建议在拟合决策树之前平衡数据集。 决策树集成集成（ensemble）是合并多个机器学习模型来构建更强大模型的方法。 随机森林：许多决策树的集合，其中每棵树之间希望相互独立。其中随机体现在以下两个方法： 构造数据的随机（n_estimators参数设置）：对数据进行自助采样，也就是说从n_samples个数据点中有放回地（即同一个样本可以被多次抽取）重复随机抽取一个样本，共抽取n_samples次。这样会创建一个与原数据集大小相同的数据集，但有些数据点会缺失（大约三分之一），有些会重复。 特征的选择随机（max_features参数设置）：在每个节点处，算法随机选择特征的一个子集，并对其中一个特征寻找最佳测试，而不是对每个节点都寻找最佳测试，选择特征的个数由max_features参数来控制。每个节点中的特征子集的选择是相互独立的，这样树的每个结点可以使用特征的不同子集来做出决策。 使用方法：利用随机森林进行预测，算法首先对森林中的每棵树进行预测。对于回归问题，可对这些结果取平均值作为最终预测。对于分类问题，则用到了“软投票”（soft voting）策略。也就是说，每个算法做出“软”预测，给出每个可能的输出标签的概率。对所有树的预测概率去平均值，然后将概率最大的类别作为预测结果。 123from sklearn.ensemble import RandomForestClassifierfrom sklearn.datasets import make_moonsfrom sklearn.model_selection import train_test_split 1234#构造数据集及训练模型X,y = make_moons(n_samples=100,noise=0.25,random_state=3)X_train,X_test,y_train,y_test =train_test_split(X,y,random_state=42)forest = RandomForestClassifier(n_estimators=5,random_state=2).fit(X_train,y_train) 作为随即森林的一部分，树被保存在estimator_属性中。我们将每棵树学到的决策边界可视化，也将它们的总预测（即整个森林做出的预测）可视化。 12345678910import matplotlib.pyplot as pltimport mglearn#结果的可视化fig,axes = plt.subplots(2,3,figsize = (20,10))for i,(ax,tree) in enumerate(zip(axes.ravel(),forest.estimators_)): ax.set_title('Tree&#123;&#125;'.format(i)) mglearn.plots.plot_tree_partition(X_train,y_train,tree,ax=ax)mglearn.plots.plot_2d_separator(forest,X_train,fill=True,ax=axes[-1,-1],alpha=0.4)axes[-1,-1].set_title('Random Forest')mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train) [&lt;matplotlib.lines.Line2D at 0x20c4a0a5358&gt;, &lt;matplotlib.lines.Line2D at 0x20c4a09a8d0&gt;] 1print('训练集精确度&#123;:2.2f&#125;% \n测试集精确度&#123;:2.2f&#125;%'.format(100*forest.score(X_train,y_train),100*forest.score(X_test,y_test))) 训练集精确度97.33% 测试集精确度84.00% 123456from sklearn.datasets import load_breast_cancer#100棵树的随机森林应用在乳腺癌数据集上的应用cancer = load_breast_cancer()X_train,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,random_state=0)forest = RandomForestClassifier(n_estimators=100,random_state=0).fit(X_train,y_train)print('训练集精确度:&#123;:.2f&#125;,测试集精确度:&#123;:.2f&#125;'.format(forest.score(X_train,y_train),forest.score(X_test,y_test))) 训练集精确度:1.00,测试集精确度:0.97 12#随机深林的特征重要性plot_feature_importances_cancer(forest) 与单棵树相比，随机森林中有更多特征的重要性不为零。与单棵决策树类似，随机森林也给了“worst radius”（最大半径）特征很大的重要，单从总体来看，它实际上却选择“worst permeter”（最大周长）作为信息量最大的特征。由于构造随机森林过程中的随机性，算法需要考虑多种可能的解释，结果就是随机森林比单棵树更能从总体把握数据特征。 随机森林总结用于回归和分类的随机森林是目前运用最广泛的机器学习方法之一。这种方法非常强大，通常不需要反复调节参数就可以给出很好的结果，也不需要对数据进行缩放。 随机森林拥有决策树的所有优点，同时弥补了决策树的一些缺陷。 仍然使用决策树的原因： 单棵树可以进行可视化展示，易解释。 如果树过多，耗时过长，可以对n_jobs对cpu进行调用使用 随机森林本质是上是随机的，设置不同的随机状态可以彻底改变构建的模型。——参数random_state=None,默认设置，如果设置成整数，可以保证每次运行的结果相同。 对于维度非常高的稀疏数据（比如文本数据），随机森林的表现往往不是很好。对于这种数据，使用线性模型可能更合适。 需要调节的参数 n_estimators:确定决策树的个数，经验法则“在你的时间/内存允许的情况下尽量多”。 max_features:特征的子集个数，决定每棵树的随机性，对于分类：max_features=sqrt(n_features)；对于回归，max_features=n_features。 n_jobs:使用更多cpu进行训练，n_jobs=-1为使用计算机所有内核进行训练。| 梯度提升回归树（梯度提升机） 梯度提升回归树是另一种集成方法，通过合并多个决策树来构建一个更为强大的模型。虽然名字中含有“回归”，但这个模型既可以用于回归也可以用于分类。 与随机森林方法不同，梯度提升采用连续的方式构造树，每棵树都试图纠正前一棵树的错误。默认情况下，梯度提升回归树中没有随机化，二十用到了强预剪枝。梯度提升树通常使用深度很小（1到5之间）的树，这样模型占用的内存更少，预测速度也更快。 主要思想是合并许多简单的模型（若学习器），比如深度较小的树。每棵树只能对部分数据做出好的预测，因此，添加的树越来越多，可以不断迭代提高性能。 除了预剪枝与集成树中的数量之外，梯度提升的另一个重要参数是learning_rate（学习率），用于控制每棵树纠正前一棵树的错误的强度。较高的学习率意味着每棵树都可以做出较强的修正，这样模型更为复杂。通过增大n_estimators来向集成中添加更多树，也可以增加模型复杂度，因为模型有更多机会纠正训练集上的错误。 123from sklearn.ensemble import GradientBoostingClassifierfrom sklearn.model_selection import train_test_splitfrom sklearn.datasets import load_breast_cancer 1234data = load_breast_cancer()X_train,X_test,y_train,y_test = train_test_split(data.data,data.target,random_state=0)gbrt = GradientBoostingClassifier(random_state=0).fit(X_train,y_train)print('测试集精确度&#123;&#125;,训练集精确度&#123;&#125;。'.format(gbrt.score(X_train,y_train),gbrt.score(X_test,y_test))) 测试集精确度1.0,训练集精确度0.958041958041958。 由于训练精度达到100%，所以很可能存在过拟合。为了降低过拟合，我们可以限制最大深度来加强预剪纸，也可以降低学习率： 12gbrt = GradientBoostingClassifier(random_state=0,max_depth=1).fit(X_train,y_train)print('测试集精确度&#123;&#125;,训练集精确度&#123;&#125;。'.format(gbrt.score(X_train,y_train),gbrt.score(X_test,y_test))) 测试集精确度0.9906103286384976,训练集精确度0.972027972027972。 12gbrt = GradientBoostingClassifier(random_state=0,learning_rate=0.01).fit(X_train,y_train)print('测试集精确度&#123;&#125;,训练集精确度&#123;&#125;。'.format(gbrt.score(X_train,y_train),gbrt.score(X_test,y_test))) 测试集精确度0.9882629107981221,训练集精确度0.965034965034965。 降低模型复杂度的两种方法：减小树的最大深度和减小学习率，减小树的最大深度显著提升了模型性能，而降低学习率仅稍稍提高了泛化性能。 1gbrt = GradientBoostingClassifier(random_state=0,max_depth=1).fit(X_train,y_train) 12345678import matplotlib.pyplot as pltimport numpy as npdef plot_feature_importances_cancer(model): n_features = cancer.data.shape[1] plt.barh(range(n_features),model.feature_importances_,align = 'center') plt.yticks(np.arange(n_features),cancer.feature_names) plt.xlabel('Feature importance') plt.ylabel('Feature') 12345678import matplotlib.pyplot as pltimport numpy as npdef plot_feature_importances_cancer(model): n_features = data.data.shape[1] plt.barh(range(n_features),model.feature_importances_,align = 'center') plt.yticks(np.arange(n_features),data.feature_names) plt.xlabel('Feature importance') plt.ylabel('Feature') 1plot_feature_importances_cancer(gbrt) 梯度提升树的特征重要性与随机森林的特征重要性有些类似，不过梯度提升完全忽略了某些特征。由于梯度提升和随机森林两种方法在类似的数据上表现得都很好，因此一种常用的方法就是先尝试随机森林，它的鲁棒性很好。如果随机森林效果很好，但预测时间很长，或者机器学习模型精度小数点后第二位的提高也很重要，那么切换成梯度提升通常会有用。 梯度提升总结 其主要缺点是需要仔细调参，而且训练时间可能会比较长。但是这一算法不需要对数据进行缩放就可以表现得很好，而且也适用于二元特征与连续特征同时存在的数据集。与其他基于树的模型相同，它也通常不适用于高维稀疏数据。 梯度提升树的模型的主要参数如下： 树的数量（n_estimators）:树的数量增大导致模型复杂度更加复杂，进而可能导致过拟合。 学习率（learning_rate）:学习率越低，就需要更多的树来构建具有相似复杂度的模型。 树的最大深度（max_depth）:降低每棵树的复杂度。 1GradientBoostingClassifier? GradientBoostingClassifier(loss=’deviance’, learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=’friedman_mse’, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=’auto’) 核支持向量机核支持向量机（通常简称SVM）是可以推广到更复杂模型的扩展，这些模型无法被输入空间的超平面定义。 线性模型与非线性特征线性模型在低维空间中可能非常受限，因为线和平面的灵活性有限。有一种方法可以让线性模型更加灵活，就是添加更多的特征，添加输入特征的交互项或多项式。 12345678import mglearnfrom sklearn.datasets import make_blobsimport matplotlib.pyplot as pltX,y = make_blobs(centers=4,random_state=8)y= y%2mglearn.discrete_scatter(X[:,0],X[:,1],y)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 线性不可分——用于分类的线性模型只能用一条直线来划分数据点，对这个数据集无法给出较好的结果。 123456from sklearn.svm import LinearSVClinear_svm = LinearSVC().fit(X,y)mglearn.plots.plot_2d_separator(linear_svm,X)mglearn.discrete_scatter(X[:,0],X[:,1],y)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 添加第三个特征的平方（feature1^2）作为一个新特征。现在我们将每个数据点表示为三位点（feature0，feature1，feature1^2）,而不是二维点（feature0，feature1）。 12345678910111213import numpy as npfrom mpl_toolkits.mplot3d import Axes3D,axes3d#添加第三维度X_new = np.hstack([X,X[:,1:]**2])figure = plt.figure()#3d可视化ax= Axes3D(figure,elev=-152,azim=-26)mask = y == 0ax.scatter(X_new[mask,0],X_new[mask,1],X_new[mask,2],c= 'b',cmap = mglearn.cm2,s=60)ax.scatter(X_new[~mask,0],X_new[~mask,1],X_new[~mask,2],c='r',marker = '^',cmap = mglearn.cm2,s=60)ax.set_xlabel('feature 0')ax.set_ylabel('feature 1')ax.set_zlabel('feature1 **2') Text(0.5,0,&apos;feature1 **2&apos;) 在数据的的新表示，现在可以用线性模型（三维空间的平面）将两个类别分开。可以用线性模型你和扩扩展后的数据来验证这一点。 1234567891011121314151617linear_svm_3d = LinearSVC().fit(X_new,y)coef,intercept = linear_svm_3d.coef_.ravel(),linear_svm_3d.intercept_#显示线性决策边框figure = plt.figure()ax= Axes3D(figure,elev=-152,azim=-26)xx = np.linspace(X_new[:,0].min()-2,X_new[:,0].max()+2,50)yy = np.linspace(X_new[:,1].min()-2,X_new[:,1].max()+2,50)XX,YY = np.meshgrid(xx,yy)ZZ = (coef[0]*XX+coef[1]*YY+intercept)/-coef[2]ax.plot_surface(XX,YY,ZZ,rstride=8,cstride=8,alpha=0.3)ax.scatter(X_new[mask,0],X_new[mask,1],X_new[mask,2],c= 'b',cmap = mglearn.cm2,s=60)ax.scatter(X_new[~mask,0],X_new[~mask,1],X_new[~mask,2],c='r',marker = '^',cmap = mglearn.cm2,s=60)ax.set_xlabel('feature 0')ax.set_ylabel('feature 1')ax.set_zlabel('feature1 **2') Text(0.5,0,&apos;feature1 **2&apos;) 分割的已经不是线性的了，它不是一条直线，二十一个椭圆。 123456ZZ=YY**2dec = linear_svm_3d.decision_function(np.c_[XX.ravel(),YY.ravel(),ZZ.ravel()])plt.contour(XX,YY,dec.reshape(XX.shape),levels=[dec.min(),0,dec.max()],cmap = mglearn.cm2,alpha=0.5)mglearn.discrete_scatter(X[:,0],X[:,1])plt.xlabel('Feature 0')plt.ylabel('Fearure 1') Text(0,0.5,&apos;Fearure 1&apos;) 核技巧向数据表示中添加非线性特征，可以让线性模型变得更强大。但是，通常来说我们并不知道要添加哪些特征，而且添加许多特征（比如100特征空间所有可能的交互项）的计算开销可能会很大。幸运的是，有一种巧妙的数学技巧，让我们可以在更高维空间中学习分类器，而不用实际就散可能非常大的新的数据表示。这种技巧叫作核技巧，它的原理是直接计算扩展特征表示中数据点之间的距离（更准确地说是内积），而不用实际对扩展进行计算。将数据映射到更高维空间中有两种常用的方法： 多项式核：在一定阶数内计算原始特征所有可能的多项式。 径向基函数（RBF）,也叫高斯核：对应无限维的特征空间，它考虑所有阶数的所有可能的多项式，但阶数越高，特征的重要性越小。 理解SVMSVM学习每个训练数据点对于表示两个类别之间的决策边界的重要性。通常只有一部分训练数据点对于定义决策边界来说很重要：位于类别之间边界上的那些点。这些点叫作支持向量（support vector），支持向量机正式由此得名。对新样本进行预测，需要测量与它每个支持向量之间的距离。分类决策是基于它与支持向量之间的距离以及在训练过程中学到的支持向量的重要性（保存在svc的dual_coef_属性中）来做出的。 123456789101112from sklearn.svm import SVCX,y = mglearn.tools.make_handcrafted_dataset()svm = SVC(kernel='rbf',C=10,gamma=0.1).fit(X,y)mglearn.plots.plot_2d_separator(svm,X,eps=.5)mglearn.discrete_scatter(X[:,0],X[:,1],y)#画出支持向量机sv= svm.support_vectors_# 支持向量的类别标签由dual_coef_的正负号给出sv_labels = svm.dual_coef_.ravel()&gt;0mglearn.discrete_scatter(sv[:,0],sv[:,1],sv_labels,s=15,markeredgewidth=3)plt.xlabel('Feature 0')plt.ylabel('Feature 1') Text(0,0.5,&apos;Feature 1&apos;) SVM给出了非常平滑且非线性（不是直线）的边界，这里我们调用两个参数： C参数 gamma参数 SVM调参 gamma参数是公式中的参数，用于控制高斯核的宽度。它决定了点与点之间“靠近”是指多大的距离。 C参数是正则化参数，与线性模型中用到的类似，它限制每个点的重要性（或者更确切地说，每个点的dual_coef）。 1234567import matplotlib.pyplot as pltimport mglearnfig,axes = plt.subplots(3,3,figsize =(15,10))for ax,C in zip(axes,[-1,0,3]): for a,gamma in zip(ax,range(-1,2)): mglearn.plots.plot_svm(log_C=C,log_gamma=gamma,ax=a)axes[0,0].legend(["class 0","class 1","sv class 0","sv class 1"],ncol = 4,loc=(.9,1.2)) &lt;matplotlib.legend.Legend at 0x1f780808588&gt; 从左到右，将参数gamma的值从0.1增加到10。gamma较小，说明高斯核的半径较大，许多点都被看作比较靠近。可以从图看出：左侧的图决策边界非常平滑，越向右的图决策边界更关注单个点。小的gamma值表示决策边界变化很慢，生成的是复杂度较低的模型，而大的gamma值则会生成更为复杂的模型。 从上到下，参数C的值从0.1增加到1000。与线性模型相同，C值相同，C值很小，说明模型非常受限，每个数据点的影响范围都有限。可以看到，左上角的图中，决策边界看起来几乎是线性的，误分类的点对边界几乎没有任何影响。左下角的图，增大C之后这些点对模型的影响变大，使得决策边界发生弯曲了将这些点正确分类。 12345678from sklearn.model_selection import train_test_splitfrom sklearn.datasets import load_breast_cancerfrom sklearn.svm import SVCcancer = load_breast_cancer()X_train,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,random_state=0)svc = SVC()svc.fit(X_train,y_train)print('训练集的精度&#123;:.2&#125;,测试集的精度&#123;:.2&#125;'.format(svc.score(X_train,y_train),svc.score(X_test,y_test))) 训练集的精度1.0,测试集的精度0.63 这个模型在训练集上的分数十分完美，但在测试集上的精度只有63%，存在相当严重的过拟合。虽然SVM的表现通常都很好，但它对参数的设定和数据的缩放非常敏感。特别地，它要求所有特征相似的变化范围。 123456plt.plot(X_train.min(axis=0),'o',label = "min")plt.plot(X_train.max(axis=0),'^',label="max")plt.legend(loc=4)plt.xlabel("Feature index")plt.ylabel("Feature magnitude")plt.yscale("log") 上图中，可以确实数据集的特征具有完全不同的数量级，这对其他模型来说（比如线性模型）可能是小问题但对核SVM却有极大影响。 为SVM预处理数据解决这个问题的一种方法就是对每个特征进行缩放，使其大致都位于同一个范围，常用的缩放方法就是将所有的特征缩放到0和1之间。 123456789#计算训练集中每个特征的最小值min_on_train = X_train.min(axis=0)#计算训练集中每个特征的范围（最大值-最小值）range_on_training = (X_train-min_on_train).max(axis=0)#范围缩放X_train_scaled = (X_train-min_on_train)/range_on_trainingX_test_scaled = (X_test-min_on_train)/range_on_trainingsvc = SVC().fit(X_train_scaled,y_train)print("训练集精度&#123;:.4f&#125;,测试集精度&#123;:.4f&#125;".format(svc.score(X_train_scaled,y_train),svc.score(X_test_scaled,y_test))) 训练集精度0.9484,测试集精度0.9510 数据缩放的作用对结果的提升有很大的作用，但是由于训练集的精度和测试集的精度差不多，而且测试集的精度略高于训练集，说明实际上模型现在处于欠拟合的状态，可以尝试增大参数C和gamma参数，增大模型的复杂度。 12svc = SVC(C=1000).fit(X_train_scaled,y_train)print("训练集精度&#123;:.4f&#125;,测试集精度&#123;:.4f&#125;".format(svc.score(X_train_scaled,y_train),svc.score(X_test_scaled,y_test))) 训练集精度0.9883,测试集精度0.9720 优点、缺点和参数 优点：核支持向量机是非常强大的模型，在各种模型数据集上的表现都很好，SVM允许决策边界很复杂，即使数据只有几个特征。它在低维数据和高维谁（即很少特征和很多特征）上的表现都很好，但对样本个数的缩放表现不好，比如在样本数为10000的数据集上表现良好，但是如果数据增加到1000000甚至更大，在运行时间和内存使用方法可能会面临挑战。 缺点：预处理数据和调参都需要非常小心。这也是为什么如今很多应用中用的都是基于树的模型，比如随机森林或梯度提升（需要很少的预处理，甚至不需要预处理）。此外，SVM模型很难检查，可能很难理解为什么会这么预测，而且也难以将模型向非专家进行解释。 核SVM的参数： 正则化参数C:默认C=1,参数是正则化参数，与线性模型中用到的类似，它限制每个点的重要性。 核的选择：默认kernel=’rbf’,径向基函数。 gamma参数：默认gamma=1/n_features,用于控制高斯核的宽度。它决定了点与点之间“靠近”是指多大的距离。 神经网络（深度学习）一类被称为神经网络的算法最近以“深度学习”的名字再度流行。虽然深度学习在许多机器学习应用中都有巨大的潜力，但深度学习算法往往经过精确调整，只适用于特定的使用场景。但是这里只讨论一些相对简单的方法，即用于分类和回归的多层感知机（multilayer perceptron，MLP）,它可以作为研究更复杂的深度学习方法的起点。MLP也被称为（普通）前馈神经网络，有时也简称为神经网络。 神经网络模型1display(mglearn.plots.plot_logistic_regression_graph()) 上图中，左边的每个节点代表一个输入特征，连线代表学到的系数，右边的节点代表输出，是输入的加权求和。 1display(mglearn.plots.plot_single_hidden_layer_graph()) 这个模型需要学习更多的系数（也叫作权重）：在每个输入与每个隐单元（隐单元组成了隐层）之间有一个系数，在每个隐单元与输出之间也有一个系数。 为了让这个模型真正比线性模型更为强大，还需要一个技巧。在计算完成每个隐单元的加权求和之后，对结果再应用一个非线性函数——通常是校正非线性（rectifying nonlinearity，也叫校正线性单元或relu）或正切双曲线（tangens hyperbolicus，tanh）。然后将这个函数的结果应用于加权求和，计算得到输出y。 1234567import numpy as npline=np.linspace(-3,3,100)plt.plot(line,np.tanh(line),label="tanh")plt.plot(line,np.maximum(line,0),label="relu")plt.legend(loc="best")plt.xlabel("x")plt.ylabel("relu(x),tanh(x)") Text(0,0.5,&apos;relu(x),tanh(x)&apos;) 需要用户设置对的一个重要的参数是隐层的一个重要参数是隐层中的节点个数，对于非常小或非常简单的数据集，这个值可以小到10；对于非常复杂的数据，这个值可以大到1000，也可以添加多个隐层。 1mglearn.plots.plot_two_hidden_layer_graph() 神经网络调参12345678910from sklearn.neural_network import MLPClassifierfrom sklearn.datasets import make_moonsfrom sklearn.model_selection import train_test_splitX,y = make_moons(n_samples=100,noise=0.25,random_state=3)X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)mlp = MLPClassifier(solver='lbfgs',random_state=0).fit(X_train,y_train)mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3)mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 神经网络学到的决策边界完全是非线性的，但相对平滑。默认情况下，MLP使用了100个隐节点，这对于这个小型数据集来说已经相当多了。我们可以减少其数量（从而降低了模型复杂度），但仍然得到很好的结果。 12345mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes=[10]).fit(X_train,y_train)mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3)mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 123456#添加两个隐层单元，每层10个节点mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes=[10,10]).fit(X_train,y_train)mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3)mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 123456#使用tanh非线性激活函数mlp = MLPClassifier(solver='lbfgs',activation='tanh',random_state=0,hidden_layer_sizes=[10,10]).fit(X_train,y_train)mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3)mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 最后，我们可以利用L2惩罚使权重趋向于0，从而控制神经网络的复杂度，正如我们在岭回归和线性分类器中所做的那样。MLPClassifier中调节惩罚参数是alpha（与线性回归和线性分类器中模型相同），它的默认值很小（正则化）。 MLPClassifier(hidden_layer_sizes=(100,), activation=’relu’, solver=’adam’, alpha=0.0001, batch_size=’auto’, learning_rate=’constant’, learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08) 1234567fig,axes = plt.subplots(2,4,figsize=(20,8))for axx,n_hidden_nodes in zip(axes,[10,100]): for ax,alpha in zip(axx,[0.0001,0.01,0.1,1]): mlp = MLPClassifier(solver='lbfgs',random_state=0,hidden_layer_sizes=[n_hidden_nodes,n_hidden_nodes],alpha=alpha).fit(X_train,y_train) mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3,ax=ax) mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train,ax=ax) ax.set_title("n_hidden=[&#123;&#125;,&#123;&#125;]\n alpha=&#123;:.4f&#125;".format(n_hidden_nodes,n_hidden_nodes,alpha)) 控制神经网络复杂度的方法有很多种： 隐层的个数 每个隐层中的单元个数 正则化（alpha） 神经网络的一个重要性质是，在开始学习之前其权重是随机设置的，这种随机初始化会影响学到的模型。也就是说，即使使用完全相同的参数，如果随机种子不同的话，我们也可能得到非常不一样的模型。如果网络很大，并且复杂度选择合理的话，那么这应该不会对精度有太大的影响，但应该记住这一点（特别是对于较小的网咯。） 123456fig,axes = plt.subplots(2,4,figsize=(20,8))for i,ax in enumerate(axes.ravel()): mlp = MLPClassifier(solver='lbfgs',random_state=i,hidden_layer_sizes=[100,100]) mlp.fit(X_train,y_train) mglearn.plots.plot_2d_separator(mlp,X_train,fill=True,alpha=.3,ax=ax) mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train,ax=ax) 12mlp = MLPClassifier(random_state=42).fit(X_train,y_train)print('训练集精度&#123;:.2&#125;,测试集精度&#123;:.2&#125;'.format(mlp.score(X_train,y_train),mlp.score(X_test,y_test))) 训练集精度0.85,测试集精度0.84 D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&apos;t converged yet. % self.max_iter, ConvergenceWarning) 123456789# 计算训练集中的每个特征的平均值mean_on_train = X_train.mean(axis=0)#计算训练集中每个特征的标准差std_on_train = X_train.std(axis=0)#减去平均值，然后乘以标准差的倒数X_train_scaled = (X_train-mean_on_train)/std_on_trainX_test_scaled = (X_test-mean_on_train)/std_on_trainmlp = MLPClassifier(random_state=0).fit(X_train_scaled,y_train)print('训练集精度&#123;:.2&#125;,测试集精度&#123;:.2&#125;'.format(mlp.score(X_train_scaled,y_train),mlp.score(X_test_scaled,y_test))) 训练集精度0.85,测试集精度0.84 D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\neural_network\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&apos;t converged yet. % self.max_iter, ConvergenceWarning) 12mlp = MLPClassifier(max_iter=10000,random_state=0).fit(X_train_scaled,y_train)print('训练集精度&#123;&#125;,测试集精度&#123;&#125;'.format(mlp.score(X_train_scaled,y_train),mlp.score(X_test_scaled,y_test))) 训练集精度0.96,测试集精度1.0 对于python用户来说，最为完善的是keras、lasagna和tensor-flow，lasagna是基于theano库构建的，而keras既可以用tensor-flow也可以用theano。这些库提供了更为灵活的接口，可以用来构建神经网络并跟踪深度学习研究的快速发展。 优点、缺点和参数在机器学习的许多应用中，神经网络再次成为最先进的模型。 优点：能够获取大量数据中包含的信息，并构建无比复杂的模型。给定足够的计算时间和数据，并且仔细调节参数，神经网络通常可以打败其他机器学习算法（无论是分类任务还是回归任务） 缺点：通常需要很长的训练时间，还需要仔细地预处理数据如果数据包含不同种类的特征，那么基于树的模型可能表现得更好。神经网络调参本身也是一门艺术。调节神经网络模型和训练模型的方法有很多种。 估计神经网络的复杂度：最重要的参数是层数和每层的隐单元个数。应该首先设置1个或2个隐层，然后可以逐步增加，每个隐层的节点个数通常与输入特征个数接近，但在几千个节点时很少会多于特征个数。 神经网络的调参的常用的方法时：首先创建一个大到足以过拟合的网络，确保这个网络可以对任务进行学习。知道训练数据可以被学习之后，要么缩小网络，要么增大alpha来增强正则化，可以提高泛化性能。 模型关注的参数： 层数 每层的节点个数 正则化 非线性 求解参数，solver：默认选项是‘adam’，在大多数情况下效果都很好；‘lbfgs’的鲁棒性相当好，但在大型模型或大型数据集上的时间会比较长；‘sgd’许多深度学习研究人员都会用到， 分类器的不确定估计一般来说，你感兴趣的不仅是分类器会预测一个测试点的属于哪个类别，还包括它对这个预测的置信程度。scikit-learn中有两个函数可用于获取分类器的不确定估计： decision_function predict_proba 大多数分类器（但不是全部）都至少有一个函数，很多分类器两个都有。 1234567891011121314from sklearn.ensemble import GradientBoostingClassifierfrom sklearn.datasets import make_circlesimport numpy as npfrom sklearn.model_selection import train_test_splitX,y = make_circles(noise=0.25,factor=0.5)#为了便于说明，将两个类别重命名为“blue”和“red”y_named = np.array(["blue","red"])[y]#我们可以对任意数组调用train_test_splitX_train,X_test,y_train_named,y_test_named ,y_train,y_test = train_test_split(X,y_named,y,random_state = 0)#构建梯度提升模型gbrt = GradientBoostingClassifier(random_state=0).fit(X_train,y_train_named) 决策函数对于二分类的情况，decision_function返回值的形状是（n_samples，），为每个样本都返回一个浮点数： 12print("X_test.shape:&#123;&#125;".format(X_test.shape))print('Decision function shape:&#123;&#125;'.format(gbrt.decision_function(X_test).shape)) X_test.shape:(25, 2) Decision function shape:(25,) 12# 显示decision_function前几个元素print("Decision function:&#123;&#125;".format(gbrt.decision_function(X_test)[:6])) Decision function:[-1.35041692 4.26214626 -3.93710237 0.00509282 3.80609676 3.26549305] 123#转化为正负号print("Thresholded decision:&#123;&#125;".format(gbrt.decision_function(X_test)&gt;0))print("predictions:&#123;&#125;".format(gbrt.predict(X_test))) Thresholded decision:[False True False True True True True False False True False False False False False True True True True False True False False False False] predictions:[&apos;blue&apos; &apos;red&apos; &apos;blue&apos; &apos;red&apos; &apos;red&apos; &apos;red&apos; &apos;red&apos; &apos;blue&apos; &apos;blue&apos; &apos;red&apos; &apos;blue&apos; &apos;blue&apos; &apos;blue&apos; &apos;blue&apos; &apos;blue&apos; &apos;red&apos; &apos;red&apos; &apos;red&apos; &apos;red&apos; &apos;blue&apos; &apos;red&apos; &apos;blue&apos; &apos;blue&apos; &apos;blue&apos; &apos;blue&apos;] decision_function可以在任意范围取值，这取决于数据与模型参数，由于可以任意缩放，因此decision_function的输出往往很难解释。 123456789101112import mglearnimport matplotlib.pyplot as pltfig,axes =plt.subplots(1,2,figsize =(13,5))mglearn.tools.plot_2d_separator(gbrt,X,ax=axes[0],alpha=.4,fill=True,cm=mglearn.cm2)scores_image = mglearn.tools.plot_2d_scores(gbrt,X,ax=axes[1],alpha=.4,cm=mglearn.ReBl)for ax in axes: mglearn.discrete_scatter(X_test[:,0],X_test[:,1],y_test,markers='^',ax=ax) mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train,markers='o',ax=ax) ax.set_title("Feature 0") ax.set_title("Feature 1")cbar = plt.colorbar(scores_image,ax=axes.tolist())axes[0].legend(&#123;"Test class 0 ","Test class 1","Train class 0","Train class 1"&#125;,ncol=4,loc=(.1,1.1)) &lt;matplotlib.legend.Legend at 0x1db64a350b8&gt; 上面两图中，既给出预测结果，又给出分类器的置信程度，这样给出的信息量更大。但在上面的图像中，很难分辨出两个类别之间的边界。 预测的概率.predict_proba的输出是每.个类别的概率，.通常比decision_function的输出更容易理解，对.于二分类问题，它的形状始终是（n_samples,2）。 12print("shape of probabilities:&#123;&#125;".format(gbrt.predict_proba(X_test).shape))print("Predicted probabilities:\n&#123;&#125;".format(gbrt.predict_proba(X_train)[:11])) shape of probabilities:(25, 2) Predicted probabilities: [[0.01163371 0.98836629] [0.97144005 0.02855995] [0.02785793 0.97214207] [0.01163371 0.98836629] [0.98663291 0.01336709] [0.0125965 0.9874035 ] [0.01045788 0.98954212] [0.98876325 0.01123675] [0.97906531 0.02093469] [0.9734402 0.0265598 ] [0.01747954 0.98252046]] 由于两个类别的概率之和为1，因此只有一个类别的概率超过50%，这个类别就是模型的预测结果。 分类器对大部分点的置信程度都相对较高的。不确定度大小实际上反映了数据依赖于模型和参数的不确定度。过拟合更强的模型可能会做出置信程度更高的预测，即使可能是错的。复杂度越低的模型通常对预测的不确定度越大。如果模型给出的不确定度符合实际情况，那么这个模型被称为校正（calibrated）模型。在校正模型总，如果预测有70%的确定度，那么它在70%的情况下正确。 123456789101112import mglearnimport matplotlib.pyplot as pltfig,axes =plt.subplots(1,2,figsize =(13,5))mglearn.tools.plot_2d_separator(gbrt,X,ax=axes[0],alpha=.4,fill=True,cm=mglearn.cm2)scores_image = mglearn.tools.plot_2d_scores(gbrt,X,ax=axes[1],alpha=.4,cm=mglearn.ReBl,function='predict_proba')for ax in axes: mglearn.discrete_scatter(X_test[:,0],X_test[:,1],y_test,markers='^',ax=ax) mglearn.discrete_scatter(X_train[:,0],X_train[:,1],y_train,markers='o',ax=ax) ax.set_title("Feature 0") ax.set_title("Feature 1")cbar = plt.colorbar(scores_image,ax=axes.tolist())axes[0].legend(&#123;"Test class 0 ","Test class 1","Train class 0","Train class 1"&#125;,ncol=4,loc=(.1,1.1)) &lt;matplotlib.legend.Legend at 0x1db65de93c8&gt; 多分类问题的不确定度decision_function和predict_proba也适用于多分类问题。 123456from sklearn.datasets import load_irisiris = load_iris()X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state= 42)gbrt= GradientBoostingClassifier(learning_rate=0.01,random_state=0).fit(X_train,y_train)print("Decision function shape:&#123;&#125;".format(gbrt.decision_function(X_test).shape))print("Decision function:\n&#123;&#125;".format(gbrt.decision_function(X_test)[:6,:])) Decision function shape:(38, 3) Decision function: [[-0.52931069 1.46560359 -0.50448467] [ 1.51154215 -0.49561142 -0.50310736] [-0.52379401 -0.4676268 1.51953786] [-0.52931069 1.46560359 -0.50448467] [-0.53107259 1.28190451 0.21510024] [ 1.51154215 -0.49561142 -0.50310736]] 多于多分类的情况，decision_function的形状为（n_samples,n_classes）,每一列对应每个类别的“确定度分数”，分数较高的类别可能性更大，得分较低的类别可能性较小。可以找出每个数据点的最大元素，从而利用这些分数再现预测结果： 12print("argmax of decision function:\n&#123;&#125;".format(np.argmax(gbrt.decision_function(X_test),axis=1)))print("predictions\n&#123;&#125;".format(gbrt.predict(X_test))) argmax of decision function: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0] predictions [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0] predict_proba输出的形状相同，也是（n_samples,n_classes）,同样，每个数据点所有可能类别的概率之和为1。 1234# 显示predict_proba的前几个元素print("predicted probabilities:\n&#123;&#125;".format(gbrt.predict_proba(X_test)[:6]))# 显示每行的和都是1print("sums:&#123;&#125;".format(gbrt.predict_proba(X_test)[:6].sum(axis=1))) predicted probabilities: [[0.10664722 0.7840248 0.10932798] [0.78880668 0.10599243 0.10520089] [0.10231173 0.10822274 0.78946553] [0.10664722 0.7840248 0.10932798] [0.10825347 0.66344934 0.22829719] [0.78880668 0.10599243 0.10520089]] sums:[1. 1. 1. 1. 1. 1.] 小结与展望 最近邻 适用于小型数据集，是很好的基准模型，很容解释。 线性模型 非常可靠的首选算法，适用于非常大的数据集，也适用于高维数据。 决策树 速度很快，不需要数据缩放，可以可视化，很容易解释 随机森林 几乎总是比单棵决策树的表现要好，鲁棒性很好，非常强大。不适用于高维稀疏数据。 梯度提升决策树 精度通常比随机森林略高。与随机森林相比，训练速度更慢，但预测速度更快，需要的内存也更少。比随机森林需要更多的参数调节。 支持向量机 对于特征含义相似的中等大小的数据集很强大。需要数据缩放，对参数敏感。 神经网络 可以构建非常复杂的模型，特别是对于大型数据集而言。对数据缩放敏感，对参数选取敏感，大型网络需要很长的训练时间。 面对新数据集，通常最好先从简单模型开始，比如线性模型、朴素贝叶斯或最近邻分类器，看能得到什么样的结果。对数据有了进一步了解之后，可以考虑用于构建更复杂模型的算法，比如随机森林、梯度提升决策树、SVM或神经网络。 无监督学习与预处理无监督学习包括没有已知输出，没有老师指导学习算法的各种机器学习算法。在无监督学习中，学习算法只有输入数据，并需要从这些数据中提取知识。 无监督学习的类型 降维：接受包含许多特征的数据高维表示，并找到表示该数据的一种新方法，用较少的特征就可以概括其重要特性。 主体提取：找到每个文档中讨论的未知主题，并学习每个文档中出现了哪些主题。 聚类：将数据划分成不同的组，每组包含相似的物项。 无监督学习的挑战无监督学习的一个主要挑战就是评估算法是否学到了有用的东西。无监督学习算法一般用于不包含任何标签信息的数据，所以我们不知道正确的输出应该是什么。因此很难判断一个模型是否“表现很好”。评估无监督算法结果的唯一方法就是人工检查。 预处理与缩放一些算法（神经网络和SVM）对数据缩放非常敏感。因此，通常的做法是对特征进行调节，使数据表示更适合于这些算法。通常来说，这是对数据的一种简单的按特征的缩放和移动。 12import mglearnmglearn.plots.plot_scaling() 不同类型的预处理 StandardScaler:确保每个特征的平均值为0、方差为1，使所有特征都位于同一量级。 RobustScaler:确保每个特征的统计属性都位于同一范围，但RobustScaler使用的是中位数和四分位数，而不是平均值和方差。这样RobustScaler会忽略与其他点有很大不同的数据点（比如测量误差）。 MinMaxScaler：使所有的特征刚好位于0到1之间。 Normalizer：一种完全不同的缩放方法，它对每个数据点进行缩放，使得特征向量的欧式长度等于1。换句话说，它将一个数据点投射到半径为1的圆上（对于更高维的情况，是球面）。这意味着每个数据点的缩放比例都不相同（乘以其长度的倒数）。 123456from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_splitcancer = load_breast_cancer()X_trian,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,random_state =1)print(X_trian.shape)print(X_test.shape) (426, 30) (143, 30) 123from sklearn.preprocessing import MinMaxScalerscaler = MinMaxScaler()scaler.fit(X_trian) MinMaxScaler(copy=True, feature_range=(0, 1)) 使用fit方法拟合缩放器（scaler），并将其应用于训练数据。对于MinMaxScaler来说，fit方法计算训练集中每个特征大最大值和最小值。与第2章中的分类器和回归器不同，在对缩放器调用fit只提供了X_train，而不用y_train。 12345678#变换数据X_train_scaled = scaler.transform(X_trian)# 在缩放之前和之后分别打印数据集属性print("transformed shape:&#123;&#125;".format(X_train_scaled.shape))print("per-feature minimum before scaling:\n &#123;&#125;".format(X_trian.min(axis=0)))print("per-feature maximum before scaling:\n &#123;&#125;".format(X_trian.max(axis=0)))print("per-feature minimum after scaling:\n &#123;&#125;".format(X_train_scaled.min(axis=0)))print("per-feature maximum after scaling:\n &#123;&#125;".format(X_train_scaled.max(axis=0))) transformed shape:(426, 30) per-feature minimum before scaling: [6.981e+00 9.710e+00 4.379e+01 1.435e+02 5.263e-02 1.938e-02 0.000e+00 0.000e+00 1.060e-01 5.024e-02 1.153e-01 3.602e-01 7.570e-01 6.802e+00 1.713e-03 2.252e-03 0.000e+00 0.000e+00 9.539e-03 8.948e-04 7.930e+00 1.202e+01 5.041e+01 1.852e+02 7.117e-02 2.729e-02 0.000e+00 0.000e+00 1.566e-01 5.521e-02] per-feature maximum before scaling: [2.811e+01 3.928e+01 1.885e+02 2.501e+03 1.634e-01 2.867e-01 4.268e-01 2.012e-01 3.040e-01 9.575e-02 2.873e+00 4.885e+00 2.198e+01 5.422e+02 3.113e-02 1.354e-01 3.960e-01 5.279e-02 6.146e-02 2.984e-02 3.604e+01 4.954e+01 2.512e+02 4.254e+03 2.226e-01 9.379e-01 1.170e+00 2.910e-01 5.774e-01 1.486e-01] per-feature minimum after scaling: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] per-feature maximum after scaling: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 变换后的数据形状与原始数据相同，特征只是发生了移动和缩放。可以看到，现在所有特征都位于0到1之间，这也符合我们的预期。 1234#对测试集进行变换X_test_scaler = scaler.transform(X_test)print("per-feature minimum after scaling:\n &#123;&#125;".format(X_test_scaler.min(axis=0)))print("per-feature maximum after scaling:\n &#123;&#125;".format(X_test_scaler.max(axis=0))) per-feature minimum after scaling: [ 0.0336031 0.0226581 0.03144219 0.01141039 0.14128374 0.04406704 0. 0. 0.1540404 -0.00615249 -0.00137796 0.00594501 0.00430665 0.00079567 0.03919502 0.0112206 0. 0. -0.03191387 0.00664013 0.02660975 0.05810235 0.02031974 0.00943767 0.1094235 0.02637792 0. 0. -0.00023764 -0.00182032] per-feature maximum after scaling: [0.9578778 0.81501522 0.95577362 0.89353128 0.81132075 1.21958701 0.87956888 0.9333996 0.93232323 1.0371347 0.42669616 0.49765736 0.44117231 0.28371044 0.48703131 0.73863671 0.76717172 0.62928585 1.33685792 0.39057253 0.89612238 0.79317697 0.84859804 0.74488793 0.9154725 1.13188961 1.07008547 0.92371134 1.20532319 1.63068851] 可以发现缩放后的最大值和最小值不是1和0，有些特征甚至在0~1的范围之外！MinMaxScaler(以及其他所有缩放器)总是对训练集和测试集应用完全相同的变换。也就是说，transform方法总是减去训练集的最小值，然后除以训练集的范围，而这两个值与测试集的最小值个范围并不相同。 12345678910111213141516171819202122232425262728293031323334from sklearn.datasets import make_blobsimport matplotlib.pyplot as pltimport mglearn#g构造数据X,_ = make_blobs(n_samples=50,centers=5,random_state=4,cluster_std=2)X_train,X_test=train_test_split(X,random_state=5,test_size=.1)#绘制训练集和测试集fig,axes = plt.subplots(1,3,figsize=(13,5))axes[0].scatter(X_train[:,0],X_train[:,1],c=mglearn.cm2(0),label="Training Set",s=60)axes[0].scatter(X_test[:,0],X_test[:,1],c=mglearn.cm2(1),label="Test Set",s=60,marker='^')axes[0].legend(loc ="upper left")axes[0].set_title("Origin Data")# 利用MinMaxScaler正确缩放数据scaler = MinMaxScaler()scaler.fit(X_train)X_train_scaled = scaler.transform(X_train)X_test_scaled = scaler.transform(X_test)axes[1].scatter(X_train_scaled[:,0],X_train_scaled[:,1],c=mglearn.cm2(0),label="Training Set",s=60)axes[1].scatter(X_test_scaled[:,0],X_test_scaled[:,1],c=mglearn.cm2(1),label="Test Set",s=60,marker='^')axes[1].set_title("Scaled Data")## 利用MinMaxScaler错误缩放数据，对每个数据进行缩放test_scaler = MinMaxScaler()test_scaler.fit(X_test)X_test_scaled_badly = test_scaler.transform(X_test)axes[2].scatter(X_train_scaled[:,0],X_train_scaled[:,1],c=mglearn.cm2(0),label="Training Set",s=60)axes[2].scatter(X_test_scaled_badly[:,0],X_test_scaled_badly[:,1],c=mglearn.cm2(1),label="Test Set",s=60,marker='^')axes[2].set_title("Improperly Scaled Data")for ax in axes: ax.set_xlabel("Feature 0") ax.set_ylabel("Feature 1") 第一张图是未缩放的二维数据集，其中训练集用圆形表示，测试集用三角形表示。 第二张图中是同样的数据，但使用MinMaxScaler缩放。第二张图中的数据集看起来与第一张图中的完全相同，知识坐标轴刻度发生了变化。但是测试数据的特征最大值和最小值并不是0和1。 第三张展示了如果我们对训练集和测试集分别进行缩放会发生什么。在这种情况下，对训练集和测试集而言，特征的最大值和最小值都是1和0。但现在数据集看起来不一样。测试集相对训练集的移动不一致，因为它们分别做啦吧不同的缩放，随意改变了数据的排列，这显然是错误的。 1234567#快捷与高效的替代方法from sklearn.preprocessing import StandardScalerscaler = StandardScaler()# 依次调用fit和transform（使用方法链）X_scaled_m1 = scaler.fit(X_train).transform(X_train)# 结果相同，但计算更加高效X_scaled_m2 = scaler.fit_transform(X_train) 预处理对监督学习的作用12345from sklearn.svm import SVCX_train,X_test,y_train,y_test=train_test_split(cancer.data,cancer.target,random_state=0)svm = SVC(C=100)svm.fit(X_train,y_train)print("Nothong Test set accuracy:&#123;:.2&#125;".format(svm.score(X_test,y_test))) Nothong Test set accuracy:0.63 12345scaler = MinMaxScaler()X_train_scaled = scaler.fit_transform(X_train)X_test_scaled = scaler.transform(X_test)svm.fit(X_train_scaled,y_train)print("MinMaxScaler Test set accuracy:&#123;:.2&#125;".format(svm.score(X_test_scaled,y_test))) MinMaxScaler Test set accuracy:0.97 12345scaler = StandardScaler()X_train_scaled = scaler.fit_transform(X_train)X_test_scaled = scaler.transform(X_test)svm.fit(X_train_scaled,y_train)print("StandardScaler Test set accuracy:&#123;:.2&#125;".format(svm.score(X_test_scaled,y_test))) StandardScaler Test set accuracy:0.96 正如我们上面所见，数据缩放的作用非常显著。虽然数据缩放不涉及任何复杂的数学，但良好的做法仍然是使用scikit-learn提供的缩放机制，而不是自己重新实现它们，因为即使在这些简单的计算中也容易放错。 降维、特征提取与流行学习利用无监督学习进行数据变换可能有很多种目的，最常见的目的就是可视化、压缩数据，以及寻找信息量更大的数据表示以用于进一步的处理。 主成分分析 非负矩阵分解（NMF） t-SNE第一个通常用于特征提取，后面通常用于二维散点图的可视化 主成分分析主成分分析（principal component analysis,PCA）是一种旋转数据集的方法，旋转后的特征在统计上不相关。在做完这种旋转之后，通常是根据新特征对解释数据的重要性来选择它的一个子集。 1mglearn.plots.plot_pca_illustration() 第一张图显示的是原始数据点，用不同颜色加以区分。 第二张图，显示的同样的数据，但现在将其旋转，使得第一主成分与x轴平行且第二主成分与y轴平行。在旋转之前，从数据中减去平均值。使得变换后的数据以零为中心。在PCA找到的旋转表示中，两个坐标轴是不相关的，也就是说，对于这种数据表示，除对角线，相关矩阵全部为零。 第三张图，将数据从二维数据集降为一维数据集。 第四张图，可以反向旋转并将平均值重新加到数据中。 1、将PCA应用于cancer数据集并可视化 PCA最常见的应用之一就是将高维数据可视化。不过有一种更简单的可视化方法——对每个特征分别计算两个类别。 12345678910111213141516171819import numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import load_breast_cancerimport mglearncancer = load_breast_cancer()fig,axes = plt.subplots(15,2,figsize=(10,20))malignant = cancer.data[cancer.target==0]begin = cancer.data[cancer.target==1]ax=axes.ravel()for i in range(30): _,bins = np.histogram(cancer.data[:,i],bins=50) ax[i].hist(malignant[:,i],bins=bins,color=mglearn.cm3(0),alpha=.5) ax[i].hist(begin[:,i],bins=bins,color=mglearn.cm3(2),alpha=.5) ax[i].set_title(cancer.feature_names[i]) ax[i].set_yticks(())ax[0].set_xlabel("Feature magnitude")ax[0].set_ylabel("Frequency")ax[0].legend(["malignant","begin"],loc="best")fig.tight_layout() 这里为每个特征创建一个直方图，计算具有某一特征的数据点在特定范围内（叫作bin）的出现频率。每张图都包含两个直方图一个是良性类别的所有点（蓝色），一个是恶性类别的所有点（红色）。这样我们可以了解每个特征在两个类别中的分布情况，也可以猜测哪些特征能够好地区分良性样本和恶性样本。例如“smoothness error”特征似乎没有什么信息量，因为两个直方图大部分都重叠在一起，而“worst concave points”特征看起来信息量相当大，因为两个直方图的交集很小。 在应用PCA之前，利用StandarScaler缩放数据，使每个特征的方差均为1。 1234from sklearn.preprocessing import StandardScalerscaler = StandardScaler()scaler.fit(cancer.data)X_scaled = scaler.transform(cancer.data) 学习并应用PCA变换与应用预处理变换一样简单。将PCA对象实例化，调用fit方法找到主成分，然后调用transform来旋转并降维。默认情况下，PCA仅旋转（并移动）数据，但保留所有的主成分。为了降低数据的维度，需要在创建PCA对象时指定想要保留的主成分个数。 123456789from sklearn.decomposition import PCA# 保留数据前两个成分pca = PCA(n_components=2)#对数据拟合pca模型pca.fit(X_scaled)#将数据变换到前两个主成分的方向上X_pca = pca.transform(X_scaled)print("Origin shape:&#123;&#125;".format(str(X_scaled.shape)))print("Reduced shape:&#123;&#125;".format(str(X_pca.shape))) Origin shape:(569, 30) Reduced shape:(569, 2) 1234567#对第一个第二个主成分作图，按类别着色plt.figure(figsize=(8,8))mglearn.discrete_scatter(X_pca[:,0],X_pca[:,1],cancer.target)plt.legend(cancer.target_names,loc="best")plt.gca().set_aspect("equal")plt.xlabel("First principal component")plt.ylabel("Second principal component") Text(0,0.5,&apos;Second principal component&apos;) PCA是一种无监督方法，在寻找旋转方向时没有用到任何类别信息。PCA的一个缺点在于，通常不容易对图中的两个轴做出解释，主成分对应于原始数据中的方向，所以它们是原始特征的组合，但这些组合往往非常复杂。 12print("PCA component shape:&#123;&#125;".format(pca.components_.shape))print("PCA components:\n&#123;&#125;".format(pca.components_)) PCA component shape:(2, 30) PCA components: [[ 0.21890244 0.10372458 0.22753729 0.22099499 0.14258969 0.23928535 0.25840048 0.26085376 0.13816696 0.06436335 0.20597878 0.01742803 0.21132592 0.20286964 0.01453145 0.17039345 0.15358979 0.1834174 0.04249842 0.10256832 0.22799663 0.10446933 0.23663968 0.22487053 0.12795256 0.21009588 0.22876753 0.25088597 0.12290456 0.13178394] [-0.23385713 -0.05970609 -0.21518136 -0.23107671 0.18611302 0.15189161 0.06016536 -0.0347675 0.19034877 0.36657547 -0.10555215 0.08997968 -0.08945723 -0.15229263 0.20443045 0.2327159 0.19720728 0.13032156 0.183848 0.28009203 -0.21986638 -0.0454673 -0.19987843 -0.21935186 0.17230435 0.14359317 0.09796411 -0.00825724 0.14188335 0.27533947]] 1234567#用热力图将系数可视化plt.matshow(pca.components_,cmap="viridis")plt.yticks([0,1],["First component","Second component"])plt.colorbar()plt.xticks(range(len(cancer.feature_names)),cancer.feature_names,rotation=60,ha='left')plt.xlabel("Feature")plt.ylabel("Principal components") Text(0,0.5,&apos;Principal components&apos;) 可以看到，在第一个主成分中，所有特征的符号相同（均为正，但前面我们提到过，箭头指向哪个方向无关紧要）。这意味着在所有特征之间存在普遍的相关性。如果一个测量值较大的话，其他的测量值可能也较大。 第二个主成分的符号有正有负，而且两个主成分包含所有30个特征。 2、特征提取的特征脸 特征提取：找到一种数据表示，比给定的原始表示更适合分析。一个很好的应用实例就是图像，图像由像素组成，通常储存为红绿蓝（RGB）强度。 非负矩阵分解非负矩阵分解（non-negative matrix factorization,NMF）是另一种无监督学习算法，其目的在于提取有用的特征。它的工作原理类似PCA，也可以用于降维。 与PCA相同点，试图将每个数据点写成一些分量的加权求和 与PCA不同点，PCA要的是正交分量，并且能够解释尽可能多的数据方差；而NMF中，希望分量和系数均为非负，希望分量和系数都大于0或等于0。 缺陷：这种方法只能应用于每个特征都是非负的数据，因为非负分量的非负求和不可能变为负值。 总结：与PCA相比，NMF得到的分量更容易解释，因为为负的分量可能会导致难以解释的抵消效应。 1mglearn.plots.plot_nmf_illustration() 对于两个分量的NMF（左图所示），显然所有数据点都可以写成这两个分量的正数组合。如果有足够多的分量能够完美地重建数据（分量的个数与特征个数相同），那么算法会选择指向数据极值的方向。 如果仅使用一个分量，那么NMF会创建一个指向平均值的分量，因为指向这里可以对数据做出最好的解释。 用t-SNE进行流形学习虽然PCA通常用于变换数据的首选方法，使能够用散点图将其可视化，但这一方法的性质（先旋转然后减少方向）限制了其有效性。有一类用于可视化的算法叫作流形学习算法，它允许进行更复杂的映射，用处也可以给出更好的可视化，其中特别有用的一个就是t-SNE算法。 流形学习算法主要用于可视化，因此很少用来生成两个以上的新特征。 流形学习对探索性数据分析是很有用的，但如果最终目标是监督学习的话，则很少用。 原理：找到数据的一个二维表示，尽可能地保持数据点之间的距离。t-SNE首先给出每个数据点的随机二维点表示，然后尝试让在原始特征空间中距离较近的点更加靠近，原始特征空间中相距较远的点更加远离。t-SNE重点关注距离较近的点，而不是保持距离较远的点之间的距离，它试图保存那些表示哪些点比较靠近的信息。 123456from sklearn.datasets import load_digitsimport matplotlib.pyplot as pltdigits = load_digits()fig,axes = plt.subplots(2,5,figsize=(10,5),subplot_kw=&#123;"xticks":(),"yticks":()&#125;)for ax,img in zip(axes.ravel(),digits.images): ax.imshow(img) 123456789101112131415from sklearn.decomposition import PCA#用PCA将将到二维数据可视化pca= PCA(n_components=2)pca.fit(digits.data)#将digits数据变换到前两个主成分的方向上digits_pca = pca.transform(digits.data)colors = ["#476A2A","#7851BB","#BD3430","#4A2D4E","#875525","#A83683","#4E655E","#853541","#3A3120","#535D8E"]plt.figure(figsize=(10,10))plt.xlim(digits_pca[:,0].min(),digits_pca[:,0].max())plt.ylim(digits_pca[:,1].min(),digits_pca[:,1].max())for i in range(len(digits.data)): #将数据实际绘制成文本，而不是散点 plt.text(digits_pca[i,0],digits_pca[i,1],str(digits.target[i]),color = colors[digits.target[i]],fontdict=&#123;"weight":"bold","size":9&#125;)plt.xlabel("First principal component")plt.ylabel("Second principal component") Text(0,0.5,&apos;Second principal component&apos;) 这里每个类别对应数字作为符号来显示每个类别的位置。利用前两个主成分可以将数字0、6和4相对较好的地分开，尽管仍有重叠。大部分其他数字都大量重叠在一起。 1234#使用tsne变换数据from sklearn.manifold import TSNEtsne = TSNE(random_state=42)digists_tsne = tsne.fit_transform(digits.data) 12345678plt.figure(figsize=(10,10))plt.xlim(digists_tsne[:,0].min(),digists_tsne[:,0].max()+1)plt.ylim(digists_tsne[:,1].min(),digists_tsne[:,1].max()+1)for i in range(len(digits.data)): #将数据实际绘制成文本，而不是散点 plt.text(digists_tsne[i,0],digists_tsne[i,1],str(digits.target[i]),color = colors[digits.target[i]],fontdict=&#123;"weight":"bold","size":9&#125;)plt.xlabel("t-SNE feature 0")plt.ylabel("t-SNE feature 1") Text(0,0.5,&apos;t-SNE feature 1&apos;) t-SNE的结果非常棒，多有类别都被明确分开。数字1和9被分成几块，但大多数类别都形成一个密集的组。 聚类聚类（clustering）是将数据集划分成组的任务，这些组叫作簇（cluster）。 其目标是划分数据，使得一个簇内的数据点非常相似且不同簇内的数据点非常不同。 与分类算法相似，聚类算法为每个数据点分配（或预测）一个数字，表示这个点属于哪个簇。 k均值聚类k均值聚类是最简单也是最常用的聚类算法之一。它试图找到代表数据特定区域的簇中心。算法交替执行以下两个步骤： 将每个数据点分配给最近的簇中心，然后将每个簇中心设置为所分配的所有数据点的平均值。 重复上面过程，如果簇的分配不再发生变化，那么算法结束。 12import mglearnmglearn.plots.plot_kmeans_algorithm() 1mglearn.plots.plot_kmeans_boundaries() 123456789from sklearn.datasets import make_blobsfrom sklearn.cluster import KMeans#生成模拟的二维数据X,y = make_blobs(random_state=1)#构建聚类模型kmeans = KMeans(n_clusters=3)kmeans.fit(X)print("Cluster memberships:\n&#123;&#125;".format(kmeans.labels_)) Cluster memberships: [1 0 0 0 2 2 2 0 1 1 0 0 2 1 2 2 2 1 0 0 2 0 2 1 0 2 2 1 1 2 1 1 2 1 0 2 0 0 0 2 2 0 1 0 0 2 1 1 1 1 0 2 2 2 1 2 0 0 1 1 0 2 2 0 0 2 1 2 1 0 0 0 2 1 1 0 2 2 1 0 1 0 0 2 1 1 1 1 0 1 2 1 1 0 0 2 2 1 2 1] 可以看到，聚类算法与分类算法有些类似，每个元素都有一个标签。但并不存在真实的标签，因此标签本身没有先验意义。而且每次运行聚类算法可能会得到不同的簇编号，原因在于初始化的随机性质。 12mglearn.discrete_scatter(X[:,0],X[:,1],kmeans.labels_,markers='o')mglearn.discrete_scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],[0,1,2],markers='^',markeredgewidth=2) [&lt;matplotlib.lines.Line2D at 0x24431414470&gt;, &lt;matplotlib.lines.Line2D at 0x24431414400&gt;, &lt;matplotlib.lines.Line2D at 0x24431420a90&gt;] 可以使用更多或更少的簇中心 12345678910111213fig,axes = plt.subplots(1,2,figsize=(10,5))#使用2个簇类中心kmeans = KMeans(n_clusters=2)kmeans.fit(X)assignments = kmeans.labels_mglearn.discrete_scatter(X[:,0],X[:,1],assignments,ax=axes[0])#使用5个簇类中心kmeans = KMeans(n_clusters=5)kmeans.fit(X)assignments = kmeans.labels_mglearn.discrete_scatter(X[:,0],X[:,1],assignments,ax=axes[1]) [&lt;matplotlib.lines.Line2D at 0x24430f0d160&gt;, &lt;matplotlib.lines.Line2D at 0x24430f0d588&gt;, &lt;matplotlib.lines.Line2D at 0x24430f0da20&gt;, &lt;matplotlib.lines.Line2D at 0x24430f0de48&gt;, &lt;matplotlib.lines.Line2D at 0x24430ee12b0&gt;] 1.k均值的失败案例 即使你指定给定数据集中簇的“正确”个数，k均值可能也不是总能找到它们。 每个簇仅由其中心定义，这意味着每个簇都是凸形。 k均值只能找到相对简单的形状。 k均值还假设所有簇在某种程度上具有相同的“直径”，它总是将簇之间的边界刚好画在簇中心的中间位置。 123456x_varied,y_varied = make_blobs(n_samples=200,cluster_std=[1.0,2.5,0.5],random_state=170)y_pred = KMeans(n_clusters=3,random_state=0).fit_predict(x_varied)mglearn.discrete_scatter(x_varied[:,0],x_varied[:,1],y_pred)plt.legend(["cluster 0","cluster 1","cluster 2"],loc="best")plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 图表显示，左下方的密集区域是第一个簇，右上方的密集区域是第二个，中间密度较小的区域是第三个。但事实上，簇0和簇1都包含一些远离簇中的其他点的点。k均值还假设所有方向对每个簇都同等重要。图表显示，数据中包含明确分开的三部分。但是这三部分被沿着对角线方向拉长。由于k均值仅考虑到最近簇中心的距离，所以它无法处理这种类型的数据： 12345678910111213141516171819#生成一些随机分组数据import numpy as npX,y = make_blobs(random_state=170,n_samples=600)rng = np.random.RandomState(74)#变换数据使其拉长transformation = rng.normal(size=(2,2))X = np.dot(X,transformation)#将数据聚类成3个簇kmeans = KMeans(n_clusters=3)kmeans.fit(X)y_pred = kmeans.predict(X)#画图plt.scatter(X[:,0],X[:,1],c=y_pred,cmap=mglearn.cm3)plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],marker='^',c=[0,1,2],s=100,linewidths=2,cmap=mglearn.cm3)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 如果簇的形状更加复杂，那么k均值的表现也很差。 1234567891011121314#生成模拟的two_moons数据from sklearn.datasets import make_moonsX,y = make_moons(n_samples=200,noise=0.05,random_state=0)#将数据聚类成2个簇kmeans = KMeans(n_clusters=2)kmeans.fit(X)y_pred = kmeans.predict(X)#画出簇分配和簇中心plt.scatter(X[:,0],X[:,1],c=y_pred,cmap=mglearn.cm2,s=60)plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],marker='^',c=[mglearn.cm2(0),mglearn.cm2(1)],s=100,linewidths=2)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 2.矢量量化，或者将k均值看作分解 虽然k均值是一种聚类算法，但在k均值和分解方法（比如之前讨论过的PCA和NMF）之间存在一些有趣的相似之处。 PCA试图找到数据中方差最大的方向，二NMF试图找到累加的分量，这通常对应于数据的“极值”或“部分”。两种方法都试图将数据点表示为一些分量之和。 k均值则尝试利用簇类中心来表示每个数据点，可以将其看作仅用一个分量来表示每个数据点，该分量有簇中心给出。这种观点将k均值看作是一种分解方法，其中每个点用单一分量来表示，这种观点被称为矢量量化。 利用k均值做矢量量化的一个有趣之处在于，可以用比输入维度更多的簇来对数据进行编码。让我们回到two_moons数据。利用PCA或NMF，对这个数据无能为力，因为它只有两个维度。使用PCA或NMF将其降到一维，将会完全破坏数据的结构。但通过对使用更多的簇中心，我们可以用k均值找到一种更具表现力的表示。 123456789X,y = make_moons(n_samples=200,noise=0.05,random_state=0)kmeans=KMeans(n_clusters=10,random_state=0)kmeans.fit(X)y_pred = kmeans.predict(X)plt.scatter(X[:,0],X[:,1],c=y_pred,s=60,cmap='Paired')plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=60,marker='^',c=range(kmeans.n_clusters),linewidths=2,cmap='Paired')plt.xlabel("Feature 0")plt.ylabel("Feature 1")print("Cluster memberships:\n&#123;&#125;".format(y_pred)) Cluster memberships: [9 2 5 4 2 7 9 6 9 6 1 0 2 6 1 9 3 0 3 1 7 6 8 6 8 5 2 7 5 8 9 8 6 5 3 7 0 9 4 5 0 1 3 5 2 8 9 1 5 6 1 0 7 4 6 3 3 6 3 8 0 4 2 9 6 4 8 2 8 4 0 4 0 5 6 4 5 9 3 0 7 8 0 7 5 8 9 8 0 7 3 9 7 1 7 2 2 0 4 5 6 7 8 9 4 5 4 1 2 3 1 8 8 4 9 2 3 7 0 9 9 1 5 8 5 1 9 5 6 7 9 1 4 0 6 2 6 4 7 9 5 5 3 8 1 9 5 6 3 5 0 2 9 3 0 8 6 0 3 3 5 6 3 2 0 2 3 0 2 6 3 4 4 1 5 6 7 1 1 3 2 4 7 2 7 3 8 6 4 1 4 3 9 9 5 1 7 5 8 2] 使用了10个簇中心，也就是说，现在每个点都被分配了0到9之间的一个数字。 我们可以将其看作10个分量表示的数据（10个新特征），只有表示该点对应簇中心的那个特征不为0，其他特征均为0。利用这个10维表示，现在可以用线性模型来划分两个半月形，而利用原始的两个特征是不可能做到这一点的。 将到每个簇中心的距离作为特征，还可以得到一种表现力更强的数据表示。可以利用kmeans的transform方法来完成这一点。 123distance_features = kmeans.transform(X)print("Distance feature shape:&#123;&#125;".format(distance_features.shape))print("Distance features:\n&#123;&#125;".format(distance_features)) Distance feature shape:(200, 10) Distance features: [[0.9220768 1.46553151 1.13956805 ... 1.16559918 1.03852189 0.23340263] [1.14159679 2.51721597 0.1199124 ... 0.70700803 2.20414144 0.98271691] [0.78786246 0.77354687 1.74914157 ... 1.97061341 0.71561277 0.94399739] ... [0.44639122 1.10631579 1.48991975 ... 1.79125448 1.03195812 0.81205971] [1.38951924 0.79790385 1.98056306 ... 1.97788956 0.23892095 1.05774337] [1.14920754 2.4536383 0.04506731 ... 0.57163262 2.11331394 0.88166689]] k均值是非常流行的聚类算法，因为它不仅相对容易理解和实现，而且运行速度也相对较快。k均值可以轻松扩张到大型数据集，scikit-learn甚至在MinBatchKMeans类中包含了一种更具可扩展性的变体，可以处理非常大的数据集。 k均值的缺点之一在于，它依赖随机初始化，也就是说，算法的输出依赖于随机种子。默认情况下，scikit-learn用10不同的随机初始化算法运行10次，并返回最佳结果。k均值还有一个缺点，就是对簇形状的假设的约束性较强。而且还要求指定所要寻找的簇的个数（在现实世界的应用中可能并不知道这个数字）。 凝聚聚类凝集聚类（agglomerative clustering）指的是许多基于相同原则构建的聚类算法，这一原则是：算法首先申明每个点是自己的簇，然后合并两个最相似的簇，直到满足某种停止准则为止。scikit-learn中实现的停止准则是簇的个数，因此相似的簇被合并，直到仅剩下指定个数的簇。还有一些链接（linkage）准则，规定如何度量“最相似的簇”。这种度量总是定义在两个现有的簇之间。scikit-learn中实现了一下三种选项。 ward 默认选项。ward挑选两个簇来合并，使得所有簇中的方差增加最小。这通常会得到大小差不多的相等的簇。 average average链接将簇中所有点之间平均距离最小的两个簇合并。 complete complete链接（也称为最大链接）将簇中点之间最大距离最小的两个簇合并。 ward适用于大多数数据集，在例子中将使用它。如果簇中的成员个数非常不同（比如其中一个比其他所有都大得多），那么average或complete可能效果更好。 1mglearn.plots.plot_agglomerative_algorithm() 最开始，每个点自成一簇。然后在每一个步骤中，相距最近的两个簇被合并。在前四个步骤中，选出两个单点簇并将其合成两点簇。在步骤5中，其中一个两点簇被扩张到三个点，以此类推。在步骤9中，只剩下3个簇。由于指定寻找3个簇，因此算法结束。 凝聚聚类对使用的简单三簇数据的效果如何。由于算法的工作原理，凝聚算法不能对新数据点做出预测。因此AgglomerativeClustering没有predict方法。为了构造模型并得到训练集上簇的成员关系，可以改用fit_predict方法。 1234567from sklearn.cluster import AgglomerativeClusteringX,y = make_blobs(random_state=1)agg = AgglomerativeClustering(n_clusters=3)assignment = agg.fit_predict(X)mglearn.discrete_scatter(X[:,0],X[:,1],assignment)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 上图可以看出，算法完美地完成了聚类。虽然凝聚聚类的scikit-learn实现需要你指定希望算法找到的簇的个数，但凝聚聚类方法为选择正确的个数提供了一些帮助。 1.层次聚类与树状图 凝聚聚类生成了所谓的层次聚类（hierarchical clustering）。聚类过程迭代进行，每个点都从一个单点簇变为属于最终的某个簇。每个中间步骤提供了数据的一种聚类（簇的个数也不相同）。有时候，同时，同时查看所有可能的聚类是有帮助的。 1mglearn.plots.plot_agglomerative() 虽然这种可视化为层次聚类提供了详细的视图，但它依赖于数据的二维性质，因此不能用于具有两个以上特征的数据集。但还有另一个将层次聚类可视化的工具，叫作树状图，它可以处理多维数据集。 123456789101112from scipy.cluster.hierarchy import dendrogram,wardX,y = make_blobs(random_state=0,n_features=12)linkage_array = ward(X)dendrogram(linkage_array)ax = plt.gca()bounds = ax.get_xbound()ax.plot(bounds,[7.25,7.25],'--',c='k')ax.plot(bounds,[4,4],'--',c='k')ax.text(bounds[1],7.25,'two clusters',va='center',fontdict=&#123;'size':15&#125;)ax.text(bounds[1],4,'three cluster',va='center',fontdict=&#123;'size':15&#125;)plt.xlabel("Sample index")plt.ylabel("Cluster distance") Text(0,0.5,&apos;Cluster distance&apos;) 不幸的是，凝聚聚类仍然无法分离像two_moons数据集这样复杂的形状。 DBSCAN另一个非常有用的聚类算法是DBSCAN（密度聚类）。 主要优点：它不需要用户先验地设置簇的个数，可以划分具有复杂形状的簇，还可以找出不属于任何簇的点。DBSCAN比凝聚聚类和k均值稍慢，但仍可以扩展到相对较大的数据集。 原理：识别特征空间的“拥挤”区域中的，在这些区域中许多数据点靠近在一起。这些区域被称为特征空间的密集（dense）区域。簇形成数据的密集区域，并由相对较空的区域分隔开。 点的类型： 核心点：如果在一个给定数据点eps的距离内至少有min_samples个数据点，那么这个数据点就是核心样本。 边界点：与核心点的距离在eps之内的点。 噪声点：如果距起始点的距离在eps之内的数据点个数小雨min_samples,那么这个点被标记为噪声。 参数： min_samples:一个区域内最小的数据点，可以判断是否是核心点。 eps:给点范围的大小。 详细原理：算法首先任意选取一个点，然后找到这个点的距离小于等于eps的所有的点。如果距起点的距离在eps之内的数据点个数小于min_samples，那么这个点被标记为噪声，也就是说它不属于任何簇。如果距离在eps之内的数据点大于min_samples，则这个点被标记为核心样本，并被分配一个新的簇标签。然后访问该点的所有邻居。如果它们还没有被分配一个簇，那么就将刚刚创建的新的簇标签分配给它们。如果它们是核心样本，那么就依次访问邻居，以此类推。簇逐渐增大，直到在簇的eps距离内没有更过的核心样本为止。然后选取另一个尚未被访问过的点，并重复相同的过程。 123456from sklearn.cluster import DBSCANfrom sklearn.datasets import make_blobsX,y = make_blobs(random_state=0,n_samples=12)dbscan = DBSCAN()clusters = dbscan.fit_predict(X)print("Cluster menberships:\n&#123;&#125;".format(clusters)) Cluster menberships: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] 12import mglearnmglearn.plots.plot_dbscan() min_samples: 2 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1] min_samples: 2 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0] min_samples: 2 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0] min_samples: 2 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0] min_samples: 3 eps: 1.000000 cluster: [-1 0 0 -1 0 -1 1 1 0 1 -1 -1] min_samples: 3 eps: 1.500000 cluster: [0 1 1 1 1 0 2 2 1 2 2 0] min_samples: 3 eps: 2.000000 cluster: [0 1 1 1 1 0 0 0 1 0 0 0] min_samples: 3 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0] min_samples: 5 eps: 1.000000 cluster: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1] min_samples: 5 eps: 1.500000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1] min_samples: 5 eps: 2.000000 cluster: [-1 0 0 0 0 -1 -1 -1 0 -1 -1 -1] min_samples: 5 eps: 3.000000 cluster: [0 0 0 0 0 0 0 0 0 0 0 0] 在这种图中，属于簇的点是实心的，而噪声点则显示为空心的。核心样本显示为较大的标记，而边界点则显示为较小的标记。 增大eps（在图中从左到右），更多的点会被包含在一个簇中。这让簇变大，但可能也会导致多个簇合并成一个。 增大min_samples（在图中从上到下），核心点会变得更少，更多的点被标记为噪声。 参数eps在某种程度上更加重要，因为它决定了点与点之间“接近”的含义。将eps设置得非常小，意味着没有点是核心样本，可能会导致所有点被标记为噪声。将eps设置得非常大，可能会导致所有点形成单个簇。 设置min_samples主要是为了判断稀疏区域的点被标记为异常值还是形成自己的簇。如果增大min_samples，任何一个包含少于min_samples个样本的簇现在将标记为噪声。 虽然DBSCAN不需要显示地设置簇的个数，但设置eps可以隐式地控制找到的簇的个数。使用StandScaler或MinMaxScaler对数据进行缩放之后，有时会更容易找到eps的较好取值，因为使用这些缩放技术将确保所有特征具有相似的范围。 1234567891011from sklearn.preprocessing import StandardScalerimport matplotlib.pyplot as pltfrom sklearn.datasets import make_moonsX,y=make_moons(n_samples=200,noise=0.05,random_state=0)scaler = StandardScaler()X_scaler = scaler.fit(X).transform(X)dbscan = DBSCAN()clusters = dbscan.fit_predict(X_scaler)plt.scatter(X_scaler[:,0],X_scaler[:,1],c=clusters,cmap=mglearn.cm2,s=60)plt.xlabel("Feature 0")plt.ylabel("Feature 1") Text(0,0.5,&apos;Feature 1&apos;) 由于算法找到了我们想要的簇的个数（2个），因此参数设置得效果似乎很好。如果将eps减小到0.2（默认值为0.5），我们将会得到8个簇。将eps增大到0.7则会导致只有一个簇。在使用DBSCAN时，需要谨慎处理返回的簇分配。如果使用簇标签另一个数据进行索引，那么使用-1表示噪声可能会产生意料之外的结果。 聚类算法的对比与评估在应用聚类算法时，其挑战之一就是很难评估一个算法的效果好坏，也很难比较不同算法的结果。在讨论完k均值、凝聚聚类和DBSCAN的算法之后，将对比各个算法在真实的数据集上比较它们。 1.用真实值评估聚类 调整rand指数（ARI） 归一化信息（NMI） 二者都给出了定量的度量，其最佳值为1,0表示不相关的聚类。 1234567891011121314151617181920212223242526from sklearn.metrics.cluster import adjusted_rand_scorefrom sklearn.cluster import KMeans,AgglomerativeClusteringX,y = make_moons(n_samples=200,noise=0.05,random_state=0)import numpy as np#将数据缩放成平均值0、方差为1scaler = StandardScaler()scaler.fit(X)X_scaled = scaler.transform(X)fig,axes = plt.subplots(1,4,figsize = (15,3),subplot_kw=&#123;"xticks":(),"yticks":()&#125;)#列出要使用的算法algorithms = [KMeans(n_clusters=2),AgglomerativeClustering(n_clusters=2),DBSCAN()]#创建一个随机的簇分配，作为参考random_state = np.random.RandomState(seed=0)random_clusters = random_state.randint(low=0,high=2,size = len(X))#绘制随机分配axes[0].scatter(X_scaled[:,0],X_scaled[:,1],c=random_clusters,cmap=mglearn.cm3,s=60)axes[0].set_title("Random assignment-ARI:&#123;:.2f&#125;".format(adjusted_rand_score(y,random_clusters)))for ax,algorithm in zip(axes[1:],algorithms): #绘制簇分配和簇中心 clusters = algorithm.fit_predict(X_scaled) ax.scatter(X_scaled[:,0],X_scaled[:,1],c=clusters,cmap = mglearn.cm3,s=60) ax.set_title("&#123;&#125;-ARI:&#123;:.2F&#125;".format(algorithm.__class__.__name__,adjusted_rand_score(y,clusters))) 调整rand指数给出了符合直觉的结果，随机簇分配的分数为0，而DBSCAN（完美地找到了期望中的类）的分数为1。 用这种方式评估聚类时，一个常见的错误是使用accuracy_score而不是adjust_rand_score、nromalized_mutual_info_score或其他聚类指标。使用精度的问题在于，它要求分配的簇类标签与真实值完全匹配。但簇类的标签本身毫无意义——唯一重要的是哪些点位于同一份簇中。 123456789from sklearn.metrics import accuracy_score#这两点标签对应于相同的聚类clusters1 = [0,0,1,1,0]clusters2 = [1,1,0,0,1]#精度为0，因为二者标签完全不同print("Accuracy:&#123;:.2f&#125;".format(accuracy_score(clusters1,clusters2)))#调整rand分数为1，因为二者聚类完全相同print("ARI:&#123;:.2f&#125;".format(adjusted_rand_score(clusters1,clusters2))) Accuracy:0.00 ARI:1.00 2.在没有真实值的情况下评估聚类 在实践中，使用诸如ARI之类的指标有一个很大的问题。在应用聚类算法时，通常没有真实值来比较结果。如果我们知道了数据的正确聚类，那么可以使用这一信息构建一个监督模型（比如分类器）。因此，使用类似ARI和NMI的指标通常仅有助与开发算法，但对评估应用是否成功没有帮助。 有一些聚类的评分指标不需要真实值，比如轮廓系数。但它们在实践中的效果并不好。轮廓分数计算一个簇的紧致度，其值越大越好，最高分数为1.虽然紧致的簇很好，但紧致度不允许复杂的形状。 12345678910111213141516171819202122232425from sklearn.metrics.cluster import silhouette_scoreX,y = make_moons(n_samples=200,noise=0.05,random_state=0)import numpy as np#将数据缩放成平均值0、方差为1scaler = StandardScaler()scaler.fit(X)X_scaled = scaler.transform(X)fig,axes = plt.subplots(1,4,figsize = (15,3),subplot_kw=&#123;"xticks":(),"yticks":()&#125;)#列出要使用的算法algorithms = [KMeans(n_clusters=2),AgglomerativeClustering(n_clusters=2),DBSCAN()]#创建一个随机的簇分配，作为参考random_state = np.random.RandomState(seed=0)random_clusters = random_state.randint(low=0,high=2,size = len(X))#绘制随机分配axes[0].scatter(X_scaled[:,0],X_scaled[:,1],c=random_clusters,cmap=mglearn.cm3,s=60)axes[0].set_title("Random assignment:&#123;:.2f&#125;".format(silhouette_score(X_scaled,random_clusters)))for ax,algorithm in zip(axes[1:],algorithms): #绘制簇分配和簇中心 clusters = algorithm.fit_predict(X_scaled) ax.scatter(X_scaled[:,0],X_scaled[:,1],c=clusters,cmap = mglearn.cm3,s=60) ax.set_title("&#123;&#125;:&#123;:.2F&#125;".format(algorithm.__class__.__name__,silhouette_score(X_scaled,clusters))) 如你所见，k均值的轮廓系数最高，尽管我们可能更喜欢DBSCAN的结果。语句评估聚类，稍好的策略是使用基于鲁棒性的聚类指标。即使我们得到一个鲁棒性很好的聚类或非常高的轮廓分数，但仍然不知道聚类中是否任何语义含义。 聚类方法小结聚类的应用与评估是一个非常定性的过程，通常在数据分析的探索阶段很有帮助。三种聚类算法：k均值、DBSCAN和凝聚聚类。这三种算法都可以控制聚类的力度。k均值和凝聚聚类允许指定想要的簇的数量，而DBSCAN允许运用eps参数定义接近的程度，从而影响簇的大小。 k均值：用簇的平均值来表示簇，可以被看作一种分解方法，每个数据点都由其簇的中心表示。 DBSCAN：检测到没有分配任何簇的“噪声点”，还可以帮助自动判断簇的数量，允许簇具有复杂的形状，生成大小差别很大的簇，这可能是它的优点，有可能是缺点。 凝聚聚类：提供数据的可能划分的整个层次结构，可以通过树状图轻松查看。 数据表示与特征工程到目前为止，一直假设数据是由浮点数组成的二维数组，其中每一列是描述数据点的连续特征。对于许多应用而言，数据的收集方式并不是这样。一种特别常见的特征类别就是分类特征，也叫离散特征。这种特征并不是数值。 对于某个特定应用来说，如何找到最佳数据表示，这个问题被称为特征工程（feature engineering），它是数据科学家和机器学习从业者在尝试解决现实世界问题时的主要任务之一。用正确的方式表示数据，对监督模型性能的影响比所选择的精确参数还要大。 分类变量使用网上的adult数据集，这个数据集描述的问题，属于分类任务，两个类别是收入是否高于50k。 One-Hot编码（虚拟变量，哑变量）到目前为止，表示分类变量最常用的方法就是使用one-hot编码或N取一编码，也叫虚拟变量。虚拟变量背后的思想是将一个分类变量替换成一个或多个新特征，新特征取值为0和1。将数据转换成分类变量的one-hot编码有两种方法： 使用pandas 使用scikit-leran 123456789101112import pandas as pdfrom IPython.display import display#文件中没有包含列名称的表头，因此我们传入header#然后在“names”中显式地提供名称data = pd.read_csv("data/adult.data",header=None,index_col=False, names=["age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship", "race","gender","capital-gain","capital-loss","hours-per-week","native-country","income"])#为了简便，只选取其中几列data = data[["age","workclass","education","gender","hours-per-week","occupation","income"]]#ipython.display可以在jupyter notebook输出漂亮格式display(data.head()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age workclass education gender hours-per-week occupation income 0 39 State-gov Bachelors Male 40 Adm-clerical &lt;=50K 1 50 Self-emp-not-inc Bachelors Male 13 Exec-managerial &lt;=50K 2 38 Private HS-grad Male 40 Handlers-cleaners &lt;=50K 3 53 Private 11th Male 40 Handlers-cleaners &lt;=50K 4 28 Private Bachelors Female 40 Prof-specialty &lt;=50K 1.检查字符串编码的分类数据 读取完这样的数据集之后，最好检查每一列是否包含有意义的分类数据。在处理人工输入的数据时，可能没有固定的类别，拼写和大小写也存在差异，因此，可能需要预处理。 1234print(data.workclass.value_counts(),"\n")print(data.education.value_counts(),"\n")print(data.gender.value_counts(),"\n")print(data.occupation.value_counts(),"\n") Private 22696 Self-emp-not-inc 2541 Local-gov 2093 ? 1836 State-gov 1298 Self-emp-inc 1116 Federal-gov 960 Without-pay 14 Never-worked 7 Name: workclass, dtype: int64 HS-grad 10501 Some-college 7291 Bachelors 5355 Masters 1723 Assoc-voc 1382 11th 1175 Assoc-acdm 1067 10th 933 7th-8th 646 Prof-school 576 9th 514 12th 433 Doctorate 413 5th-6th 333 1st-4th 168 Preschool 51 Name: education, dtype: int64 Male 21790 Female 10771 Name: gender, dtype: int64 Prof-specialty 4140 Craft-repair 4099 Exec-managerial 4066 Adm-clerical 3770 Sales 3650 Other-service 3295 Machine-op-inspct 2002 ? 1843 Transport-moving 1597 Handlers-cleaners 1370 Farming-fishing 994 Tech-support 928 Protective-serv 649 Priv-house-serv 149 Armed-Forces 9 Name: occupation, dtype: int64 用pandas编码数据有一种非常简单的方法，就是使用get_dunmmies函数。get_dummies函数自动变换所有具有对象类型（比如字符串）的列或所有分类的列（这是pandas中的一个特殊概念）。这里有一个缺点就是，pandas只会将非数字表示的列识别为分类变量，但是实际上，有的数字变量也是分类变量。 123print("原特征:\n",list(data.columns),"\n")data_dummies = pd.get_dummies(data)print("经过编码后的编码\n,",list(data_dummies.columns)) 原特征: [&apos;age&apos;, &apos;workclass&apos;, &apos;education&apos;, &apos;gender&apos;, &apos;hours-per-week&apos;, &apos;occupation&apos;, &apos;income&apos;] 经过编码后的编码\, [&apos;age&apos;, &apos;hours-per-week&apos;, &apos;workclass_ ?&apos;, &apos;workclass_ Federal-gov&apos;, &apos;workclass_ Local-gov&apos;, &apos;workclass_ Never-worked&apos;, &apos;workclass_ Private&apos;, &apos;workclass_ Self-emp-inc&apos;, &apos;workclass_ Self-emp-not-inc&apos;, &apos;workclass_ State-gov&apos;, &apos;workclass_ Without-pay&apos;, &apos;education_ 10th&apos;, &apos;education_ 11th&apos;, &apos;education_ 12th&apos;, &apos;education_ 1st-4th&apos;, &apos;education_ 5th-6th&apos;, &apos;education_ 7th-8th&apos;, &apos;education_ 9th&apos;, &apos;education_ Assoc-acdm&apos;, &apos;education_ Assoc-voc&apos;, &apos;education_ Bachelors&apos;, &apos;education_ Doctorate&apos;, &apos;education_ HS-grad&apos;, &apos;education_ Masters&apos;, &apos;education_ Preschool&apos;, &apos;education_ Prof-school&apos;, &apos;education_ Some-college&apos;, &apos;gender_ Female&apos;, &apos;gender_ Male&apos;, &apos;occupation_ ?&apos;, &apos;occupation_ Adm-clerical&apos;, &apos;occupation_ Armed-Forces&apos;, &apos;occupation_ Craft-repair&apos;, &apos;occupation_ Exec-managerial&apos;, &apos;occupation_ Farming-fishing&apos;, &apos;occupation_ Handlers-cleaners&apos;, &apos;occupation_ Machine-op-inspct&apos;, &apos;occupation_ Other-service&apos;, &apos;occupation_ Priv-house-serv&apos;, &apos;occupation_ Prof-specialty&apos;, &apos;occupation_ Protective-serv&apos;, &apos;occupation_ Sales&apos;, &apos;occupation_ Tech-support&apos;, &apos;occupation_ Transport-moving&apos;, &apos;income_ &lt;=50K&apos;, &apos;income_ &gt;50K&apos;] 1data_dummies.head(n=10) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } age hours-per-week workclass_ ? workclass_ Federal-gov workclass_ Local-gov workclass_ Never-worked workclass_ Private workclass_ Self-emp-inc workclass_ Self-emp-not-inc workclass_ State-gov … occupation_ Machine-op-inspct occupation_ Other-service occupation_ Priv-house-serv occupation_ Prof-specialty occupation_ Protective-serv occupation_ Sales occupation_ Tech-support occupation_ Transport-moving income_ &lt;=50K income_ &gt;50K 0 39 40 0 0 0 0 0 0 0 1 … 0 0 0 0 0 0 0 0 1 0 1 50 13 0 0 0 0 0 0 1 0 … 0 0 0 0 0 0 0 0 1 0 2 38 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 3 53 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 4 28 40 0 0 0 0 1 0 0 0 … 0 0 0 1 0 0 0 0 1 0 5 37 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 6 49 16 0 0 0 0 1 0 0 0 … 0 1 0 0 0 0 0 0 1 0 7 52 45 0 0 0 0 0 0 1 0 … 0 0 0 0 0 0 0 0 0 1 8 31 50 0 0 0 0 1 0 0 0 … 0 0 0 1 0 0 0 0 0 1 9 42 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 0 1 10 rows × 46 columns 下面我们可以使用valuse属性将data_dummies数据框转换为NumPy数组，然后在其上训练一个机器学习模型。在训练模型之前，注意把目标变量（现在是income列）从数据中分离出来。将输出变量或输出变量的一些导出属性包含在特征表示中，这是构建监督机器学习模型时一个非常常见的错误。 1234features = data_dummies.ix[:,"age":"occupation_ Transport-moving"]x = features.valuesy = data_dummies["income_ &gt;50K"].valuesprint("x.shape:&#123;&#125; y.shape:&#123;&#125;".format(x.shape,y.shape) ) x.shape:(32561, 44) y.shape:(32561,) 现在数据的表示方式可以被scikit-learn处理，我们可以像之前一样继续下一步： 123456from sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(x,y,random_state=0)logreg = LogisticRegression()logreg.fit(X_train,y_train)print("训练集分数:&#123;:.2f&#125;,测试集分数:&#123;:.2f&#125;".format(logreg.score(X_train,y_train),logreg.score(X_test,y_test))) 训练集分数:0.81,测试集分数:0.81 在这个例子中，同时包含训练集数据和测试数据的数据框调用get_dummies.这一点很重要，可以确保训练集和测试集中的分类变量的表示方式相同。 数字可以编码分类变量在adult数据集的例子中，分类变量被编码为字符串。 可能会有拼写错误。 明确地将一个变量标记为分类变量。 无论是为了便于存储还是因为数据的收集方式，分类变量通常被编码为整数。 pandas的get_dunmmies函数将所有数字看作是连续的，不会为其创建虚拟变量。为了解决这个问题，可以使用scikit-learn的OneHotEncoder，指定哪些变量是连续的、哪些变量是离散的，也可以将数据框中的数值列转换为字符串。 123#创建一个DateFrame，包含一个整数特征和一个分类字符串特征demo_df = pd.DataFrame(&#123;"Integer Feature":[0,1,2,1],"Categorical Feature":["socks","fox","socks","box"]&#125;)display(demo_df) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Categorical Feature Integer Feature 0 socks 0 1 fox 1 2 socks 2 3 box 1 使用get_dummies只会编码字符串特征，不会改变整数特征 1pd.get_dummies(demo_df) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Integer Feature Categorical Feature_box Categorical Feature_fox Categorical Feature_socks 0 0 0 0 1 1 1 0 1 0 2 2 0 0 1 3 1 1 0 0 如果想要“Integer Feature”这一列创建虚拟变量，可以使用columns参数显式地给出想要编码的列。于是这两个特征都会被当作分类特征处理： 12demo_df["Integer Feature"] = demo_df["Integer Feature"].astype(str)pd.get_dummies(demo_df,columns=['Integer Feature','Categorical Feature']) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Integer Feature_0 Integer Feature_1 Integer Feature_2 Categorical Feature_box Categorical Feature_fox Categorical Feature_socks 0 1 0 0 0 0 1 1 0 1 0 0 1 0 2 0 0 1 0 0 1 3 0 1 0 1 0 0 分箱、离散化、模型与树数据表示的最佳方法不仅取决于数据的语义，还取决于所使用的模型种类。线性模型与基于树的模型（比如决策树、梯度提升树和随机森林）是两种成员很多同时又非常常用的模型，它们在处理不同的特征表示时就具有非常不同的性质。 123456789101112131415161718from sklearn.linear_model import LinearRegressionfrom sklearn.tree import DecisionTreeRegressorimport mglearnimport numpy as npimport matplotlib.pyplot as pltX,y = mglearn.datasets.make_wave(n_samples=100)line = np.linspace(-3,3,1000,endpoint=False).reshape(-1,1)reg = DecisionTreeRegressor(min_samples_split=3).fit(X,y)plt.plot(line,reg.predict(line),label='decsion tree')reg = LinearRegression().fit(X,y)plt.plot(line,reg.predict(line),label="linear regression")plt.plot(X[:,0],y,'o',c='k')plt.ylabel("Regression output")plt.xlabel("Input feature")plt.legend(loc='best') &lt;matplotlib.legend.Legend at 0x2470d877be0&gt; 如上图所示，线性模型只能对线性关系模型建模，对于单个特征的情况就是直线。决策树可以构建更为复杂的数据模型，但这强烈依赖于数据表示。有一种方法可以让线性模型在连续数据上变得更加强大，就是使用特征分箱（binning，也叫离散化）将其划分为多个特征。 123#创建-3,3之间定义10个均匀分布的箱子bins = np.linspace(-3,3,11)print("bins:&#123;&#125;".format(bins)) bins:[-3. -2.4 -1.8 -1.2 -0.6 0. 0.6 1.2 1.8 2.4 3. ] 123which_bin = np.digitize(X,bins = bins)print("\nDate points:\n&#123;&#125;",X[:5])print("\nBin membership for data points :\n",which_bin[:5]) Date points: {} [[-0.75275929] [ 2.70428584] [ 1.39196365] [ 0.59195091] [-2.06388816]] Bin membership for data points : [[ 4] [10] [ 8] [ 6] [ 2]] 要在这个数据上使用scikit-learn模型，利用preprocessing模块的OneHotEncoder将这个离散特征变换为one-hot编码。OneHotEncoder实现的编码与pandas.get_dummies相同，但目前它只适用于值为整数的分类编码。 123456from sklearn.preprocessing import OneHotEncoder#使用OneHotEncoder进行变换encoder = OneHotEncoder(sparse=False)encoder.fit(which_bin)X_binned = encoder.transform(which_bin)print(X_binned[:5]) [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]] 由于指定了10个箱子，所以变换后的X_binned数据集现在包含10个特征 1print("X_binned.shape:&#123;&#125;".format(X_binned.shape)) X_binned.shape:(100, 10) 12345678910line_binned = encoder.transform(np.digitize(line,bins=bins))reg=LinearRegression().fit(X_binned,y)plt.plot(line,reg.predict(line_binned),label="linear regression binnned")reg = DecisionTreeRegressor(min_samples_split=3).fit(X_binned,y)plt.plot(line,reg.predict(line_binned),label="decision regression binnned")plt.plot(X[:,0],y,'o',c='k')plt.vlines(bins,-3,3,linewidth=1,alpha=.2)plt.legend(loc="best")plt.ylabel("Regression output")plt.xlabel("Input feature") Text(0.5,0,&apos;Input feature&apos;) 蓝色和橙色完全重合，说明线性回归模型和决策树做出来了完全相同的预测。对于每个箱子，二者都预测一个常数值。因为每个箱子内的特征是不变的，所以对于一个箱子内的所有点，任何模型都会预测相同的值。比较对特征进行分箱前后模型学到的内容，发现，线性模型变得更加灵活了，因为它对每个箱子具有不同的取值，而决策树模型的灵活性降低了。 分箱特征对基于树的模型通常不会产生更好的效果，因为这种模型可以学习在任何位置划分数据。 从某种意义上来看，决策树可以学习如何分箱对预测这些数据最为有用。 此外，决策树可以同时查看多个特征，而分箱通常针对的是单个特征。不过，线性模型的表现理在数据变换后得到了极大的提高。 对于特定的数据集，如果有充分的理由使用线性模型——比如数据集很大、维度很高，但有些特征与输出的关系是非线性的——那么分箱是提高建模能力的好方法。 交互特征与多项式特征想要丰富特征表示，特别是对于线性模型而言，另一种方法是添加原始数据的交互特征和多项式特征。这种特征工程通常用于统计建模。 12X_combined = np.hstack([X,X_binned])print(X_combined.shape) (100, 11) 123456789reg = LinearRegression().fit(X_combined,y)line_combined = np.hstack([line,line_binned])plt.plot(line,reg.predict(line_combined),label = "linear regression combined")for bin in bins: plt.plot([bin,bin],[-3,3],':',c='k')plt.legend(loc="best")plt.ylabel("Regression output")plt.xlabel("Input feature")plt.plot(X[:,0],y,'o',c='k') [&lt;matplotlib.lines.Line2D at 0x2470e730550&gt;] 上图中，模型在每个箱子都学到一个偏移，还学到一个斜率。学到的斜率是向下的，并且在所有箱子中都相同——只有一个x轴特征，也就只有一个斜率。因为斜率在所有的箱子中是相同的，所有它似乎不是很有用。更希望每个箱子都有一个不同的斜率。可以添加交互特征或乘积特征，用来表示数据点所在的箱子以及数据点的x轴上的位置。这个特征是箱子指示符与原始特征的乘积。 12X_product = np.hstack([X_binned,X*X_binned])print(X_product[:5],X_product.shape) [[ 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. -0. -0. -0. -0.75275929 -0. -0. -0. -0. -0. -0. ] [ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2.70428584] [ 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.39196365 0. 0. ] [ 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.59195091 0. 0. 0. 0. ] [ 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. -0. -2.06388816 -0. -0. -0. -0. -0. -0. -0. -0. ]] (100, 20) 这个数据集现在有20个特征：数据点所在箱子的指示符与原始特征和箱子指示符的乘积。可以将乘积特征看作每个箱子x轴特征的单独副本。它在箱子内等于原始特征，在其他位置等于零。 123456789reg = LinearRegression().fit(X_product,y)line_product = np.hstack([line_binned,line*line_binned])plt.plot(line,reg.predict(line_product),label = "linear regression combined")for bin in bins: plt.plot([bin,bin],[-3,3],':',c='k')plt.legend(loc="best")plt.ylabel("Regression output")plt.xlabel("Input feature")plt.plot(X[:,0],y,'o',c='k') [&lt;matplotlib.lines.Line2D at 0x2470e2c0198&gt;] 使用分箱是扩展连续特征的一种方法。另一种方法是使用原始特征的多项式。对于给定特征x，我们考虑x^2、x^3、x^3，等等。这在preprocessing模块的PolynomialFeatures中实现： 12345from sklearn.preprocessing import PolynomialFeaturespoly = PolynomialFeatures(degree=10,include_bias=False)poly.fit(X)x_poly = poly.transform(X) 可以通过调用get_feature_names方法来获取特征的语义，给出每个特征的指数： 1print("Polynomial feature names:\n&#123;&#125;".format(poly.get_feature_names())) Polynomial feature names: [&apos;x0&apos;, &apos;x0^2&apos;, &apos;x0^3&apos;, &apos;x0^4&apos;, &apos;x0^5&apos;, &apos;x0^6&apos;, &apos;x0^7&apos;, &apos;x0^8&apos;, &apos;x0^9&apos;, &apos;x0^10&apos;] 将多项式与线性回归模型一起使用，可以得到经典的多项式回归模型。 1234567reg = LinearRegression().fit(x_poly,y)line_poly = poly.transform(line)plt.plot(line,reg.predict(line_poly),label="polynomial linear regression")plt.plot(X[:,0],y,'o',c='k')plt.xlabel("Input feature")plt.ylabel("Regression output")plt.legend(loc="best") &lt;matplotlib.legend.Legend at 0x2470e3c9240&gt; 如上图所示，多项式特征在这个以一维数据上得到了非常平滑的拟合。但高次多项式在边界上或数据很少的区域可能有极端的表现。下面在原始数据上学到的核SVM模型，没有做任何变换 12345678from sklearn.svm import SVRfor gamma in [1,10]: svr = SVR(gamma=gamma).fit(X,y) plt.plot(line,svr.predict(line),label="SVR gamma=&#123;&#125;".format(gamma))plt.plot(X[:,0],y,'o',c='k')plt.ylabel("Regression output")plt.xlabel("Input output")plt.legend(loc="best") &lt;matplotlib.legend.Legend at 0x2470ebb3198&gt; 使用更加复杂的模型（即核SVM）,我们能够学到一个与多项式回归的复杂度类似的预测结果，且不需要进行显示的特征变换。 1234567891011121314151617from sklearn.datasets import load_bostonfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import MinMaxScaler#数据缩放boston = load_boston()X_train,X_test,y_train,y_test = train_test_split(boston.data,boston.target,random_state=0)scaler = MinMaxScaler()X_train_scaled = scaler.fit_transform(X_train)X_test_scaled = scaler.transform(X_test)#建立模型poly = PolynomialFeatures(degree=2).fit(X_train_scaled)X_train_poly = poly.transform(X_train_scaled)X_test_poly = poly.transform(X_test_scaled)print("x_train.shape:&#123;&#125;".format(X_train.shape))print("X_train_poly.shape:&#123;&#125;".format(X_train_poly.shape)) x_train.shape:(379, 13) X_train_poly.shape:(379, 105) 原始数据有13个特征，现在被扩展到105交互特征。这些新特征表示两个不同的原始特征之间所有可能的交互项，以及每个原始特征的评分。这里degree=2的意思，我们需要有最多两个原始特征的乘积组成的所有特征。 1print("交互项特征:\n&#123;&#125;".format(poly.get_feature_names())) 交互项特征: [&apos;1&apos;, &apos;x0&apos;, &apos;x1&apos;, &apos;x2&apos;, &apos;x3&apos;, &apos;x4&apos;, &apos;x5&apos;, &apos;x6&apos;, &apos;x7&apos;, &apos;x8&apos;, &apos;x9&apos;, &apos;x10&apos;, &apos;x11&apos;, &apos;x12&apos;, &apos;x0^2&apos;, &apos;x0 x1&apos;, &apos;x0 x2&apos;, &apos;x0 x3&apos;, &apos;x0 x4&apos;, &apos;x0 x5&apos;, &apos;x0 x6&apos;, &apos;x0 x7&apos;, &apos;x0 x8&apos;, &apos;x0 x9&apos;, &apos;x0 x10&apos;, &apos;x0 x11&apos;, &apos;x0 x12&apos;, &apos;x1^2&apos;, &apos;x1 x2&apos;, &apos;x1 x3&apos;, &apos;x1 x4&apos;, &apos;x1 x5&apos;, &apos;x1 x6&apos;, &apos;x1 x7&apos;, &apos;x1 x8&apos;, &apos;x1 x9&apos;, &apos;x1 x10&apos;, &apos;x1 x11&apos;, &apos;x1 x12&apos;, &apos;x2^2&apos;, &apos;x2 x3&apos;, &apos;x2 x4&apos;, &apos;x2 x5&apos;, &apos;x2 x6&apos;, &apos;x2 x7&apos;, &apos;x2 x8&apos;, &apos;x2 x9&apos;, &apos;x2 x10&apos;, &apos;x2 x11&apos;, &apos;x2 x12&apos;, &apos;x3^2&apos;, &apos;x3 x4&apos;, &apos;x3 x5&apos;, &apos;x3 x6&apos;, &apos;x3 x7&apos;, &apos;x3 x8&apos;, &apos;x3 x9&apos;, &apos;x3 x10&apos;, &apos;x3 x11&apos;, &apos;x3 x12&apos;, &apos;x4^2&apos;, &apos;x4 x5&apos;, &apos;x4 x6&apos;, &apos;x4 x7&apos;, &apos;x4 x8&apos;, &apos;x4 x9&apos;, &apos;x4 x10&apos;, &apos;x4 x11&apos;, &apos;x4 x12&apos;, &apos;x5^2&apos;, &apos;x5 x6&apos;, &apos;x5 x7&apos;, &apos;x5 x8&apos;, &apos;x5 x9&apos;, &apos;x5 x10&apos;, &apos;x5 x11&apos;, &apos;x5 x12&apos;, &apos;x6^2&apos;, &apos;x6 x7&apos;, &apos;x6 x8&apos;, &apos;x6 x9&apos;, &apos;x6 x10&apos;, &apos;x6 x11&apos;, &apos;x6 x12&apos;, &apos;x7^2&apos;, &apos;x7 x8&apos;, &apos;x7 x9&apos;, &apos;x7 x10&apos;, &apos;x7 x11&apos;, &apos;x7 x12&apos;, &apos;x8^2&apos;, &apos;x8 x9&apos;, &apos;x8 x10&apos;, &apos;x8 x11&apos;, &apos;x8 x12&apos;, &apos;x9^2&apos;, &apos;x9 x10&apos;, &apos;x9 x11&apos;, &apos;x9 x12&apos;, &apos;x10^2&apos;, &apos;x10 x11&apos;, &apos;x10 x12&apos;, &apos;x11^2&apos;, &apos;x11 x12&apos;, &apos;x12^2&apos;] 第一个新特征是常数特征，这里的名称是“1”。接下来的13个特征是原始特征（名称从x0到x12），然后是每个特征平方项以及两两特征组合。则1+13+78+13=105 12345from sklearn.linear_model import Ridgeridge = Ridge().fit(X_train_scaled,y_train)print("测试集得分无交互项:&#123;:.3f&#125;".format(ridge.score(X_test_scaled,y_test)))ridge = Ridge().fit(X_train_poly,y_train)print("测试集加入交互项：&#123;:.3f&#125;".format(ridge.score(X_test_poly,y_test))) 测试集得分无交互项:0.621 测试集加入交互项：0.753 显然，在使用Ridge，交互特征和多项式特征对性能有很大的提升。但如果使用更加复杂的模型（比如随机森林），情况会稍有不同： 12345from sklearn.ensemble import RandomForestRegressorrf = RandomForestRegressor(n_estimators=100).fit(X_train_scaled,y_train)print("没有交互项得分:&#123;:.3f&#125;".format(rf.score(X_test_scaled,y_test)))rf = RandomForestRegressor(n_estimators=100).fit(X_train_poly,y_train)print("有交互项得分:&#123;:.3f&#125;".format(rf.score(X_test_poly,y_test))) 没有交互项得分:0.803 有交互项得分:0.798 可以看出，即使没有额外特征的特征，随机森林的性能也要优于Ridge。添加交互项特征和多项式特征实际上会略微降低其性能。 单变量非线性变换刚刚看到，添加特征的评分或立方可以改进线性回归模型。其他变换通常也对变换某些特征有用，特别是应用数学变换，比如log、exp或sin。虽然基于树的模型只关注特征的顺序，但线性模型和神经网络依赖于每个特征的尺度和分布。如果在特征和目标之间存在非线性关系，那么建模就变得非常困难，特别是对于回归问题。log或exp函数可以帮助调节数据的相对比例，从而改进线性模型或神经网络的学习效果。 大部分模型都在每个特征（在回归问题中还包括目标值）大致遵循高斯分布时表现最好，也就是说，每个特征的直方图应该具有类似于熟悉的“钟形曲线”的曲线。使用诸如log和exp之类的变换并不稀奇，但却是实现这一点的简单又有效的方法。在一种特别常见的情况下，这样的变换非常有用，就是处理整数计数数据时。 123456import numpy as nprnd = np.random.RandomState(0)X_org=rnd.normal(size=(1000,3))w = rnd.normal(size=3)x = rnd.poisson(10*np.exp(X_org))y = np.dot(X_org,w) 1print("特征统计个数:\n&#123;&#125;".format(np.bincount(x[:,0]))) 特征统计个数: [28 38 68 48 61 59 45 56 37 40 35 34 36 26 23 26 27 21 23 23 18 21 10 9 17 9 7 14 12 7 3 8 4 5 5 3 4 2 4 1 1 3 2 5 3 8 2 5 2 1 2 3 3 2 2 3 3 0 1 2 1 0 0 3 1 0 0 0 1 3 0 1 0 2 0 1 1 0 0 0 0 1 0 0 2 2 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1] 12345import matplotlib.pyplot as pltbins = np.bincount(x[:,0])plt.bar(range(len(bins)),bins,color='gray')plt.ylabel("Number of feature")plt.xlabel("Value") Text(0.5,0,&apos;Value&apos;) 特征x[:,1]和x[:,2]具有类似的性质。这种类型的数值分布（许多较小的值和一些非常大的值）在实践中非常常见。但大多数线性模型无法很好地处理这种数据。 12345from sklearn.model_selection import train_test_splitfrom sklearn.linear_model import RidgeX_train,X_test,y_train,y_test = train_test_split(x,y,random_state = 0)score = Ridge().fit(X_train,y_train).score(X_test,y_test)print("test score:&#123;:.3f&#125;".format(score)) test score:0.622 12345X_train_log = np.log(X_train+1)X_test_log = np.log(X_test+1)plt.hist(X_test_log[:,0],bins=25,color='gray')plt.ylabel("Number of appearances")plt.xlabel("Value") Text(0.5,0,&apos;Value&apos;) 12score = Ridge().fit(X_train_log,y_train).score(X_test_log,y_test)print("Test score:&#123;:.3&#125;".format(score)) Test score:0.875 为数据集和模型的所有组合寻找最佳变换，这在某种程度上是一门艺术。尝试预测技术（比如订单数量）是一项相当常见的任务，而且使用log（y+1）变换也往往有用。分箱、多项式和交互项都对模型在给定数据集上的性能有很大影响，对于复杂度较低的模型更是这样，比如线性模型和朴素贝叶斯模型。与之相反，基于树的模型通常能够自己发现重要的交互项，大多数情况下不需要显式地变换数据。其他模型，比如SVM、最近邻和神经网络，有时可能会从使用分箱、交互项或多项式中受益，但其效果通常不如线性模型那么明显。 自动化特征选择有了这么多种创建新特征的方法，可能会想要增大数据的维度，使其远大于原始特征的数量。但是，添加更多特征会使所有模型变得更加复杂，从而增大过拟合的可能性。在添加新特征或处理一般的高维数据集时，最好将特征的数量减少到只包含最有用的那些特征，并删除其余特征。 单变量统计 基于模型的选择 迭代选择 这三种策略都是监督方法，即它们需要目标值拟合模型，我们需要将数据划分为训练集和测试集，并只在训练集上拟合特征选择。 单变量统计在单变量统计中，计算每个特征和目标值之间的关系是否存在统计显著性，然后选择具有最高置信度的特征。对于分类问题，这也被称为反差分析。这些测试的一个关键性质就是它们单变量，即它们只单独考虑每个特征。因此，如果一个特征只有在与另外一个特征合并时才具有信息量，那么这个特征将被舍弃。单变量测试的计算速度通常很快，并且不需要构建模型。另一方面，它们完全独立于可能在特征选择之后应用的模型。 在scikit-learn中使用单变量特征选择，需要选择一项测试： 对分类问题通常是f_classif(默认值）。 对回归问题通常是f_regression。 然后基于测试中确定的p值来选择一种舍弃特征的方法。 计算阈值的方法各有不同，最简单的是SelectKBest和SelectPercentile selectKbest：选择固定数量的k个特征。 selecpercentile：选择固定百分比的特征。 1234567891011121314from sklearn.datasets import load_breast_cancerfrom sklearn.feature_selection import SelectPercentilefrom sklearn.model_selection import train_test_splitcancer = load_breast_cancer()rng = np.random.RandomState(42)noise = rng.normal(size=(len(cancer.data),50))X_w_nosie = np.hstack([cancer.data,noise])X_train,X_test,y_train,y_test= train_test_split(X_w_nosie,cancer.target,random_state = 0,test_size=.5)select = SelectPercentile(percentile=50)select.fit(X_train,y_train)X_train_selected = select.transform(X_train)print("原始训练集形状:&#123;&#125;".format(X_train.shape))print("特征选择后的形状:&#123;&#125;".format(X_train_selected.shape)) 原始训练集形状:(284, 80) 特征选择后的形状:(284, 40) 1234mask = select.get_support()print(mask)plt.matshow(mask.reshape(1,-1),cmap='gray_r')plt.xlabel("Sample index") [ True True True True True True True True True False True False True True True True True True False False True True True True True True True True True True False False False True False True False False True False False False False True False False True False False True False True False False False False False False True False True False False False False True False True False False False False True True False True False False False False] Text(0.5,0,&apos;Sample index&apos;) 12345678from sklearn.linear_model import LogisticRegressionX_test_selected = select.transform(X_test)lr = LogisticRegression()lr.fit(X_train,y_train)print("无特征选择:&#123;:.3f&#125;".format(lr.score(X_test,y_test)))lr.fit(X_train_selected,y_train)print("特征选择:&#123;:.3f&#125;".format(lr.score(X_test_selected,y_test))) 无特征选择:0.930 特征选择:0.940 删除噪声特征可以提高性能，即使丢失了某些原始特征。在真实数据上的结果要更加复杂。不过，如果特征量太大以至于无法构建模型，或者你怀疑许多特征完全没有信息量，那么单变量特征选择还是非常有用的。 基于模型的特征选择基于模型的特征选择使用一个监督机器学习模型来判断每个特征的重要性，并且仅保留最重要的特征。用于特征选择的监督模型不需要与用于最终监督建模的模型相同。特征选择模型需要为每个特征提供某种重要性度量，以便于这个度量对特征进行排序。 决策树和记忆决策树的模型提供了feature_importance_属性，可以直接编码每个特征的重要性。 线性模型系数的绝对值也可以用于表示特征的重要性。 与单变量选择不同，基于模型的选择同时考虑所有特征，因此可以获取交互项（如果模型能够获取它们的话）。如果使用基于模型的特征选择，需要使用SelectFromMode变换器。 123from sklearn.feature_selection import SelectFromModelfrom sklearn.ensemble import RandomForestClassifierselect = SelectFromModel(RandomForestClassifier(n_estimators=100,random_state=42),threshold="median") SelectFromModel类选择出重要性度量（由监督模型提供）大于给定阈值的所有特征。为了得到可以与单变量特征选择进行对比的结果，使用中位数作为阈值，这样就可以选择一般特征。 1234select.fit(X_train,y_train)X_train_l1 = select.transform(X_train)print("X_train.shape:&#123;&#125;".format(X_train.shape),X_train.shape)print("X_train_l1.shape:&#123;&#125;".format(X_train_l1.shape)) X_train.shape:(284, 80) (284, 80) X_train_l1.shape:(284, 40) 123mask = select.get_support()plt.matshow(mask.reshape(1,-1),cmap='gray_r')plt.xlabel("Sample index") Text(0.5,0,&apos;Sample index&apos;) 这次，除了两个原始特征，其他原始特征都被选中。由于我们指定选择40个特征，所以也选择了一些噪声特征。 123X_test_l1 = select.transform(X_test)score = LogisticRegression().fit(X_train_l1,y_train).score(X_test_l1,y_test)print("Test score:&#123;:.4f&#125;".format(score)) Test score:0.9509 利用更好的特征选择，性能也得到了提高。 迭代特征选择在单变量测试中，没有使用模型，而在基于模型的选择中，使用了单个模型来选择特征。在迭代特征选择中，建辉构建一系列模型，每个模型都你用不同数量的特征。有两种基本方法： 开始时没有特征，然后逐个添加特征，直到满足某个终止条件 从所有特征开始，然后逐个删除特征，直到满足某个终止条件。 由于构建一系列模型，所以这些方法的计算成本要比前面讨论过的方法更高。其中一种特殊方法是递归特征消除(rfe)，它从所有特征开始构建模型，并根据模型舍弃最不重要的特征，然后使用除被舍弃特征之外的所有特征来构建一个新模型。如此继续，直到仅剩下预设数量的特征，正如模型的选择所做的那样。 123456from sklearn.feature_selection import RFEselect = RFE(RandomForestClassifier(n_estimators=300,random_state=42),n_features_to_select=40)select.fit(X_train,y_train)mask = select.get_support()plt.matshow(mask.reshape(1,-1),cmap='gray_r')plt.xlabel("Sample index") Text(0.5,0,&apos;Sample index&apos;) 与单变量选择和基于模型的选择相比，迭代特征选择的结果更好。 1234X_train_rfe = select.transform(X_train)X_test_rfe = select.transform(X_test)score = LogisticRegression().fit(X_train_rfe,y_train).score(X_test_rfe,y_test)print("Test score:&#123;&#125;".format(score)) Test score:0.9543859649122807 这里，在RFE内部使用的随机森林的性能，与在所选特征上训练一个logistic回归模型得到的性能相同。换句话说，只要我们选择了正确的特征，线性模型表现与随机森林一样好。 利用专家知识对于特定应用来说，在特征工程中通常可以利用专家知识。虽然在许多情况下，机器学习的目的是避免创建一组专家设计的规则，但这并不意味着应该舍弃该应用或该领域的先验知识。通常来说，领域专家可以帮组找出有用的特征，其信息数量比根据原始表示要大得多。 小结与展望强调了使用适合机器学习算法的数据表示方式的重要性，例如one-hot编码过的分类变量。通过特征工程生成新特征的重要性，以及利用专家知识从数据中创建导出特征的可能性。特别是线性模型，可能会从分箱、添加多项式和交互项而生成的新特征中大大受益。对于更加复杂的非线性（比如随机森林和SVM），在无需显示扩展特征空间的前提下就可以学习更加复杂的任务。在实践中，所使用的特征（以及特征与方法之间的匹配）通常是机器学习方法表现良好的最重要的因素。 模型评估与改进到目前为止，为了评估我们的监督模型，我们使用train_test_splist函数将数据集划分为训练集和测试集，在训练集上调用fit方法来构建模型，并且在测试集上用score方法来评估这个模型——对于分类问题而言，就是计算正确分类的样本所占的比例。 12345678from sklearn.datasets import make_blobsfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splitX,y = make_blobs(random_state=0)X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)lr = LogisticRegression().fit(X_train,y_train)print("测试集得分:&#123;:.3f&#125;".format(lr.score(X_test,y_test))) 测试集得分:0.880 之所以划分为训练集和测试集，是因为要到度量模型对前所未见的数据的泛化能力。对模型在训练集上的拟合效果不感兴趣，而是想知道模型对于训练过程中呢没有见过的数据的预测能力。 交叉验证交叉验证（cross-validation）是一种评估泛化性能的统计学方法，他比单词划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是k折交叉验证，其中k是由用户指定的数字，通常取5或10。 12import mglearnmglearn.plots.plot_cross_validation() C:\Users\GoFisher\AppData\Roaming\Python\Python36\site-packages\matplotlib\pyplot.py:2790: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 ret = ax.barh(*args, **kwargs) scikit-learn中的交叉验证scikit-learn是利用model_selection模块中的cross_val_score函数来实现交叉验证。 cross_val_score函数的参数是我们想要评估的模型、训练数据与真实标签。 123456from sklearn.model_selection import cross_val_scorefrom sklearn.datasets import load_irisiris = load_iris()logreg = LogisticRegression()scores = cross_val_score(logreg,iris.data,iris.target)print("3折交叉验证情况下的模型测试得分:&#123;&#125;".format(scores)) 3折交叉验证情况下的模型测试得分:[0.96078431 0.92156863 0.95833333] 123scores = cross_val_score(logreg,iris.data,iris.target,cv=5)print("3折交叉验证情况下的模型测试得分:&#123;&#125;".format(scores))print("5折交叉验证情况下的模型平均测试得分:&#123;:.3f&#125;".format(scores.mean())) 3折交叉验证情况下的模型测试得分:[1. 0.96666667 0.93333333 0.9 1. ] 5折交叉验证情况下的模型平均测试得分:0.960 可以从交叉验证平均值中得出结论，预计模型的平均精度约为96%。观察5折交叉验证得到的所有5个精度值，还可以发现，折与折之间的精度有较大的变化，范围从100%到90%精度。这可能意味着模型强烈依赖于某个折用于训练，但也可能只是因为数据集的数据量太小。 交叉验证的优点 train_test_split对数据进行随机划分，可能出现所有容易划分的数据点划入训练集，而难以区分的点划入测试集，这样容易导致最终的模型的效果并不是很好；交叉验证保证每个样例刚好在测试集中出现一次：每个样例位于一个折中，而每个折都在测试集中出现一次。因此，模型需要对数据集中所有样本的泛化能力都很好，才能让所有的交叉验证得分都很高。 对数据进行多次划分，还可以提供模型对训练集选择的敏感性信息。根据每个折的得分成绩，可知模型应用于新数据时在最坏情况和最好情况下的可能表现。 数据的使用更加高效。在比例划分数据时候，只有75%数据用于训练，25%数据用于评估，使用5交叉验证时，在每次迭代中我们可以使用80%的数据来拟合模型。 交叉验证的主要缺点： 增加啦计算成本 重要：交叉验证不是一种构建可应用于新数据的模型的方法。交叉验证不会返回一个模型。在调用cross_val_score时，内部会构建多个模型，但交叉验证的目的只是评估给定算法在特定数据集上训练后的泛化能力好坏。 分层k折交叉验证和其他策略将数据集划分为k折时，从数据的前k分之一开始划分，这可能并不总是一个好主意。 1print("Iris label:&#123;&#125;".format(iris.target)) Iris label:[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2] 上面的结果所示，数据的前三分之一是类别0，中间三分之一是类别1，最后三分之一是类别2。如果直接使用3折的交叉验证，每个类都会被划分成一折，对模型的训练没有帮助，可能得到好多精度为0。 简单的k折策略在这里失效了，所以scikit-learn在分类问题中不使用这种策略，而是使用分层k折交叉验证。 在分层交叉验证中，划分数据，使每个折中类别之间的比例与整个数据集中的比例相同。 1mglearn.plots.plot_stratified_cross_validation() D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:121: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 color=colors, hatch=&quot;//&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:125: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 color=&quot;w&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:158: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 height=.6, color=&quot;grey&quot;, hatch=&quot;//&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:163: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 hatch=&quot;//&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:167: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 edgecolor=&apos;k&apos;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:171: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:175: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 color=&quot;w&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) 使用分层k折交叉验证而不是k折交叉验证来评估一个分类器，这通常是一个好主意，因为它可以对泛化性能做出更可靠的估计。在只有10%的样本属于类别B的情况下，如果使用标准k折交叉验证，很可能某个折中只包含类别A的样本。利用这个折作为测试集的话，无法给出分类器整体性能的信息。 对于回归问题，scikit-learn默认使用标准k折交叉验证。也可以尝试让每个折表示回归目标的不同取值，但这并不是一种常用的策略，也会让大多数用户感到意外。 1.对交叉验证的更多控制 利用cv参数来调节cross_val_score所使用的折数。但scikit-learn允许提供一个交叉验证分离器作为cv参数，来对数据划分过程进行更精细的控制。 123from sklearn.model_selection import KFoldkfold = KFold(n_splits=5)print("Cross-validation scores:\n&#123;&#125;".format(cross_val_score(logreg,iris.data,iris.target,cv=kfold))) Cross-validation scores: [1. 0.93333333 0.43333333 0.96666667 0.43333333] 12kfold = KFold(n_splits=3)print("Cross-validation scores:\n&#123;&#125;".format(cross_val_score(logreg,iris.data,iris.target,cv=kfold))) Cross-validation scores: [0. 0. 0.] iris数据集中每个折对应一个类别，因此学不到任何内容。解决这个问题的另一种方法是将数据打乱来代替分层，以打乱样本按标签排序。可以通过将KFold的shuffle参数设为True来是实现这一点。如果我们将数据打乱，那么还需要固定random_state以获得可重复的打乱结果。否则，每次运行cross_val_score将会得到不同的结果，因为每次使用的是不同的划分。 123# 打乱数据集的交叉验证kfold = KFold(n_splits=3,shuffle=True,random_state=0)print("Cross-validation scores:\n&#123;&#125;".format(cross_val_score(logreg,iris.data,iris.target,cv=kfold))) Cross-validation scores: [0.9 0.96 0.96] 1234# 分层交叉验证from sklearn.model_selection import StratifiedKFoldskf = StratifiedKFold(n_splits=3)print("Cross-validation scores:\n&#123;&#125;".format(cross_val_score(logreg,iris.data,iris.target,cv=skf))) Cross-validation scores: [0.96078431 0.92156863 0.95833333] 2.留一法交叉验证另外一种常用的交叉验证方法是留一法（leave-one-out）。可以将留一法交叉验证看作是每折只包含单个样本的k折交叉验证。对于每次划分，选择单个数据点作为测试集。这种方法可能非常耗时，特别是对于大型的数据集来说，但在小型的数据集上有时可以给出更好的估计结果。 123456from sklearn.model_selection import LeaveOneOutloo = LeaveOneOut()scores = cross_val_score(logreg,iris.data,iris.target,cv=loo)print("Number of cv iterations:",len(scores))print("Number of cv scores:",scores)print("Cross-validation scores:\n&#123;&#125;".format(scores.mean())) Number of cv iterations: 150 Number of cv scores: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] Cross-validation scores: 0.9533333333333334 3.打乱划分交叉验证 另一种非常灵活的交叉验证策略是打乱划分交叉验证。在打乱划分交叉验证中，每次划分为训练集取样train_size个点，为测试取样test_size个点。将这一划分方法重复n_iter次。下图显示是对包含十个点的数据集运行4词迭代划分，每次的训练集包含5个点，测试集包含2个点（可以将train+size和test_size设为整数来表示这两个集合的绝对大小，也可以设为浮点数来表示占整个数据集的比例。） 1mglearn.plots.plot_shuffle_split() D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:85: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 hatch=&quot;//&quot;, edgecolor=&apos;k&apos;, align=&apos;edge&apos;) 1234from sklearn.model_selection import ShuffleSplitshuffle_split = ShuffleSplit(test_size=.5,train_size=.5,n_splits=10)scores = cross_val_score(logreg,iris.data,iris.target,cv=shuffle_split)print("Cross-validation scores:\n&#123;&#125;".format(scores)) Cross-validation scores: [0.97333333 0.98666667 0.86666667 0.98666667 0.97333333 0.93333333 0.94666667 0.96 1. 0.94666667] 打乱划分交叉验证可以在训练集和测试集大小之外独立控制迭代次数，这有时候很有帮助的。它还允许在每次迭代中仅使用部分数据，这可以通过设置train_size和test_size之和不等于1来实现。用这种方法对数据进行二次采样可能对大型数据上的试验很有用。 4.分组交叉验证 另一种非常常见的交叉验证适用于数据中的分组高度相关时。比如你想构建一个从人脸图片中识别情感的系统，并且收集了100个人的照片的数据集，其中每个人都进行了多次拍摄，分别展示了不同的情感。目标是构建一个分类器，能够正确识别未包含在数据中的人的情感。可以使用默认的分层交叉验证来度量分类器的性能。但是这样的话，同一个人的照片可能会同时出现在训练集和测试集中。对于分类而言，检测训练集中出现过的人类情感比全新的人脸要容易得多。因此，为了准确评估模型对新的人脸的泛化能力，必须确保训练集和测试集中包含不同人的图像。 实现这一点，可以使用GroupKFold,它以groups数组作为参数，可以用来说明照片中对应的是哪个人。这里的groups数组表示数据中的分组，在创建训练集和测试集的时候不应该将其分开，也不应该与类别标签弄混。数据分组的这种例子常见于医疗应用，你可能拥有来自同一名病人的多个样本，但想要将其泛化到新的病人。同样，在语音识别领域，你的数据集中可能包含同一名发言人的多条记录，但希望能够识别新的发言人的讲话。 12345from sklearn.model_selection import GroupKFoldX,y = make_blobs(n_samples=12,random_state=0)groups = [0,0,0,1,1,1,1,2,2,3,3,3]scores = cross_val_score(logreg,X,y,groups,cv=GroupKFold(n_splits=3))print("cross-validation scores:&#123;&#125;".format(scores)) cross-validation scores:[0.75 0.8 0.66666667] 1mglearn.plots.plot_group_kfold() D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:33: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 hatch=&quot;//&quot;, edgecolor=&quot;k&quot;, align=&apos;edge&apos;) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\mglearn\plot_cross_validation.py:39: MatplotlibDeprecationWarning: The *bottom* kwarg to `barh` is deprecated use *y* instead. Support for *bottom* will be removed in Matplotlib 3.0 color=&quot;w&quot;, edgecolor=&apos;k&apos;, align=&quot;edge&quot;) 标准的KFold、StratifiedKFlod和GroupKFold是目前最常用的集中。 网格搜索知道了评估一个模型的泛化能力，下面通过调参来提升模型的泛化性能。在尝试调参之前，重要的是理解参数的含义。找到一个模型的重要参数（提供最佳泛化性能的参数）的取值是一项棘手的任务，但对于几乎所有模型和数据集来说都是必要的。其中最常用的方法就是网格搜索（grid searsh），它主要是尝试我们关心的参数的所有可能组合。 简单网格搜索实现一个简单的网格搜索，在2个参数上使用for循环，对每种参数组合分别训练并评估一个分类器。 123456789101112131415161718from sklearn.svm import SVCfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitiris = load_iris()X_train,X_test,y_train,y_test =train_test_split(iris.data,iris.target,random_state =0)print("Size of training set:&#123;&#125; size of test srt:&#123;&#125;".format(X_train.shape[0],X_test.shape[0]))best_score = 0for gamma in [0.001,0.01,0.1,1,10,100]: for C in [0.001,0.01,0.1,1,10,100]: svm = SVC(gamma=gamma,C=C) svm.fit(X_train,y_train) score = svm.score(X_test,y_test) if score &gt;best_score: best_score = score best_patameters = &#123;"C":C,"gamma":gamma&#125;print("best score:&#123;:.3f&#125;".format(best_score))print("best parameters:&#123;&#125;".format(best_patameters)) Size of training set:112 size of test srt:38 best score:0.974 best parameters:{&apos;C&apos;: 100, &apos;gamma&apos;: 0.001} 参数过拟合的风险与验证集找到了一个在数据集上精度上达到97%的模型。然而，这种说法可能过于乐观了（或者是错误的），其原因如下:我们尝试了许多不同的参数，并选择了在测试集上精度最高的那个，但这个精度不一定能推广到新数据上。由于我们使用测试数据进行调参，所以不能再它来评估模型的好坏。最开始需要将数据划分为训练集和测试集也是这个原因。需要一个独立的数据集来评估，一个在创建模型时没有用到的数据集。 12import mglearnmglearn.plots.plot_threefold_split() 验证集：确定最佳参数 训练集：构建模型 测试集：验证模型或者评估模型 1234567891011121314151617181920X_trainval,X_test,y_trainval,y_test =train_test_split(iris.data,iris.target,random_state =0)X_train,X_valid,y_train,y_valid = train_test_split(X_trainval,y_trainval,random_state = 1)print("Size of training set:&#123;&#125; Size of valid set:&#123;&#125; size of test set:&#123;&#125;".format(X_train.shape[0],X_valid.shape[0],X_test.shape[0]))best_score = 0for gamma in [0.001,0.01,0.1,1,10,100]: for C in [0.001,0.01,0.1,1,10,100]: svm = SVC(gamma=gamma,C=C) svm.fit(X_train,y_train) score = svm.score(X_valid,y_valid) if score &gt;best_score: best_score = score best_patameters = &#123;"C":C,"gamma":gamma&#125;#在训练集+验证集上重新构建一个模型，并在测试集上进行评估svm = SVC(**best_patameters)svm.fit(X_trainval,y_trainval)test_score = svm.score(X_test,y_test) print("best score on validation set :&#123;:.3f&#125;".format(best_score))print("best parameters:&#123;&#125;".format(best_patameters))print("best set score with best parameters:&#123;:.3f&#125;".format(test_score)) Size of training set:84 Size of valid set:28 size of test set:38 best score on validation set :0.964 best parameters:{&apos;C&apos;: 10, &apos;gamma&apos;: 0.001} best set score with best parameters:0.921 验证集上的最高分数是96%，这比之前略低，可能是因为我们使用了更少的数据来训练模型（现在X_train更少，因为对数据集进行两次划分）。但测试集上的分数（这个分数实际放映了模型的泛化能力）更低，为92%。因此，只能声称对92%的新数据正确分类，而不是之前的97%。 训练集、验证集和测试集之间的区别是对于在实践中应用机器学习方法至关重要。任何根据测试集精度所做的选择都会将测试集的信息“泄漏”到模型中。因此，保留一个单独的测试集是很重要的，它仅用于最终评估。好的做法是利用训练集和验证集的组合完成所有探索性分析与模型选择，并保留测试集用于最终评估——即使对于探索性可视化也是如此。严格来说，在测试集上对不止一个模型进行评估并选择更好的那个，将会导致对模型精度过于乐观的估计。 带交叉验证的网格搜索虽然数据划分为训练集、验证集和测试集的方法是可行的，也相对常用，但这种方法对数据的划分相当敏感。从上面结果来看网格搜索选择‘C’：10，‘gamma’:0.001作为最佳参数，而前面的代码输出结果不一样。为了得到对泛化性能的更好估计，可以使用交叉验证来评估每种参数组合的性能，而不是仅将数据单次划分为训练集与验证集。 1234567891011121314151617from sklearn.model_selection import cross_val_scorefor gamma in [0.001,0.01,0.1,1,10,100]: for C in [0.001,0.01,0.1,1,10,100]: svm = SVC(gamma=gamma,C=C) #执行交叉验证 score = cross_val_score(svm,X_trainval,y_trainval,cv=5) score = score.mean() if score &gt;best_score: best_score = score best_patameters = &#123;"C":C,"gamma":gamma&#125;#在训练集+验证集上重新构建一个模型，并在测试集上进行评估svm = SVC(**best_patameters)svm.fit(X_trainval,y_trainval)test_score = svm.score(X_test,y_test) print("best score on validation set :&#123;:.3f&#125;".format(best_score))print("best parameters:&#123;&#125;".format(best_patameters))print("best set score with best parameters:&#123;:.3f&#125;".format(test_score)) best score on validation set :0.973 best parameters:{&apos;C&apos;: 100, &apos;gamma&apos;: 0.01} best set score with best parameters:0.974 要想使用5折交叉验证对C和gamma特定取值的SVM的精度进行评估，需要训练36×5=180个模型。可以想象，使用交叉验证的主要缺点是训练所有这些模型所需花费的时间。 1mglearn.plots.plot_cross_val_selection() D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;mean_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split0_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split1_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split2_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split3_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split4_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;std_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) 对于每种参数设置，需要计算5个精度值，交叉验证的每次划分都要计算一个精度值。然后，对每种参数设置计算平均验证精度。最后，选择验证精度最高的参数用圆圈标记。 交叉验证时在特定数据集上对给定算法进行评估的一种方法。但它通常与网格搜索等参数搜索方法结合使用。因此，许多人使用交叉验证这一术语来通俗地指代带交叉验证的网格搜索。 1mglearn.plots.plot_grid_search_overview() 由于带交叉验证的网格搜素是一种常用的调参方法，因此scikit-learn提供了GridsearchCV，它以估计器的形式实现了这种方法。要使用GridSearshCV类，首先需要要用一个字典指定要搜索的参数。然后GridSearshCV会执行所有必要的模型拟合。字典的键是我们要调节的参数名称，字典的键是我们想要尝试的参数设置。如果C和gamma想尝试的取值，可以将其转化为下面的字典: 123456from sklearn.model_selection import GridSearchCVparam_grid = &#123;"C":[0.001,0.01,0.1,1,10,100],"gamma":[0.001,0.01,0.1,1,10,100]&#125;X_train,X_test,y_train,y_test =train_test_split(iris.data,iris.target,random_state =0)grid_searsh = GridSearchCV(SVC(),param_grid,cv=5)grid_searsh.fit(X_train,y_train)print("Test set score:&#123;:.3f&#125;".format(grid_searsh.score(X_test,y_test))) Test set score:0.974 利用交叉验证选择参数，实际上找到了一个在测试集上精度为97.4%的模型。重要的是，我们没有使用测试集来选择参数。找到的参数保存在best_params_属性中，而交叉验证最佳精度（对于这种参数设置，不同划分的平均精度）保存在best_score_中。 12print("Best paraments:&#123;&#125;".format(grid_searsh.best_params_))print("Best cross-validation score:&#123;:.4f&#125;".format(grid_searsh.best_score_)) Best paraments:{&apos;C&apos;: 100, &apos;gamma&apos;: 0.01} Best cross-validation score:0.9732 注意：不要将best_score_与模型在测试集上调用score方法计算得到的泛化性能弄混。使用 score方法（或者对predict方法的输出进行评估）采用的是在整个测试集上的训练的模型。 best_score_属性保存的是交叉验证的平均精度，是在训练集上进行交叉验证得到的。 12#查看模型的最佳参数设置print("Best estimator:\n&#123;&#125;".format(grid_searsh.best_estimator_)) Best estimator: SVC(C=100, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&apos;ovr&apos;, degree=3, gamma=0.01, kernel=&apos;rbf&apos;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 1.分析交叉验证的结构 将交叉验证的结果可视化通常有助于理解模型泛化能力对所搜索参数的依赖关系。网格搜索的结果可以在cv_results_属性中找到，它是一个字典，其中保存了搜索的所有内容。 1234import pandas as pd#转换为dataframe（数据框）results = pd.DataFrame(grid_searsh.cv_results_)display(results.head()) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;mean_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split0_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split1_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split2_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split3_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split4_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;std_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } mean_fit_time mean_score_time mean_test_score mean_train_score param_C param_gamma params rank_test_score split0_test_score split0_train_score … split2_test_score split2_train_score split3_test_score split3_train_score split4_test_score split4_train_score std_fit_time std_score_time std_test_score std_train_score 0 0.000901 0.0004 0.366071 0.366079 0.001 0.001 {‘C’: 0.001, ‘gamma’: 0.001} 22 0.375 0.363636 … 0.363636 0.366667 0.363636 0.366667 0.380952 0.362637 0.000200 0.000200 0.011371 0.002852 1 0.000600 0.0001 0.366071 0.366079 0.001 0.01 {‘C’: 0.001, ‘gamma’: 0.01} 22 0.375 0.363636 … 0.363636 0.366667 0.363636 0.366667 0.380952 0.362637 0.000200 0.000200 0.011371 0.002852 2 0.000701 0.0003 0.366071 0.366079 0.001 0.1 {‘C’: 0.001, ‘gamma’: 0.1} 22 0.375 0.363636 … 0.363636 0.366667 0.363636 0.366667 0.380952 0.362637 0.000245 0.000245 0.011371 0.002852 3 0.000801 0.0003 0.366071 0.366079 0.001 1 {‘C’: 0.001, ‘gamma’: 1} 22 0.375 0.363636 … 0.363636 0.366667 0.363636 0.366667 0.380952 0.362637 0.000245 0.000245 0.011371 0.002852 4 0.000901 0.0004 0.366071 0.366079 0.001 10 {‘C’: 0.001, ‘gamma’: 10} 22 0.375 0.363636 … 0.363636 0.366667 0.363636 0.366667 0.380952 0.362637 0.000200 0.000200 0.011371 0.002852 5 rows × 22 columns results中每一行对应一种特定的参数设置。对于每种参数设置，交叉验证所有划分的结果都被记录下来，所有划分的平均值和标准查也被记录下来。 1234import numpy as npscores = np.array(results.mean_test_score).reshape(6,6)#对交叉验证平均分数作图mglearn.tools.heatmap(scores,xlabel='gamma',xticklabels=param_grid['gamma'],ylabel='C',yticklabels=param_grid['C'],cmap='viridis') &lt;matplotlib.collections.PolyCollection at 0x22093d8cfd0&gt; 由上图可知： 调节的参数对于获得良好的性能非常重要。这两个参数都很重要，因为调节它们可以将精度从40%提高到96%。 选择的参数范围中也可以看到输出发送了显著的变化。 参数的范围要足够大：每个参数的最佳值不能位于图像的边界上。 2.在非网格的空间中搜索 在某些情况下，尝试所有参数的所有组合并不是一个好主意。例如，svc有一个kernel参数，根据所选择的kernel，凄然参数也是与之相关的。 如果kernel=’linear’,那么模型时线性的，只会用到C参数。 如果kernel=’rbf’,则需要C和gamma两个参数。 在这种情况下，搜索C、gamma和kernel所有可能组合没有意义。为了处理这种“条件”参数，GridSearshCV的param_grid可以是字典组成的列表。列表中的每个字典可扩展为一个独立的网格。 123param_grid = [&#123;"kernel":['rbf'],'C':[0.001,0.01,0.10,100],'gamma':[0.001,0.01,0.10,100]&#125;,&#123;"kernel":['rbf'],'C':[0.001,0.01,0.10,100]&#125;]print("List of grids:\n&#123;&#125;".format(param_grid)) List of grids: [{&apos;kernel&apos;: [&apos;rbf&apos;], &apos;C&apos;: [0.001, 0.01, 0.1, 100], &apos;gamma&apos;: [0.001, 0.01, 0.1, 100]}, {&apos;kernel&apos;: [&apos;rbf&apos;], &apos;C&apos;: [0.001, 0.01, 0.1, 100]}] 12345from sklearn.model_selection import GridSearchCVgrid_search = GridSearchCV(SVC(),param_grid,cv=5)grid_search.fit(X_train,y_train)print("Best paramenters:&#123;&#125;".format(grid_search.best_params_))print("Best cross-value score:&#123;:.2f&#125;".format(grid_search.best_score_)) Best paramenters:{&apos;C&apos;: 100, &apos;gamma&apos;: 0.01, &apos;kernel&apos;: &apos;rbf&apos;} Best cross-value score:0.97 123import pandas as pdresults = pd.DataFrame(grid_search.cv_results_)display(results.T) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;mean_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split0_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split1_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split2_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split3_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;split4_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) D:\foreign\Python\py_version\Anaconda3.5\lib\site-packages\sklearn\utils\deprecation.py:122: FutureWarning: You are accessing a training score (&apos;std_train_score&apos;), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True warnings.warn(*warn_args, **warn_kwargs) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 mean_fit_time 0.00119858 0.00110116 0.000901127 0.00120177 0.000800276 0.000600481 0.000900602 0.00110054 0.000700569 0.000600529 0.000500393 0.000900316 0.000400209 0.000700712 0.000500774 0.00130043 0.000800467 0.000600433 0.000800419 0.000700617 mean_score_time 0.000503826 0.000400352 0.000299978 0.000399065 0.000300121 0.000300169 0.000300169 0.000500584 0.000400019 0.000300169 0.000400782 0.000399876 0.000200176 0.000200033 0.000200176 0.000400925 0.00010004 0.000300312 0.000300217 0.00010004 mean_test_score 0.366071 0.366071 0.366071 0.366071 0.366071 0.366071 0.366071 0.366071 0.366071 0.696429 0.919643 0.366071 0.964286 0.973214 0.955357 0.5625 0.366071 0.366071 0.955357 0.946429 mean_train_score 0.366079 0.366079 0.366079 0.366079 0.366079 0.366079 0.366079 0.366079 0.366079 0.696424 0.919744 0.366079 0.977676 0.984368 0.988788 1 0.366079 0.366079 0.946536 0.993258 param_C 0.001 0.001 0.001 0.001 0.01 0.01 0.01 0.01 0.1 0.1 0.1 0.1 100 100 100 100 0.001 0.01 0.1 100 param_gamma 0.001 0.01 0.1 100 0.001 0.01 0.1 100 0.001 0.01 0.1 100 0.001 0.01 0.1 100 NaN NaN NaN NaN param_kernel rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf rbf params {‘C’: 0.001, ‘gamma’: 0.001, ‘kernel’: ‘rbf’} {‘C’: 0.001, ‘gamma’: 0.01, ‘kernel’: ‘rbf’} {‘C’: 0.001, ‘gamma’: 0.1, ‘kernel’: ‘rbf’} {‘C’: 0.001, ‘gamma’: 100, ‘kernel’: ‘rbf’} {‘C’: 0.01, ‘gamma’: 0.001, ‘kernel’: ‘rbf’} {‘C’: 0.01, ‘gamma’: 0.01, ‘kernel’: ‘rbf’} {‘C’: 0.01, ‘gamma’: 0.1, ‘kernel’: ‘rbf’} {‘C’: 0.01, ‘gamma’: 100, ‘kernel’: ‘rbf’} {‘C’: 0.1, ‘gamma’: 0.001, ‘kernel’: ‘rbf’} {‘C’: 0.1, ‘gamma’: 0.01, ‘kernel’: ‘rbf’} {‘C’: 0.1, ‘gamma’: 0.1, ‘kernel’: ‘rbf’} {‘C’: 0.1, ‘gamma’: 100, ‘kernel’: ‘rbf’} {‘C’: 100, ‘gamma’: 0.001, ‘kernel’: ‘rbf’} {‘C’: 100, ‘gamma’: 0.01, ‘kernel’: ‘rbf’} {‘C’: 100, ‘gamma’: 0.1, ‘kernel’: ‘rbf’} {‘C’: 100, ‘gamma’: 100, ‘kernel’: ‘rbf’} {‘C’: 0.001, ‘kernel’: ‘rbf’} {‘C’: 0.01, ‘kernel’: ‘rbf’} {‘C’: 0.1, ‘kernel’: ‘rbf’} {‘C’: 100, ‘kernel’: ‘rbf’} rank_test_score 9 9 9 9 9 9 9 9 9 7 6 9 2 1 3 8 9 9 3 5 split0_test_score 0.375 0.375 0.375 0.375 0.375 0.375 0.375 0.375 0.375 0.708333 0.916667 0.375 1 1 0.958333 0.541667 0.375 0.375 0.958333 0.958333 split0_train_score 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.693182 0.943182 0.363636 0.977273 0.988636 0.988636 1 0.363636 0.363636 0.954545 0.988636 split1_test_score 0.347826 0.347826 0.347826 0.347826 0.347826 0.347826 0.347826 0.347826 0.347826 0.695652 0.913043 0.347826 0.956522 0.956522 1 0.478261 0.347826 0.347826 0.913043 0.956522 split1_train_score 0.370787 0.370787 0.370787 0.370787 0.370787 0.370787 0.370787 0.370787 0.370787 0.696629 0.932584 0.370787 0.977528 0.977528 0.977528 1 0.370787 0.370787 0.955056 0.988764 split2_test_score 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.681818 1 0.363636 1 1 1 0.590909 0.363636 0.363636 1 1 split2_train_score 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.7 0.9 0.366667 0.966667 0.977778 0.977778 1 0.366667 0.366667 0.944444 0.988889 split3_test_score 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.363636 0.681818 0.863636 0.363636 0.909091 0.954545 0.863636 0.590909 0.363636 0.363636 0.909091 0.863636 split3_train_score 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.366667 0.7 0.888889 0.366667 0.988889 0.988889 1 1 0.366667 0.366667 0.955556 1 split4_test_score 0.380952 0.380952 0.380952 0.380952 0.380952 0.380952 0.380952 0.380952 0.380952 0.714286 0.904762 0.380952 0.952381 0.952381 0.952381 0.619048 0.380952 0.380952 1 0.952381 split4_train_score 0.362637 0.362637 0.362637 0.362637 0.362637 0.362637 0.362637 0.362637 0.362637 0.692308 0.934066 0.362637 0.978022 0.989011 1 1 0.362637 0.362637 0.923077 1 std_fit_time 0.000247529 0.000200083 0.000200106 0.000246431 0.000244912 0.0002002 0.000374317 0.000200272 0.00024501 0.000200057 3.16298e-07 0.000200177 0.000200105 0.000244796 4.67203e-07 0.000400531 0.00024497 0.000200105 0.000244834 0.000245165 std_score_time 6.73742e-06 0.000200176 0.000244931 0.000199536 0.000245048 0.000245087 0.000245087 0.000316733 0.00020001 0.000245087 0.000200393 0.000199939 0.000245165 0.00024499 0.000245165 0.000200465 0.000200081 0.000245204 0.000245126 0.000200081 std_test_score 0.0113708 0.0113708 0.0113708 0.0113708 0.0113708 0.0113708 0.0113708 0.0113708 0.0113708 0.0131963 0.0440102 0.0113708 0.0340769 0.0223995 0.0495662 0.0496678 0.0113708 0.0113708 0.0394362 0.0443632 std_train_score 0.00285176 0.00285176 0.00285176 0.00285176 0.00285176 0.00285176 0.00285176 0.00285176 0.00285176 0.00325802 0.0212659 0.00285176 0.00703191 0.00548507 0.00999451 0 0.00285176 0.00285176 0.0124322 0.00550551 3.使用不同的交叉验证策略进行网格搜索 与cross_val_score类似，GridSearshCV对分类问题默认使用分层k折交叉验证，对回归问题默认使用k折交叉验证。但是，可以传入任何交叉验证分离器作为GridSearshCV的cv参数。特征地，如果只想将数据单次划分为训练集个验证集，可以使用ShuffSplit或StratifedShuffleSplit，并设置n_iter=1。 （1）嵌套交叉验证 在前面的例子中，先介绍了将数据单次划分为训练集、验证集与测试集，然后介绍了先将数据划分训练集和测试集，再在训练集上进行交叉验证。但前面在使用GridSearchCV时，仍然将数据单次划分为训练集和测试集，这可能会导致结果不稳定，也过于依赖于数据的此次划分。可以再深入一点，不是只将原始数据一次划分为训练集和测试集，而是使用交叉验证进行多次划分，这就是所谓的嵌套交叉验证。 在嵌套交叉中，有一个外层循环，遍历将数据划分为训练集和测试集的所有划分。对于每种划分都运行一次网格搜索（对于外层循环的每种划分可能会得到不同的最佳参数）。然后，对于每种外层划分，利用最佳参数设置计算得到测试集分数。 1234from sklearn.model_selection import cross_val_scorescores = cross_val_score(GridSearchCV(SVC(),param_grid,cv=5),iris.data,iris.target,cv=5)print("Cross-validation scores:",scores)print("Mean cross-validation score:",scores.mean()) Cross-validation scores: [0.96666667 1. 0.96666667 0.96666667 1. ] Mean cross-validation score: 0.9800000000000001 (2)交叉验证与网格搜索并行 虽然在许多参数上运行网格搜索和在大型数据集上运行网格搜索的计算了可能很大，但令人尴尬的是，这些计算都是并行的。这也就是说，在一种交叉验证划分下使用特定参数设置来构建一个模型，与利用其他参数的模型时完全独立的。这使得网格搜索与交叉验证成为多个CPU内核或集群上并行化的理想选择。可以将n_jobs参数设置为你想使用的CPU内核数量，从而在GridSearchCV和cross_val_score中使用多个核。可以设置n_jobs=-1来使用所有可用的内核。 评估指标与评分到目前位置，我们使用精度（正确分类的样本所占的比例）来评估分类性能，使用R评分来评估回归性能。但是，总结监督模型在给定数据集上的表现有多种方法，这两个指标只是其中两种。在实践中，这些评估指标可能不适用于你的应用。在选择模型与调参时，选择正确的指标时很重要的。 牢记最终目标 在实践中，通常不仅对精确的预测感兴趣，还希望将这些预测结果用于更大的决策过程。在选择机器学习指标之前，应该考虑高级目标，这通常称为商业影响。 高级目标可能是避免交通事故或者减少入院人数，也可能是吸引更多的网站用户或者让用户在你的商店中花更多的钱。 在选择模型或调参时，应该选择对商业指标具有最大正面影响的模型或参数值。 下面将首先讨论二分类这一重要特例的指标，然后转向多分类问题，最后讨论回归问题。 二分类指标二分类可能是实践中最常见的机器学习应用，也是概念最简单的应用。但是，即使是评估这个简单任务也仍有一些注意事项。通常会说正类和反类，而正类是我们要寻找的类。 1.错误类型 通常来说，精度并不是很好地度量预测性能，因为我们所错误的数量并不包含我们感兴趣的所有信息。想象一个应用，利用自动化测试来筛查癌症的早期发现。如果测试结果为阴性，那么认为患者是健康的，而如果测试结果为阳性，患者则需要接受额外的筛查。 一种可能的错误是健康的患者被诊断为阳性，导致需要进行额外的测试。这给患者带来了一些额外的费用支出和不便（可能还会精神上的痛苦)。错误的阳性预测叫作假正例（false positive），在统计学中被称为第一类错误。 另一种可能的错误是患病的人被诊断为阴性，因而不会接受进一步的检查和治疗。未诊断出的癌症可能导致严重的健康问题，甚至可能致命。这种类型的错误（错误的阴性预测）叫作假反例（false negative），在统计学上被称为第二类错误。 我们依然沿用“假正例”和“假反例”的说法，因为它们的含义更加明确，也更好记。在癌症诊断的例子中，显然，我们希望尽量避免假反例，而假正例可以被看作是小麻烦。 2.不平衡数据集 如果在两个类别中，一个类别的的出现次数比另一个多很多，那么错误类型将发挥重要作用。这在实践中十分常见，一个很好的例子是点击（click-through）预测。我们可能需要要向用户展示100非广告或文章，他们才会找到足够有趣的内容来点击查看。这样就会得到一个数据集，其中每99个“未点击”的数据才有1个“已点击”的数据点。换句话说，99%的样本属于“未点击”类别。 这种一个类别比另一个类别出现次数多很多的数据集，通常叫作不平衡数据集（imbalance dataset）或者具有不平衡类别的数据集（dataset with imbalance classes）。在实际当中，不平衡数据才是常态，而数据中感兴趣事件的次数相同会相似的情况十分罕见。 要想对这种不平衡数据的预测性能能进行量化，精度并不是一种合适的度量。我们希望在选择模型方面能够提供更好指导的其他指标，可以告诉我们，一个模型比“最常见”预测或随机预测要好多少。 3.混淆矩阵 对于二分类问题的评估结果，一种最全面的表示方法是使用淆矩阵（confusion matrix）。 混淆矩阵主对角线上的元素对应于正确的分类，而其他元素组告诉我们一个类别中有多少样本被错误地划分到其他类别中。 12import mglearnmglearn.plots.plot_confusion_matrix_illustration() TP：真正例 TF：真假例 FP：假正例 FT：假反例 1mglearn.plots.plot_binary_confusion_matrix() 总结混淆矩阵还有集中方法，其中最常见的就是准确率、召回率和F值。 准确率：度量的是被预测为正例的样本中有多少是真正的正例：P = TP/(TP+FP)。 召回率：度量的是正类样本中有多少被预测为正类：R = TP/(FN+TP)。 F值：虽然准确率和召回率是非常重要的度量，但是仅查看二者之一无法提供完整的图景。将两种度量进行汇总的一种方法是F值，它是准确率与召回率的调和平均：F=2*(precision*recall)/(precision+recall)，同时考虑了准确率和召回率，所以它对于不平衡的二分类数据集来说是一种比精度更好的度量。 4.考虑不确定性 混淆矩阵和分类报告为一组特定的预测提供了非常详细的分析。但是，预测本身已经丢弃了模型中包含的大量信息。正如第2章所讨论的那样，大多数分类器都提供了一个decision_function或predict_proba方法来评估预测的不确定度。预测可以被看作以某个固定点作为decision_function或predcit_proba输出的阈值——在二分类问题中，使用0作为决策函数的阈值，0.5作为predict_proba的阈值。 123456from mglearn.datasets import make_blobsfrom sklearn.model_selection import train_test_splitfrom sklearn.svm import SVCX,y = make_blobs(n_samples=(400,50),centers=2,cluster_std=[7.0,2],random_state=22)X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)svc = SVC(gamma=.05).fit(X_train,y_train) 1mglearn.plots.plot_decision_threshold() 1234#使用分类报告评估两个类别的准确率与召回率from sklearn.metrics import classification_report,f1_scoreprint(classification_report(y_test,svc.predict(X_test)))print(f1_score(y_test,svc.predict(X_test))) precision recall f1-score support 0 0.97 0.89 0.93 104 1 0.35 0.67 0.46 9 avg / total 0.92 0.88 0.89 113 0.46153846153846156 对于类别1，得到了一个相当低的准确率，而召回率则令人失望。由于0要大的多，所以分类器将重点放在将类别0分类正确，而不是较小的类别1。假设在我们的应用中，类别1具有高召回率更加重要，即愿意冒险判定更多的假正例（FP）,换取更多的真正例（TP），这会提高类别1的召回率：R=TP/(FN+TP)因为FN的个数会减少。通过控制默认decision_function值大于0将被化为类别1，如果希望更多的点华为类别1，所有需要减小阈值。 1y_pred_lower_threshold =svc.decision_function(X_test) &gt; -.8 1print(classification_report(y_test,y_pred_lower_threshold)) precision recall f1-score support 0 1.00 0.82 0.90 104 1 0.32 1.00 0.49 9 avg / total 0.95 0.83 0.87 113 类别1的召回率增大，准确率减少。现在我们将更大的空间区域划为类别1。如果认为准确率比召回率更重要，或者反过来，或者数据严重不平衡，那么改变决策阈值是得到更好结果是最简单方法。由于decision_function的取值可能在任意范围，所以很难提供关于如何选取阈值的经验法则。 如果设置了阈值，那么要小心不要在测试集上这么做。与其他任何参数一样，在测试集上设置决策阈值可能会得到过于乐观的结果。可以使用验证集或交叉验证来代替。 5.准确率-召回率曲线 对分类器设置要求（比如90%的召回率）通常被称为设置工作点，在业务中固定工作点通常有助于客户或组织内的其他小组提供性能保证。在开发新模型时，通常不完全清楚工作点在哪里。因此，为了更好理解建模问题，很有启发性的做法是，同时查看所有可能的阈值或准确率和召回率的所有可能折中。 123from sklearn.metrics import precision_recall_curvedatas = precision_recall_curve(y_test,svc.decision_function(X_test)) precision_recall_curve函数返回一个列表，包含按顺序的所有可能阈值（在决策函数中出现的所有值）对应的准确率和召回率，这样就可以绘制一条曲线。 1datas (array([0.32142857, 0.2962963 , 0.30769231, 0.32 , 0.33333333, 0.34782609, 0.36363636, 0.38095238, 0.4 , 0.36842105, 0.33333333, 0.35294118, 0.375 , 0.4 , 0.42857143, 0.38461538, 0.41666667, 0.45454545, 0.4 , 0.44444444, 0.5 , 0.57142857, 0.66666667, 0.6 , 0.5 , 0.66666667, 0.5 , 1. , 1. ]), array([1. , 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.77777778, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.55555556, 0.55555556, 0.55555556, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.33333333, 0.22222222, 0.22222222, 0.11111111, 0.11111111, 0. ]), array([-0.7512563 , -0.58749402, -0.48739733, -0.44364565, -0.40435353, -0.28965335, -0.24173165, -0.19257469, -0.17852475, -0.16644845, -0.1601932 , 0.08620484, 0.14630375, 0.19153373, 0.36988055, 0.52008479, 0.5230006 , 0.53195462, 0.63212214, 0.74430046, 0.87212596, 0.88002558, 0.88395198, 0.97789353, 1.00010384, 1.07030762, 1.08436417, 1.25059991])) 1234567891011121314import numpy as npimport matplotlib.pyplot as pltX,y = make_blobs(n_samples=(4000,500),centers=2,cluster_std=[7.0,2],random_state=22)X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)svc = SVC(gamma=.05).fit(X_train,y_train)precision,recall,thresholds = precision_recall_curve(y_test,svc.decision_function(X_test))#找到最接近0的阈值close_zero = np.argmin(np.abs(thresholds))plt.plot(precision[close_zero],recall[close_zero],'o',markersize =10,label= 'threshold zero',fillstyle='none',c='k',mew=2)plt.plot(precision,recall,label="precision recall curve" )plt.ylabel("Recall")plt.xlabel("Precision")plt.legend(loc='best') &lt;matplotlib.legend.Legend at 0x1d3f8c7c550&gt; 曲线越靠近右上角，则分类器越好。右上角的点表示对于同一个阈值，准确率和召回率都很高。 曲线从左上角开始，这里对应于非常低的阈值，将所有样本都划为正类。提高阈值可以让曲线向准确率更高的方向移动，但同时召回率降低。 继续增大阈值，大多数被划为正类的点都是真正例，此时准确率很高，但召回率更低。随着准确率的升高，模型就能够保持较高的召回率，则模型越好。 进一步观察曲线，可以发现，利用这个模型可以得到约为0.5的准确率，同时保持很高的召回率。如果我们想要提高准确率，那么就必须牺牲很多召回率。换句话说，曲线左侧相对平坦，说明在准确率提高的同时召回率没有下降很多。当准确率大于0.5之后，准确率每增加一点都会导致召回率下降许多。 12345678910111213from sklearn.ensemble import RandomForestClassifierrf = RandomForestClassifier(n_estimators=100,random_state=0,max_features=2)rf.fit(X_train,y_train)precision_rf,recall_rf,thresholds_rf = precision_recall_curve(y_test,rf.predict_proba(X_test)[:,1])plt.plot(precision,recall,label='svc')plt.plot(precision[close_zero],recall[close_zero],'o',markersize =10,label= 'threshold zero',fillstyle='none',c='k',mew=2)plt.plot(precision_rf,recall_rf,label='rf')close_default_rf =np.argmin(np.abs(thresholds_rf-0.5))plt.plot(precision_rf[close_default_rf],recall_rf[close_default_rf],'^',markersize =10,label= 'threshold 0.5 rf',fillstyle='none',c='k',mew=2)plt.ylabel("Recall")plt.xlabel("Precision")plt.legend(loc='best') &lt;matplotlib.legend.Legend at 0x1d3f9d34cc0&gt; 从这张对比图中可以看出，随机森林在极值处（要求很高的准确率或者很高的召回率）的表现更好。在中间位置SVM表现更好。如果我们只查看F值分数来比较二者的总体性能，那么可能就会遗漏这些细节。F值只反映啦准确率-召回率曲线上的一个点，即默认阈值对应的那个点。 12print("f_score of random forest:&#123;:.3f&#125;".format(f1_score(y_test,rf.predict(X_test))))print("f_score svm:&#123;:.3f&#125;".format(f1_score(y_test,svc.predict(X_test)))) f_score of random forest:0.610 f_score svm:0.656 比较这两条准确率-召回率曲线，可以为我们提供大量详细的信息，但这是一个相当麻烦的过程。对于自动化模型对比，可能希望总结曲线中包含的信息，而不限于某个特定的阈值或工作点。 总结准确率-召回率的一种方法就是计算该曲线下的积分或面积，也叫作平均准确率。 12345from sklearn.metrics import average_precision_scoreap_rf = average_precision_score(y_test,rf.predict_proba(X_test)[:,1])ap_svc = average_precision_score(y_test,svc.decision_function(X_test))print("Average precision of random forest:&#123;:.3f&#125;".format(ap_rf))print("Average precision of random forest:&#123;:.3f&#125;".format(ap_svc)) Average precision of random forest:0.660 Average precision of random forest:0.666 6.受试者工作特征（ROC）与AUC 还有一种常用的工具可以分析不同阈值的分类器行为：受试者工作特征曲线（receiver operating characteristics curve）,简称为ROC曲线（ROC curve）。与准确率-召回率曲线类似，ROC曲线考虑了给定分类器的所有可能的阈值，但它显示的是假正例率（fasle positive rate，FPR）和真正例（true positive rate，TPR），而不是报告准确率和召回率。 真正例率与召回率相同:TPR = TP/(TP+FN) 假正例率是假正例占所有反类样本的比例：FPR=FP/(FP+TN) 12345678from sklearn.metrics import roc_curvefpr,tpr,thresholds = roc_curve(y_test,svc.decision_function(X_test))plt.plot(fpr,tpr,label='ROC curve')plt.ylabel("FPR")plt.xlabel("TRP(recall)")close_zero = np.argmin(np.abs(thresholds))plt.plot(fpr[close_zero],tpr[close_zero],'o',markersize =10,label= 'threshold zero',fillstyle='none',c='k',mew=2)plt.legend(loc=4) &lt;matplotlib.legend.Legend at 0x1d3f9dc31d0&gt; 对于ROC曲线，理想的曲线要靠近左上角：希望分类器的召回率很高，同时保持假正例率很低。从曲线中可以看出，与默认阈值0相比，可以得到明显更高的召回率（约0.9），而FPR仅稍有增加。最接近左上角的点可能是比默认选择更好的工作点。同样注意，不应该在测试集上选择阈值，二十应该在单独的验证集上选择。 1234567891011from sklearn.metrics import roc_curvefrom sklearn.metrics import roc_curvefpr_rf,tpr_rf,thresholds_rf = roc_curve(y_test,rf.predict_proba(X_test)[:,1])plt.plot(fpr,tpr,label='ROC curve SVC')plt.plot(fpr_rf,tpr_rf,label='ROC curve RF')plt.ylabel("FPR")plt.xlabel("TRP(recall)")plt.plot(fpr[close_zero],tpr[close_zero],'o',markersize =10,label= 'threshold zero',fillstyle='none',c='k',mew=2)close_zero = np.argmin(np.abs(thresholds_rf-0.5))plt.plot(fpr_rf[close_zero],tpr_rf[close_zero],'^',markersize =10,label= 'threshold zero',fillstyle='none',c='k',mew=2)plt.legend(loc=4) &lt;matplotlib.legend.Legend at 0x1d3fa01b438&gt; 与准确率-召回率曲线一样，通常希望使用一个数字来总结ROC曲线，即曲线下的面积[通常被称为AUC(area under the curve)]，这里的曲线指的就是ROC曲线。 12345from sklearn.metrics import roc_auc_scorerf_auc = roc_auc_score(y_test,rf.predict_proba(X_test)[:,1])svc_auc = roc_auc_score(y_test,svc.decision_function(X_test))print("AUC for Random Forest:&#123;:.3f&#125;".format(rf_auc))print("AUC for SVC:&#123;:.3f&#125;".format(svc_auc)) AUC for Random Forest:0.937 AUC for SVC:0.916 利用AUC分数来比较随机森林和SVM，发现随机森林的表现比SVM要略好一些。由于平均准确率是从0到1的曲线下的面积，所有平均准确率总是返回一个0到1之间的值。随机预测得到的AUC总是等于0.5，无论数据集中的类别多么不平衡。对于不平衡的分类问题来说，AUC是一个比精度好得多的指标。AUC可以被解释为评估正例样本的排名。它等价于从正类样本中随机挑选一个点，由分类器给出的分数比从反类样本中随机挑选一个点的分数更高的概率。 强烈建议在不平衡数据集上评估模型时使用AUC。但是，AUC没有使用默认阈值，因此，为了从高AUC的模型中得到有用的分类结果，可能还需要调节决策阈值。 多分类指标多分类问题的所有指标基本上都来自于二分类指标，但是要对所有类别进行平均。多分类的精度被定义为正确分类的样本所占的比例。同样，如果类别不平衡的，精度并不是很好的评估度量。想象一个三分类问题，其中85%的数据点属于类别A，10%属于类别B,5%属于类别C。在这个数据集上85%的精度说明了什么？一般来说，多分类结果比二分类结果更加难以理解。除了精度，常用的工具具有混淆矩阵和分类报告。 1234567891011from sklearn.datasets import load_digitsfrom sklearn.metrics import accuracy_scorefrom sklearn.metrics import confusion_matrixfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splitdigits = load_digits()X_train,X_test,y_train,y_test = train_test_split(digits.data,digits.target,random_state=0)lr = LogisticRegression().fit(X_train,y_train)pred = lr.predict(X_test)print("Accuracy:&#123;:.3f&#125;".format(accuracy_score(y_test,pred)))print("Confusion matrix:\n&#123;&#125;".format(confusion_matrix(y_test,pred))) Accuracy:0.953 Confusion matrix: [[37 0 0 0 0 0 0 0 0 0] [ 0 39 0 0 0 0 2 0 2 0] [ 0 0 41 3 0 0 0 0 0 0] [ 0 0 1 43 0 0 0 0 0 1] [ 0 0 0 0 38 0 0 0 0 0] [ 0 1 0 0 0 47 0 0 0 0] [ 0 0 0 0 0 0 52 0 0 0] [ 0 1 0 1 1 0 0 45 0 0] [ 0 3 1 0 0 0 0 0 43 1] [ 0 0 0 1 0 1 0 0 1 44]] 1234import mglearnscores_image=mglearn.tools.heatmap(confusion_matrix(y_test,pred),xlabel='predicted label',ylabel='True label',xticklabels=digits.target_names,yticklabels=digits.target_names,cmap=plt.cm.gray_r,fmt='%d')plt.title("Confusion matrix")plt.gca().invert_yaxis() 1print(classification_report(y_test,pred)) precision recall f1-score support 0 1.00 1.00 1.00 37 1 0.89 0.91 0.90 43 2 0.95 0.93 0.94 44 3 0.90 0.96 0.92 45 4 0.97 1.00 0.99 38 5 0.98 0.98 0.98 48 6 0.96 1.00 0.98 52 7 1.00 0.94 0.97 48 8 0.93 0.90 0.91 48 9 0.96 0.94 0.95 47 avg / total 0.95 0.95 0.95 450 对于多分类问题中的不平衡数据集，最常用的指标就是多分类版的F值。多分类F值背后的想法是，对每个类别计算一个二分类F值，其中该类别是正类，其他所有类别组成反类。然后，使用以下策略之一对这些类别F值进行平均。 “宏”平均：计算未加权的按类别F值。它对所有类别给出相同的权重，无论类别中的样本量大小。 “加权”平均：以每个类别的支持作为权重计算按类别F值的平均值。分类报告中给出的就是这个值。 “微”平均：计算所有类别中假正例、假反例和真正例的总数，然后利用这些计数来计算准确率、召回率和F值。 如果你对每个样本等同看待，那么推荐使用“微”平均F值；如果你对每个类别等同看待，那么推荐使用“宏”平均F值。 12print("Micro average f1 score:&#123;:.3f&#125;".format(f1_score(y_test,pred,average="micro")))print("Macro average f1 score:&#123;:.3f&#125;".format(f1_score(y_test,pred,average="macro"))) Micro average f1 score:0.953 Macro average f1 score:0.954 回归指标对回归问题可以像分类问题一样进行详细评估，例如，对目标值估计过高与目标值估计过低进行对比分析。但是，对于我们见过的大多数应用来说，使用默认R平方足够了，它由所有回归器的score方法给出。业务决策有时是根据均方误差或平均绝对误差做出的，这可能会鼓励使用这些指标来调节模型。但是一般来说，认为R平方是评估回归模型的更直观的指标。 在模型选择中使用评估指标通常希望，在使用GridSearchCV或cross_val_score进行模型选择时能够使用AUC等指标。幸运的是，scikit-learn提供了一种非常简单的实现方法，就是scoring参数，它可以同时用于GridSearchCV或cross_val_score。只需提供一个字符串，用于描述想要使用的评估指标。 12345678from sklearn.model_selection import cross_val_scorefrom sklearn.svm import SVC#分类问题的默认评分是精度print("default scoring:&#123;&#125;".format(cross_val_score(SVC(),digits.data,digits.target==9)))explicit_accuracy=cross_val_score(SVC(),digits.data,digits.target==9,scoring="accuracy")print("Explicit accuracy scoring:&#123;&#125;".format(explicit_accuracy))roc_auc=cross_val_score(SVC(),digits.data,digits.target==9,scoring="roc_auc")print("AUC scoring&#123;&#125;".format(roc_auc)) default scoring:[0.89983306 0.89983306 0.89983306] Explicit accuracy scoring:[0.89983306 0.89983306 0.89983306] AUC scoring[0.99372294 0.98957947 0.99594929] 类似地，可以改变GriSearchCV中用于选择最佳参数的指标： 1234567891011121314from sklearn.model_selection import GridSearchCVfrom sklearn.metrics import roc_auc_scoreX_train,X_test,y_train,y_test=train_test_split(digits.data,digits.target==9,random_state=0)# 给出了不太好的网格来说明param_grid=&#123;"gamma":[0.0001,0.01,0.1,1,10]&#125;#使用默认的精度grid=GridSearchCV(SVC(),param_grid=param_grid)grid.fit(X_train,y_train)print("Grid-Search with accuracy")print("Best parameters",grid.best_params_)print("Best cross-validation score(accuracy):&#123;:.3f&#125;".format(grid.best_score_))print("Test set AUC:&#123;:.3f&#125;".format(roc_auc_score(y_test,grid.decision_function(X_test))))print("Test set accuracy:&#123;:.3f&#125;".format(grid.score(X_test,y_test))) Grid-Search with accuracy Best parameters {&apos;gamma&apos;: 0.0001} Best cross-validation score(accuracy):0.970 Test set AUC:0.992 Test set accuracy:0.973 1234567grid=GridSearchCV(SVC(),param_grid=param_grid,scoring="roc_auc")grid.fit(X_train,y_train)print("Grid-Search with AUC")print("Best parameters",grid.best_params_)print("Best cross-validation score(accuracy):&#123;:.3f&#125;".format(grid.best_score_))print("Test set AUC:&#123;:.3f&#125;".format(roc_auc_score(y_test,grid.decision_function(X_test))))print("Test set accuracy:&#123;:.3f&#125;".format(grid.score(X_test,y_test))) Grid-Search with AUC Best parameters {&apos;gamma&apos;: 0.01} Best cross-validation score(accuracy):0.997 Test set AUC:1.000 Test set accuracy:1.000 在使用精度时，选择的参数是gamma=0.0001，而使用AUC时选择的参数是gamma=0.01。在两种情况下，交叉验证精度与测试集精度是一致的。但是，使用AUC找到的参数设置，对应的AUC更高，设置对应的精度也更高。 对于分类问题，scoring参数最重要的取值： accuracy(默认值) roc_auc(ROC曲线下方的面积) average_precision(准确率-召回率下方的面积) f1值 f1_macro f1_micro f1_weighted 对于回归问题，最常用的取值： r^2 mean_squared_error(均分误差) mean_absolute_error(平均绝对误差) 12from sklearn.metrics.scorer import SCORERSprint("可用得分的参数:\n&#123;&#125;".format(sorted(SCORERS.keys()))) 可用得分的参数: [&apos;accuracy&apos;, &apos;adjusted_mutual_info_score&apos;, &apos;adjusted_rand_score&apos;, &apos;average_precision&apos;, &apos;completeness_score&apos;, &apos;explained_variance&apos;, &apos;f1&apos;, &apos;f1_macro&apos;, &apos;f1_micro&apos;, &apos;f1_samples&apos;, &apos;f1_weighted&apos;, &apos;fowlkes_mallows_score&apos;, &apos;homogeneity_score&apos;, &apos;log_loss&apos;, &apos;mean_absolute_error&apos;, &apos;mean_squared_error&apos;, &apos;median_absolute_error&apos;, &apos;mutual_info_score&apos;, &apos;neg_log_loss&apos;, &apos;neg_mean_absolute_error&apos;, &apos;neg_mean_squared_error&apos;, &apos;neg_mean_squared_log_error&apos;, &apos;neg_median_absolute_error&apos;, &apos;normalized_mutual_info_score&apos;, &apos;precision&apos;, &apos;precision_macro&apos;, &apos;precision_micro&apos;, &apos;precision_samples&apos;, &apos;precision_weighted&apos;, &apos;r2&apos;, &apos;recall&apos;, &apos;recall_macro&apos;, &apos;recall_micro&apos;, &apos;recall_samples&apos;, &apos;recall_weighted&apos;, &apos;roc_auc&apos;, &apos;v_measure_score&apos;] 小结与展望 交叉验证或者使用测试集可以评估一个机器学习模型未来的表示。但是，如果使用测试集或交叉验证来选择模型或选择模型参数，那么我们就“用完”测试数据，而使用相同的数据来评估模型未来的表现将会得到过于乐观的估计。因此，需要将数据集划分为训练数据、验证数据与测试数据： 训练集用于模型构建 验证集用于选择模型与参数 测试集用于评估模型 用叉验证来代替每一次简单的划分。最常用的形式是训练/测试划分用于评估，然后对测试集使用交叉验证来选择模型与参数。 机器学习任务的最终目标很少是构建一个高精度的模型。一定要确定你用于模型评估与选择的指标能够很好地替代模型的实际用途。在实际当中，分类问题很好会遇到平衡的类别，假正例和假反例也通常具有非常不同的后果。一定要了解这些后果，并选择相应的评估指标。 算法链与管道对于许多机器学习算法，提供的特定数据表示非常重要。首先对数据进行缩放，然后手动合并特征，再利用无监督机器学习来学习特征。因此，大多数机器学习应用不仅需要应用单个算法，而且还需要将许多不同处理步骤和机器学习模型链接一起。下面例子中，实现了划分数据、计算最小值和最大值、缩放数据与训练SVM： 12345678910111213141516171819from sklearn.svm import SVCfrom sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import MinMaxScaler#加载并划分数据cancer = load_breast_cancer()X_train,X_test,y_train,y_test = train_test_split(cancer.data,cancer.target,random_state=0)#计算数据的最小值和最大值scaler = MinMaxScaler().fit(X_train)#对数据进行缩放X_train_scaled = scaler.transform(X_train)#在缩放后的训练数据集上学习svm = SVC()svm.fit(X_train_scaled,y_train)#对测试集数据进行缩放，并计算缩放后的数据的分数X_test_scaled = scaler.transform(X_test)print("Test accuracy score:&#123;:.3f&#125;".format(svm.score(X_test_scaled,y_test))) Test accuracy score:0.951 用预处理进行参数选择1234567from sklearn.model_selection import GridSearchCVparam_grid = &#123;"C":[0.001,0.01,0.1,1,10,100],"gamma":[0.001,0.01,0.1,1,10,100]&#125;grid = GridSearchCV(SVC(),param_grid=param_grid,cv=5)grid.fit(X_train_scaled,y_train)print("Best cross-validation accuracy:&#123;:.3f&#125;".format(grid.best_score_))print("Best set score:&#123;:.3f&#125;".format(grid.score(X_test_scaled,y_test)))print("Best parameters:",grid.best_params_) Best cross-validation accuracy:0.981 Best set score:0.972 Best parameters: {&apos;C&apos;: 1, &apos;gamma&apos;: 1} 这里利用缩放后的数据对SVC参数进行网格搜索。但是，上面的代码中有一个不易察觉的陷阱。在缩放数据时，使用了训练集中的所有数据来找到训练的方法。然后，使用缩放后的训练数据运行带交叉验证的网格搜索。对于交叉验证中的每次划分，原始训练集的一部分被划分为训练部分，另一部分被划分为测试部分。测试部分用于度量在训练部分上所训练的模型在新数据上的表现。但是，在缩放数据时已经使用过测试部分中所包含的信息。交叉验证每次划分的测试部分都是训练集的一部分，使用这个训练集的信息来找到数据的正确缩放。 对于模型来说，这些数据与新数据看起来截然不同。如果观察新数据（比如测试集中的数据），那么这些数据并没有用于对训练数据进行缩放，其最大值和最小值也可能与训练数据不同。下图显示了交叉验证与最终评估这连个过程中数据处理的不同之处。 12import mglearnmglearn.plots.plot_improper_processing() 对于建模过程，交叉验证中的无法正确地反映新数据的特征。这将导致在交叉验证过程中得到过于乐观的结果，并可能会导致选择次优的参数。 为了解决这个问题，在交叉验证过程中，应该在任何与处理之前完成数据集的划分。任何从数据集中提取信息的处理过程都应该仅应用于数据记得训练部分，因此，任何交叉验证都应该位于处理过程的“最外层循环”。 构建管道如何使用Pipeline类来表示在使用MinMaxScaler缩放数据之后再训练一个SVM的工作流程。 1234567#首先，构建一个由步骤列表组成的管道对象。每个步骤都是一个元组，其中包含一个名称和一个估计器的实例from sklearn.pipeline import Pipelinepipe = Pipeline([("sccler",MinMaxScaler()),("svm",SVC())])#这里pipe.fit首先对第一个步骤调用dit，然后使用该数据器对训练数据进行变换，最后用缩放后的数据来拟合SVM。pipe.fit(X_train,y_train)print("Test score:&#123;:.3f&#125;".format(pipe.score(X_test,y_test))) Test score:0.951 如果对管道调用score方法，则首先使用缩放器对测试数据进行变换，然后利用缩放后的测试数据对SVM调用score方法。这个结果与我们开始代码得到的结果一致。利用管道： 减少了“预处理+分类”过程所需要的代码量。 使用管道的主要优点在于，可以在cross_val_score或GridSearchCV中使用这个估计器。 在网格搜索中使用管道1234567# svm__C和svm__gammaparam_grid = &#123;"svm__C":[0.001,0.01,0.1,1,10,100],"svm__gamma":[0.001,0.01,0.1,1,10,100]&#125;grid = GridSearchCV(pipe,param_grid=param_grid,cv=5)grid.fit(X_train,y_train)print("Best cross-validation accuracy:&#123;:.3f&#125;".format(grid.best_score_))print("Best set score:&#123;:.3f&#125;".format(grid.score(X_test,y_test)))print("Best parameters:",grid.best_params_) Best cross-validation accuracy:0.981 Best set score:0.972 Best parameters: {&apos;svm__C&apos;: 1, &apos;svm__gamma&apos;: 1} 1mglearn.plots.plot_proper_processing() 在交叉验证中，信息泄漏的影响大小取决于预处理步骤的性质。使用测试部分来估计数据的范围，通常不会产生可怕的影响，但在特征提取和特征选择中使用测试部分，则会导致结果的显著差异。 通用的管道接口PipeLine类不但可用于处理和分类，实际上还可以将任意数量的估计器连接在一起。例如，可以构建一个包含特征提取、特征选择、缩放和分类的管道，总共4个步骤。同样，最后一步可以用回归或聚类代替分类。对于管道中估计器的唯一要求就是，除了最后一步之外的所有步骤都需要具有transform方法，这样他们可以生成新的数据表示，以供下一个步骤使用。 在调用Pipeline.fit的过程中，管道内部依次对每个步骤调用fit和transform，其输入是前一个步骤中transform方法的输出。对于管道中的最后一步，则仅调用fit。 用make_pipeline方便地创建管道利用上述语法创建管道有时有点麻烦，通常不需要为每一个步骤提供用户指定的名称。有一个很方便的函数make_pipeline，可以创建管道并根据每个步骤所属的类为其自动命名。 12345from sklearn.pipeline import make_pipeline#标准语法pipe_long = Pipeline([("scler",MinMaxScaler()),("svm",SVC(C=100))])#缩写语法pipe_short= make_pipeline(MinMaxScaler(),SVC(C=100)) 1print("Pipeline steps:\n&#123;&#125;".format(pipe_short.steps)) Pipeline steps: [(&apos;minmaxscaler&apos;, MinMaxScaler(copy=True, feature_range=(0, 1))), (&apos;svc&apos;, SVC(C=100, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;rbf&apos;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False))] 一般来说，步骤名称只是类名称的小写版本。如果多个步骤属于同一个类，则会附加一个数字。 小结Pipeline是一种通用工具，可以将机器学习工作流程中的多个处理步骤连接在一起。现实世界中的机器学习应用很少仅涉及模型的单独使用，而是需要一系列处理步骤。使用管道可以将多个步骤封装为单个Python对象，这个对象具有我们熟悉的scikit-learn接口fit、predict、transform。特别是使用交叉验证进行模型评估与使用网格搜索进行参数选择时，使用Pipeline类来包括所有处理步骤对正确的评估至关重要。利用Pipeline类还可以让代码更加简洁，并减少不用pipeline类构建处理链时可能会犯的错误（比如忘记将所有变换器应用于测试集，或者应用顺序错误）的可能性。选择特征提取、预处理和模型的正确组合，这在某种程度上是一门艺术，通常需要一些试错。但是有了管道，这种“尝试”多个不同的处理步骤是非常简单的。在进行试验时，要小心不要将处理过程复杂化，并且一定要评估一些模型中每个组件是否必要。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>数据分析</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python简介]]></title>
    <url>%2F2018%2F06%2F16%2Fpython%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[python简介——人生苦短，我用Python C程序犹如拿着剃刀在刚打过蜡的地板上劲舞。——Waldi RavensC++学起来很难，因为它天生如此。——佚名Java从很多方面来说，就是简化版的C++。——Michael Feldman接下来请欣赏与众不同的表演。——巨蟒剧团之《飞翔的马戏团》 Python是什么？为何要使用它？官方宣传说：Python是一种面向对象的解释性高级编程语言，具有动态语义。这句话中有很多术语，在阅读本书的过程中，你会逐渐了解其含义。这句话的要点在于，Python是一种知道如何不妨碍你编写程序的编程语言。它让你能够毫无困难地实现所需的功能，还让你能够编写出清晰易懂的程序（与使用当前流行的其他大多数编程语言相比，编写出来的程序要清晰易懂得多）。虽然Python的速度可能没有C、C++等编译型语言那么快，但它能够节省编程时间。仅考虑到这一点就值得使用Python，况且对大多数程序而言，速度方面的差别并不明显。如果你是C语言程序员，那么你可轻松地使用C语言实现程序的重要部分，再将其与Python部分整合起来。如果你没有任何编程经验（并对我提及C和C++感到有点迷惑），那么简洁而强大的Python就是你进入编程殿堂的理想选择。尽管每种编程语言都具有各自的特点，但在某些方面，它们还是有共同之处的： 低级编程与高级编程：二者之间的区别是，编写程序时，我们是使用机器层次的指令和数据对象（例如，将64位数据从一个位置移动到另一个位置），还是使用语言设计者提供的更为抽象的操作（例如，在屏幕上弹出一个菜单。） 通用性和专注于某一应用领域：指编程语言中的基本操作是广泛适用的还是只针对某个领域。例如，SQL设计的目的是使你更容易地从数据库提取信息，但你不能指望去建立一个操作系统。 解析运行和编译运行：指程序员编写的指令序列，即源代码是直接执行（通过解释器）的，还是要先转换（用过编译器）成机器层次的基础操作序列。（在早期的计算机中，人们必须使用与机器编码非常相似的语言来编写源代码，这种代码可以直接被计算机硬件解释执行。）这两种方法各有优势。使用解释型语言编写的程序更容易调试，因为解释器可以给出与源代码相关的错误信息。而编译型语言编写的程序速度更快，占用的空间也更少。 各种类型语言的总结编译型语言和解释型语言1、编译型语言 需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。 优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。 缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。 代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift 2、解释型语言 解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。 优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。 缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。 代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby 3、混合型语言 既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。比如C#,C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行（博友回复指出）。我个人认为抛开一切的偏见C#是这个星球上最好的编程语言。可惜微软的政策限制了C#的推广。 Java先生成字节码再在Java虚拟机中解释执行。 严格来说混合型语言属于解释型语言。C#更接近编译型语言。 动态语言和静态语言1、动态语言 是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。 主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。 2、静态语言 与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。 3、注意： 很多人认为解释型语言都是动态语言，这个观点是错的！Java是解释型语言但是不是动态语言，Java不能在运行的时候改变自己结构。反之成立吗？动态语言都是解释型语言。也是错的！Object-C是编译型语言，但是他是动态语言。得益于特有的run time机制（准确说run time不是语法特性是运行时环境，这里不展开）OC代码是可以在运行的时候插入、替换方法的。 C#也是动态语言，通过C#的反射机制可以动态的插入一段代码执行。所以我说C#是这个星球最好的编程语言。 动态类型语言和静态类型语言1、动态类型语言 很多网上资料把动态类型语言和动态语言混为一谈，简直是误人子弟。动态类型语言和动态语言是完全不同的两个概念。动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行是改变结构，说的是代码结构。 动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。 主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。 2、静态类型语言 静态语言的数据类型是在编译其间确定的或者说运行之前确定的，编写代码的时候要明确确定变量的数据类型。 主要语言：C、C++、C#、Java、Object-C。 3、注意： 相当一部分程序员，也包括曾经的我，认为解释型语言都是动态类型语言，编译型语言都是静态类型语言。这个也是错的。swift是编译型语言但是它也是动态类型语言。C#和Java是解释型语言也是静态类型语言。 强类型语言和弱类型语言1、强类型语言： 强类型语言，一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型。你不能把一个整形变量当成一个字符串来处理。 主要语言：Java、C#、Python、Object-C、Ruby 2、弱类型语言： 数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型。 主要语言：JavaScript、PHP、C、C++（C和C++有争议，但是确实可以给一个字符变量赋整形值，可能初衷是强类型，形态上接近弱类型） 3、注意： 一个语言是不是强类型语言和是不是动态类型语言也没有必然联系。Python是动态类型语言，是强类型语言。JavaScript是动态类型语言，是弱类型语言。Java是静态类型语言，是强类型语言。]]></content>
      <categories>
        <category>python基础</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
</search>
